{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba11211",
   "metadata": {},
   "source": [
    "In this notebook, all the calculation for the likelihood are gathered.\n",
    "\n",
    "The main function looks for a pdf distribution, that will then permit to determine the likelihood of an event, thanks to the cdf of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4699da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats._continuous_distns import _distn_names\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec17621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=5000, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Best holders\n",
    "    best_distributions = []\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for ii, distribution in enumerate([d for d in _distn_names if not d in ['levy_stable', 'studentized_range']]):\n",
    "\n",
    "        #print(\"{:>3} / {:<3}: {}\".format( ii+1, len(_distn_names), distribution ))\n",
    "\n",
    "        distribution = getattr(st, distribution)\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "                \n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "                \n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0)) # error calculated here with the mean squared error\n",
    "                # y ; observed values from histogram\n",
    "                # pdf ; predicted values from distribution function\n",
    "                \n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                best_distributions.append((distribution, params, sse))\n",
    "        \n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    return sorted(best_distributions, key=lambda x:x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bf56f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150691f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_best_distr(data,climate_var,unit):\n",
    "    matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "    matplotlib.style.use('ggplot')\n",
    "\n",
    "    # Plot for comparison\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = data.plot(kind='hist', bins=50, density=True, alpha=0.5, color=list(matplotlib.rcParams['axes.prop_cycle'])[1]['color'])\n",
    "\n",
    "    # Save plot limits\n",
    "    dataYLim = ax.get_ylim()\n",
    "\n",
    "    # Find best fit distribution\n",
    "    best_distibutions = best_fit_distribution(data, 200, ax)\n",
    "    best_dist = best_distibutions[0]\n",
    "\n",
    "    # Update plots\n",
    "    ax.set_ylim(dataYLim)\n",
    "    ax.set_title(u'Histogram data\\n All Fitted Distributions')\n",
    "    ax.set_xlabel(climate_var+' '+unit)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Make PDF with best params \n",
    "    pdf = make_pdf(best_dist[0], best_dist[1])\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = pdf.plot(lw=2, label='PDF', legend=True)\n",
    "    data.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=True, ax=ax)\n",
    "\n",
    "    param_names = (best_dist[0].shapes + ', loc, scale').split(', ') if best_dist[0].shapes else ['loc', 'scale']\n",
    "    param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_dist[1])])\n",
    "    dist_str = '{}({})'.format(best_dist[0].name, param_str)\n",
    "\n",
    "    ax.set_title(u'Data with best fit distribution \\n' + dist_str)\n",
    "    ax.set_xlabel(climate_var+' '+unit)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    print('best distribution '+str(best_dist[0].name))\n",
    "    return best_dist[0], param_str # return the function of distribution attributes, return the parameters as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51ad16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before appling this function, need to import the best ditribution function attributed to the distribution, otherwise, it will not work\n",
    "# idea of function that gives you direclty the likelihood of an event\n",
    "\n",
    "# rice is a distribution function\n",
    "#rice.ppf(0.95,1.8,loc=36.01,scale=2.61)\n",
    "#rice.cdf(45.512922702726385,1.8,loc=36.01,scale=2.61)\n",
    "#rice.ppf(0.95,1.8,loc=36.01,scale=2.61)\n",
    "#rice.ppf(0.05,1.8,loc=36.01,scale=2.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c7d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(event, name_distr, params):\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "    \n",
    "    # find the function of the distribution based on the name of the function\n",
    "    # The getattr() method returns the value of the named attribute of an object. \n",
    "    # If not found, it returns the default value provided to the function.\n",
    "    # https://www.programiz.com/python-programming/methods/built-in/getattr\n",
    "    distribution = getattr(st, name_distr) # st is the short name for the module 'scipy.stats'\n",
    "    \n",
    "    pdf_ = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    cdf_ = distribution.cdf(event,loc=loc, scale=scale, *arg)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd09bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_likelihood(event,unit, distribution, params):\n",
    "    \n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "    \n",
    "    #distribution = getattr(st, name_distr) # st is the short name for the module 'scipy.stats'\n",
    "    cdf_event = distribution.ppf(event,loc=loc, scale=scale, *arg)\n",
    "    \n",
    "    if cdf_event>=0.05 and cdf_event<=0.95:\n",
    "        if cdf_event>=0.17 and cdf_event<=0.83:\n",
    "            if cdf_event>=0.25 and cdf_event<=0.75:\n",
    "                likelihood = str(round(distribution.ppf(0.25,loc=loc, scale=scale, *arg),2))+'-'+str(round(distribution.ppf(0.75,loc=loc, scale=scale, *arg),2))+unit+', probable range' # more likely than not\n",
    "                return likelihood\n",
    "            likelihood = str(round(distribution.ppf(0.17,loc=loc, scale=scale, *arg),2))+'-'+str(round(distribution.ppf(0.83,loc=loc, scale=scale, *arg),2))+unit+', likely range'\n",
    "            return likelihood\n",
    "        if cdf_event<0.17 and cdf_event>0.83:\n",
    "            likelihood = 'unlikely range'\n",
    "            return likelihood\n",
    "        likelihood = str(round(distribution.ppf(0.05,loc=loc, scale=scale, *arg),2))+'-'+str(round(distribution.ppf(0.95,loc=loc, scale=scale, *arg),2))+unit+', very likely range'\n",
    "        return likelihood\n",
    "    else:\n",
    "        likelihood = 'very unlikely range'\n",
    "        return likelihood\n",
    "    print('Problem, no likelihood was found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f1f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(event,type_event,unit, distribution, params):\n",
    "    \n",
    "    proba_event=type_event_f(event,type_event,distribution,params)\n",
    "    \n",
    "    likelihood = define_likelihood(proba_event)\n",
    "    \n",
    "    return proba_event,likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491d766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_event_f(event,type_event,distribution,params):\n",
    "    \n",
    "    params1=params.split(',')\n",
    "    arg=[]\n",
    "    for p in params1:\n",
    "        if 'loc' in p:\n",
    "            temp=p.split('=')\n",
    "            loc = float(temp[len(temp)-1])\n",
    "            continue\n",
    "        if 'scale' in p:\n",
    "            temp=p.split('=')\n",
    "            scale = float(temp[len(temp)-1]  )   \n",
    "            continue\n",
    "        else:\n",
    "            temp=p.split('=')\n",
    "            arg.append(float(temp[len(temp)-1]))\n",
    "            continue\n",
    "\n",
    "    #distribution = getattr(st, distribution) # st is the short name for the module 'scipy.stats'\n",
    "    if type_event == '=':\n",
    "        proba_event = distribution.pdf(event,loc=loc, scale=scale, *arg)\n",
    "        \n",
    "    if type_event == '>': # likelihood variable over a threshold\n",
    "        proba_event = 1-distribution.cdf(event,loc=loc, scale=scale, *arg)\n",
    "    \n",
    "    if type_event == '<': # likelihood variable under a threshold\n",
    "        proba_event = distribution.cdf(event,loc=loc, scale=scale, *arg)\n",
    "    return proba_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec492d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_likelihood(proba_event):\n",
    "    if proba_event<0.05:\n",
    "        likelihood = 'Rare'\n",
    "        return likelihood\n",
    "    if proba_event<0.2:\n",
    "        likelihood = 'Unlikely'\n",
    "        return likelihood\n",
    "        \n",
    "    if proba_event<0.5:\n",
    "        likelihood = 'Moderate'\n",
    "        return likelihood\n",
    "        \n",
    "    if proba_event<0.8:\n",
    "        likelihood = 'Likely'\n",
    "        return likelihood\n",
    "        \n",
    "    if proba_event<0.95:\n",
    "        likelihood = 'Almost certain'\n",
    "        return likelihood\n",
    "    else: # over 0.95\n",
    "        likelihood = 'Certain'\n",
    "        return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e328e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input dataframe df should have no Nan values (add .dropna() at the end of input)\n",
    "# climate_var is 'tas', 'tasmax','tasmin' or 'pr'\n",
    "# name_column is the name of the column of the values of interest\n",
    "# event is the threshold value of the event to look at\n",
    "# type_event is either '=','>' or '<'. \n",
    "# examples, \n",
    "#     if we are interested in the event 'the temperature will go over 40', event = 40, type_event = '>'\n",
    "#     if we are interested in the event 'the temperature will go under 40', event = 40, type_event = '<'\n",
    "def likelihood_accross_models(df,climate_var,unit,name_column,event,type_event):\n",
    "    \n",
    "    proba_event=[]\n",
    "    model_not_in_final_calculation = []\n",
    "    for model in list(set(df['Model'])):\n",
    "        (distribution,params)=look_best_distr(df[df['Model']==model][[name_column]],climate_var,unit)\n",
    "        print('params '+str(params))\n",
    "        proba_event_model = type_event_f(event,type_event,distribution,params)\n",
    "        print('proba_event_model '+str(proba_event_model))\n",
    "        if not np.isnan(proba_event_model): # apparently, when the parameters are too small, can cause trouble to calculate the probability\n",
    "            proba_event.append(proba_event_model)\n",
    "            print('proba_event_model registered')\n",
    "        else:\n",
    "            model_not_in_final_calculation.append(distribution.name)\n",
    "        \n",
    "    proba_event_accross_model=statistics.mean(proba_event)\n",
    "    \n",
    "    likelihood=define_likelihood(proba_event_accross_model)\n",
    "    \n",
    "    return proba_event_accross_model,likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input dataframe df should have no Nan values (add .dropna() at the end of input)\n",
    "# CAREFUL --> only inout one project each time, not sevral ones in the same dataframe\n",
    "# climate_var is 'tas', 'tasmax','tasmin' or 'pr'\n",
    "# name_column is the name of the column of the values of interest\n",
    "# event is the threshold value of the event to look at\n",
    "# type_event is either '=','>' or '<'. \n",
    "# examples, \n",
    "#     if we are interested in the event 'the temperature will go over 40', event = 40, type_event = '>'\n",
    "#     if we are interested in the event 'the temperature will go under 40', event = 40, type_event = '<'\n",
    "\n",
    "def likelihood_accross_models_and_ssps(df,climate_var,unit,name_column,event,type_event):\n",
    "    \n",
    "    proba_event=[]\n",
    "    model_not_in_final_calculation = []\n",
    "    for model in list(set(df['Model'])):\n",
    "        for ssp in list(set(df['Experiment'])):\n",
    "            (distribution,params)=look_best_distr(df[(df['Model']==model)&(df['Experiment']==ssp)][[name_column]],climate_var,unit)\n",
    "            print('params '+str(params))\n",
    "            proba_event_model = type_event_f(event,type_event,distribution,params)\n",
    "            print('proba_event_model '+str(proba_event_model))\n",
    "            if not np.isnan(proba_event_model): # apparently, when the parameters are too small, can cause trouble to calculate the probability\n",
    "                proba_event.append(proba_event_model)\n",
    "                print('proba_event_model registered')\n",
    "            else:\n",
    "                model_not_in_final_calculation.append(distribution.name)\n",
    "        \n",
    "    proba_event_accross_model=statistics.mean(proba_event)\n",
    "    \n",
    "    likelihood=define_likelihood(proba_event_accross_model)\n",
    "    \n",
    "    return proba_event_accross_model,likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f14cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
