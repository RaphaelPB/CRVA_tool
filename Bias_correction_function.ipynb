{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76bbfc5c",
   "metadata": {},
   "source": [
    "This notebook aims to contain all the functions that will permit to apply bias correction.\n",
    "\n",
    "TO DO :\n",
    "\n",
    "NEED TO CHECK FUNCTIONALITY OF THE CODE for other methods than bscd precipitation\n",
    "apply cdf for quantile ..\n",
    "impose a version for the past and for the future (without y test, not used for BC, just for presentation of results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e514190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculte return period\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import gumbel_r\n",
    "from scipy.stats import gumbel_l\n",
    "\n",
    "# function qui marche pour precipitation return period\n",
    "\n",
    "\n",
    "def threshold_coresponding_to_return_period(loc,scale,T):\n",
    "    p_non_exceedance = 1 - (1/T)\n",
    "    try:\n",
    "        threshold_coresponding = round(gumbel_r.ppf(p_non_exceedance,loc,scale))\n",
    "    except OverflowError: # the result is not finite\n",
    "        if math.isinf(gumbel_r.ppf(p_non_exceedance,loc,scale)) and gumbel_r.ppf(p_non_exceedance,loc,scale)<0:\n",
    "            # ppf is the inverse of cdf\n",
    "            # the result is -inf\n",
    "            threshold_coresponding = 0 # the value of wero is imposed\n",
    "    return threshold_coresponding\n",
    "\n",
    "from Functions_Indicators import add_year_month_season # need to add conversion of time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baedebe",
   "metadata": {},
   "source": [
    "# BIAS CORRECTION - POINT WISE METHOD\n",
    "\n",
    "[Scikit-downscale](https://github.com/pangeo-data/scikit-downscale/tree/main)\n",
    "[Detailed process here](https://github.com/pangeo-data/scikit-downscale/blob/main/examples/2020ECAHM-scikit-downscale.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8752f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import xarray as xr\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# exploratory data analysis for arrm model\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# train_test_split Quick utility that wraps input validation and\n",
    "#    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
    "#    into a single call for splitting (and optionally subsampling) data in a\n",
    "#    oneliner.\n",
    "#    Returns\n",
    "#    -------\n",
    "#    splitting : list, length=2 * len(arrays)\n",
    "#        List containing train-test split of inputs.\n",
    "\n",
    "#        .. versionadded:: 0.16\n",
    "#            If the input is sparse, the output will be a\n",
    "#            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
    "#            input type.\n",
    "\n",
    "#from utils import get_sample_data\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# use for discretization\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b91f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare data for the fitting\n",
    "def treat_data_for_test(df_obs,name_col_obs,df_model_past,name_col_model,name_station,model):\n",
    "    #from sklearn.preprocessing import StandardScaler\n",
    "    if 'pr' in name_col_model.lower():\n",
    "        new_name = 'pcp'\n",
    "    if 'temp' in name_col_model.lower():\n",
    "        if 'maximum' in name_col_model.lower():\n",
    "            new_name = 'temp_max'\n",
    "        if 'minimum' in name_col_model.lower():\n",
    "            new_name = 'temp_min'\n",
    "        if 'maximum' not in name_col_model.lower() and 'minimum' not in name_col_model.lower():\n",
    "            new_name = 'temp'\n",
    "    \n",
    "    # prepare training data\n",
    "    df_model_past_BC=df_model_past[df_model_past['Name station']==name_station].drop(['Name station','Year','Month','Season'],axis =1)\n",
    "    df_model_past_BC = df_model_past_BC[df_model_past_BC['Model'] ==model].drop(['Model','Experiment','Latitude','Longitude'],axis=1)\n",
    "    training = df_model_past_BC.rename(columns = {'Date':'time',name_col_model:new_name}).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    # Scale your dataset to avoid “ValueError: Input contains NaN, infinity or a value too large for dtype(‘float64’)”\n",
    "    #scaler = StandardScaler()\n",
    "    #training[new_name].values = scaler.fit_transform(training[new_name].values)\n",
    "    \n",
    "    Date1 = training['time'].values\n",
    "    for i in np.arange(0,len(training)):\n",
    "        training['time'][i] = Date1[i][6:10]+'-'+Date1[i][3:5]+'-'+Date1[i][0:2]#datetime.strptime(, '%Y-%M-%d').date()\n",
    "        #print(training['time'][i])\n",
    "    # .date() to avoid having the hours in the datetime\n",
    "    training=training.set_index('time')\n",
    "    \n",
    "    # prepare targets data\n",
    "    targets = df_obs[['NAME','DATE',name_col_obs]] # select only 3 columns of interest\n",
    "    targets = targets[targets['NAME']==name_station].rename(columns = {'DATE':'time',name_col_obs:new_name}).set_index('time').drop(['NAME'],axis=1) # the targets data is meant to represent our \"observations\"\n",
    "    \n",
    "    if len(targets)>len(training):\n",
    "        targets = targets.dropna() # drop rows with NaN\n",
    "        training = training[training.index.isin(list(targets.index))]\n",
    "    if len(targets)<len(training):\n",
    "        training = training.dropna() # drop rows with NaN\n",
    "        targets = targets[targets.index.isin(list(training.index))]\n",
    "    \n",
    "    # concat training and target data in one dataframe\n",
    "    df=pd.concat({'training': training, 'targets': targets}, axis=1)\n",
    "    df=df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ac64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_obs and df_model should be under a dataframe format, with no nan values, with a common timelaps, with the data as a string format '%Y-%m-%d', and as index\n",
    "\n",
    "# Method could be :\n",
    "#        piecewise_regressor\n",
    "#        Quantile_Linear_Regression\n",
    "\n",
    "def BC(df,name_col,method,name_station,name_project,name_model):\n",
    "    # set title and xaxis\n",
    "    if name_col == 'pcp':\n",
    "        climate_var = 'Precipitation '\n",
    "        unit = '[mm/day]'\n",
    "    if name_col == 'temp':\n",
    "        climate_var = 'Temperature '\n",
    "        unit = u'\\{°}C'\n",
    "    if name_col == 'temp_max':\n",
    "        climate_var = 'Maximum temperature '\n",
    "        unit = u'\\{°}C'\n",
    "    if name_col == 'temp_min':\n",
    "        climate_var = 'Minimum temperature '\n",
    "        unit = u'\\{°}C'\n",
    "    \n",
    "    if method == 'piecewise_regressor':\n",
    "        (X_train, X_test, y_train, y_test,pred)=piecewise_regressor(df,name_col)\n",
    "        #(X_train, X_test, y_train, y_test,name_strat,score_strat)=piecewise_regressor(df,name_col)\n",
    "        #return X_train, X_test, y_train, y_test,name_strat,score_strat\n",
    "        plot_train_test(X_train, X_test, y_train, y_test,name_station,name_col)\n",
    "        plot_train_test_pred(X_train, X_test, y_train, y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test,y_test, y_train, pred,name_station,name_project,name_model,name_col)\n",
    "        # plot CDF\n",
    "        #plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        plot_cdf(ax=ax,X=X_test, y=y_test, out=pred)\n",
    "        ax.set_xlabel('Cumulative distribution function')\n",
    "        ax.set_ylabel(climate_var+unit)\n",
    "        fig.suptitle(climate_var+'cumulative distribution function with observed data from '+name_station+' and modelled data from '+name_project)\n",
    "        \n",
    "    if method == 'Quantile_Linear_Regression':\n",
    "        (X_train, X_test, y_train, y_test,pred)=Quantile_Linear_Regression(df,name_col) \n",
    "        plot_train_test(X_train, X_test, y_train, y_test,name_station,name_col)\n",
    "        plot_train_test_pred(X_train, X_test, y_train, y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test,y_test, y_train, pred,name_station,name_project,name_model,name_col)\n",
    "        # plot CDF\n",
    "        #plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        plot_cdf(ax=ax,X=X_test, y=y_test, out=pred)\n",
    "        ax.set_xlabel('Cumulative distribution function')\n",
    "        ax.set_ylabel(climate_var+unit)\n",
    "        fig.suptitle(climate_var+'cumulative distribution function with observed data from '+name_station+' and modelled data from '+name_project)\n",
    "        \n",
    "    if method == 'Quantile_MLP_Regressor':\n",
    "        (X_train, X_test, y_train, y_test,pred)=Quantile_MLP_Regressor(df,name_col)\n",
    "        plot_train_test(X_train, X_test, y_train, y_test,name_station,name_col)\n",
    "        plot_train_test_pred(X_train, X_test, y_train, y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test,y_test, y_train, pred,name_station,name_project,name_model,name_col)\n",
    "        # plot CDF\n",
    "        #plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        plot_cdf(ax=ax,X=X_test, y=y_test, out=pred)\n",
    "        ax.set_xlabel('Cumulative distribution function')\n",
    "        ax.set_ylabel(climate_var+unit)\n",
    "        fig.suptitle(climate_var+'cumulative distribution function with observed data from '+name_station+' and modelled data from '+name_project)\n",
    "    \n",
    "    if method == 'Bcsd_Precipitation':\n",
    "        (X_train, X_test, y_train, y_test,pred)=BCSD_Precipitation(df)\n",
    "        plot_time_series(X_test,y_test,pred,name_model)\n",
    "        plot_train_test_pred(X_train.values, X_test.values, y_train.values, y_test.values,pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test.values,y_test.values, y_train.values, pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        \n",
    "        \n",
    "    if method == 'BCSD_Precipitation_without_multi':\n",
    "        (X_train, X_test, y_train, y_test,pred)=BCSD_Precipitation_without_multi(df)\n",
    "        plot_time_series(X_test,y_test,pred,name_model)\n",
    "        plot_train_test_pred(X_train.values, X_test.values, y_train.values, y_test.values,pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test.values,y_test.values, y_train.values, pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "        \n",
    "        \n",
    "    if method == 'Bcsd_Temperature':\n",
    "        (X_train, X_test, y_train, y_test,pred)=BCSD_Temperature(df)\n",
    "        plot_time_series(X_test,y_test,pred,name_model)\n",
    "        plot_train_test_pred(X_train.values, X_test.values, y_train.values, y_test.values,pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test.values,y_test.values, y_train.values, pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "    \n",
    "    if method == 'BCSD_Temperature_without_addition':\n",
    "        (X_train, X_test, y_train, y_test,pred)=BCSD_Temperature_without_addition(df)\n",
    "        plot_time_series(X_test,y_test,pred,name_model)\n",
    "        plot_train_test_pred(X_train.values, X_test.values, y_train.values, y_test.values,pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_test_pred(X_test.values,y_test.values, y_train.values, pred.values,name_station,name_project,name_model,name_col)\n",
    "        plot_cdfs(X_test,y_test,pred,name_station,name_project,name_model,name_col)\n",
    "\n",
    "    return pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a78c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_regressor(df,name_col):\n",
    "    from mlinsights.mlmodel import PiecewiseRegressor # in piecewise estimator\n",
    "    #     Uses a :epkg:`decision tree` to split the space of features\n",
    "    #    into buckets and trains a linear regression (default) on each of them.\n",
    "    #    The second estimator is usually a :epkg:`sklearn:linear_model:LinearRegression`.\n",
    "    #    It can also be :epkg:`sklearn:dummy:DummyRegressor` to just get\n",
    "    #    the average on each bucket.\n",
    "    \n",
    "    X = df[[('training',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#training[[name_col]]['1980': '2000'].values\n",
    "    y = df[[('targets',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#targets[[name_col]]['1980': '2000'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)# splits data\n",
    "    \n",
    "    # parameters for Quantile transforms\n",
    "    qqwargs = {'n_quantiles': int(1e6), 'copy': True, 'subsample': int(1e6)} # add int for n_quantiles and subsample to avoid\n",
    "    # following problem:  InvalidParameterError: The 'n_quantiles' parameter of QuantileTransformer must be an int in the range [1, inf). Got 1000000.0 instead.\n",
    "    n_bins = 7\n",
    "\n",
    "    \n",
    "    score_strat =[]\n",
    "    name_strat = ['kmeans', 'uniform', 'quantile']\n",
    "    print('R2 score')\n",
    "    for strat in name_strat:\n",
    "        model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=strat))\n",
    "        #model.fit(X_train, y_train)\n",
    "        model.fit(X_train.reshape((len(X_train),1)), y_train.reshape((len(y_train),)))\n",
    "        #pred = model.predict(X_test)\n",
    "        pred = model.predict(X_test.reshape((len(X_test),1)))#*X_test.reshape((len(X_test),))\n",
    "        #print(model.score(X_test, y_test))\n",
    "        print(model.score(X_test.reshape((len(X_test),1)), y_test.reshape((len(y_test),))))\n",
    "        score_strat.append(model.score(X_test.reshape((len(X_test),1)), y_test.reshape((len(y_test),))))\n",
    "        # how is the score calculated ? r2 score\n",
    "    #return X_train, X_test, y_train, y_test,name_strat,score_strat\n",
    "    #model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=name_strat[int(np.where(score_strat==max(score_strat))[0])]))\n",
    "    #model.fit(X_train, y_train)\n",
    "    model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=name_strat[int(np.where(score_strat==max(score_strat))[0])]))\n",
    "    model.fit(X_train.reshape((len(X_train),1)), y_train.reshape((len(y_train),)))\n",
    "    #if name_col=='pcp':\n",
    "    #    pred = model.predict(X_test.reshape((len(X_test),1)))*X_test.reshape((len(X_test),))\n",
    "    #    print('Applying correction for precipitation')\n",
    "    #if 'temp' in name_col.lower():\n",
    "    #    pred = model.predict(X_test.reshape((len(X_test),1)))+X_test.reshape((len(X_test),))\n",
    "    #    print('Applying correction for temperature')\n",
    "    #if name_col!='pcp' and 'temp' not in name_col.lower():\n",
    "    #else:\n",
    "    pred = model.predict(X_test)\n",
    "    #pred = model.predict(X_test.reshape((len(X_test),1)))\n",
    "    #    print('Applying correction for other climate variable')\n",
    "    print('Strategy chosen is '+name_strat[int(np.where(score_strat==max(score_strat))[0])])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e5af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantile_Linear_Regression(df,name_col):\n",
    "    from mlinsights.mlmodel import QuantileLinearRegression # in quantile_regression\n",
    "    \n",
    "    X = df[[('training',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#training[[name_col]]['1980': '2000'].values\n",
    "    y = df[[('targets',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#targets[[name_col]]['1980': '2000'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)# splits data\n",
    "    \n",
    "    #y_train = y_train[:, 0]\n",
    "    \n",
    "    model = QuantileLinearRegression()\n",
    "\n",
    "    model.fit(X_train.reshape((len(X_train),1)), y_train.reshape((len(y_train),)))\n",
    "    #if name_col=='pcp':\n",
    "       # pred = model.predict(X_test.reshape((len(X_test),1)))*X_test.reshape((len(X_test),))\n",
    "    #if 'temp' in name_col.lower():\n",
    "        #pred = model.predict(X_test.reshape((len(X_test),1)))+X_test.reshape((len(X_test),))\n",
    "    #if name_col!='pcp' and 'temp' not in name_col.lower():\n",
    "    #else:\n",
    "    pred = model.predict(X_test.reshape((len(X_test),1)))\n",
    "    print('mean absolute error')\n",
    "    print(model.score(X_test.reshape((len(X_test),1)), y_test.reshape((len(y_test),))))# mean absolute error\n",
    "    \n",
    "\n",
    "    return (X_train, X_test, y_train, y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5107c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Quantile_MLP_Regressor(df,name_col):\n",
    "    from mlinsights.mlmodel import QuantileMLPRegressor # in qunatile_mlpregressor\n",
    "    \n",
    "    X = df[[('training',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#training[[name_col]]['1980': '2000'].values\n",
    "    y = df[[('targets',name_col)]][min(df.index)[0:4]: max(df.index)[0:4]].values#targets[[name_col]]['1980': '2000'].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)# splits data\n",
    "    \n",
    "    model = QuantileMLPRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print('mean absolute error')\n",
    "    print(model.score(X_test, y_test)) # mean absolute error\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30cbdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCSD_Precipitation(df):\n",
    "    from skdownscale.pointwise_models import BcsdPrecipitation\n",
    "\n",
    "    training = df['training']\n",
    "    targets = df['targets']\n",
    "    training.index = pd.to_datetime(training.index)\n",
    "    targets.index = pd.to_datetime(targets.index)\n",
    "    X_pcp = training[[\"pcp\"]].resample(\"MS\").sum()#MS\n",
    "    y_pcp = targets[[\"pcp\"]].resample(\"MS\").sum()\n",
    "    # Fit/predict the BCSD Temperature model\n",
    "    bcsd_temp = BcsdPrecipitation()\n",
    "    bcsd_temp.fit(X_pcp, y_pcp)\n",
    "    out = bcsd_temp.predict(X_pcp) * X_pcp # additive for temperature, multiplicative for precipitation\n",
    "    \n",
    "    return (X_pcp,X_pcp,y_pcp,y_pcp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a719a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCSD_Precipitation_without_multi(df):\n",
    "    from skdownscale.pointwise_models import BcsdPrecipitation\n",
    "\n",
    "    training = df['training']\n",
    "    targets = df['targets']\n",
    "    training.index = pd.to_datetime(training.index)\n",
    "    targets.index = pd.to_datetime(targets.index)\n",
    "    X_pcp = training[[\"pcp\"]].resample(\"MS\").sum()#MS\n",
    "    y_pcp = targets[[\"pcp\"]].resample(\"MS\").sum()\n",
    "    # Fit/predict the BCSD Temperature model\n",
    "    bcsd_temp = BcsdPrecipitation()\n",
    "    bcsd_temp.fit(X_pcp, y_pcp)\n",
    "    out = bcsd_temp.predict(X_pcp)# * X_pcp # additive for temperature, multiplicative for precipitation\n",
    "    \n",
    "    return (X_pcp,X_pcp,y_pcp,y_pcp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4ee592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCSD_Precipitation_one_more_time(df,out):\n",
    "    \n",
    "    df=df.loc[out.index]\n",
    "    df['training'] = out['pcp']\n",
    "    print(df)\n",
    "    out = BCSD_Precipitation(df)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d43704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing graphs\n",
    "\n",
    "def BCSD_Temperature(df):\n",
    "    from skdownscale.pointwise_models import BcsdTemperature\n",
    "    training = df['training']\n",
    "    targets = df['targets']\n",
    "    training.index = pd.to_datetime(training.index)\n",
    "    targets.index = pd.to_datetime(targets.index)\n",
    "    X_temp = training[[training.columns[0]]].resample(\"MS\").mean()#MS\n",
    "    y_temp = targets[[training.columns[0]]].resample(\"MS\").mean()\n",
    "    \n",
    "    X_temp = X_temp.dropna()\n",
    "    y_temp = y_temp.dropna()\n",
    "    \n",
    "    if len(X_temp) != len(y_temp):\n",
    "        if len(X_temp) <= len(y_temp):\n",
    "            y_temp[y_temp.index.isin(list(X_temp.index))]\n",
    "        if len(X_temp) >= len(y_temp):\n",
    "            X_temp[X_temp.index.isin(list(y_temp.index))]\n",
    "            \n",
    "    print('Check for nan values')\n",
    "    print(X_temp.isnull().sum())\n",
    "    print(y_temp.isnull().sum())\n",
    "    print('Check for infinity values')\n",
    "    print(np.isinf(y_temp).sum())\n",
    "    print(y_temp.isnull().sum())\n",
    "    # Fit/predict the BCSD Temperature model\n",
    "    bcsd_temp = BcsdTemperature()\n",
    "    bcsd_temp.fit(X_temp, y_temp)\n",
    "    out = bcsd_temp.predict(X_temp) + X_temp # additive for temperature, multiplicative for precipitation\n",
    "    return (X_temp,X_temp,y_temp,y_temp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81555d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing graphs\n",
    "\n",
    "def BCSD_Temperature_without_addition(df):\n",
    "    from skdownscale.pointwise_models import BcsdTemperature\n",
    "    training = df['training']\n",
    "    targets = df['targets']\n",
    "    training.index = pd.to_datetime(training.index)\n",
    "    targets.index = pd.to_datetime(targets.index)\n",
    "    X_temp = training[[training.columns[0]]].resample(\"MS\").mean()#MS\n",
    "    y_temp = targets[[training.columns[0]]].resample(\"MS\").mean()\n",
    "    \n",
    "    X_temp = X_temp.dropna()\n",
    "    y_temp = y_temp.dropna()\n",
    "    \n",
    "    if len(X_temp) != len(y_temp):\n",
    "        if len(X_temp) <= len(y_temp):\n",
    "            y_temp[y_temp.index.isin(list(X_temp.index))]\n",
    "        if len(X_temp) >= len(y_temp):\n",
    "            X_temp[X_temp.index.isin(list(y_temp.index))]\n",
    "            \n",
    "    print('Check for nan values')\n",
    "    print(X_temp.isnull().sum())\n",
    "    print(y_temp.isnull().sum())\n",
    "    print('Check for infinity values')\n",
    "    print(np.isinf(y_temp).sum())\n",
    "    print(y_temp.isnull().sum())\n",
    "    # Fit/predict the BCSD Temperature model\n",
    "    bcsd_temp = BcsdTemperature()\n",
    "    bcsd_temp.fit(X_temp, y_temp)\n",
    "    out = bcsd_temp.predict(X_temp)# + X_temp # additive for temperature, multiplicative for precipitation\n",
    "    return (X_temp,X_temp,y_temp,y_temp,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61b70a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "def plot_time_series(X_test_to_copy,y_test_to_copy,out_to_copy,name_model):\n",
    "    \n",
    "    #out.plot()\n",
    "    #plt.title('')\n",
    "    \n",
    "    X_test=X_test_to_copy.copy(deep=True)\n",
    "    y_test=y_test_to_copy.copy(deep=True)\n",
    "    out=out_to_copy.copy(deep=True)\n",
    "    \n",
    "    \n",
    "    #out=out.rename(columns={'training':'pcp'})\n",
    "    \n",
    "    out.index = out.index.strftime('%Y-%m-%d')\n",
    "    X_test.index = X_test.index.strftime('%Y-%m-%d')\n",
    "    y_test.index = y_test.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=1, nrows=3, figsize=(8, 9), sharex=True)\n",
    "    time_slice = slice(min(X_test.index), max(X_test.index))\n",
    "\n",
    "    # plot-temperature\n",
    "    #training[time_slice]['pcp'].plot(ax=axes[0], label='training')\n",
    "    X_test[time_slice][X_test.columns[0]].plot(ax=axes[0], label='training')\n",
    "    #X_test[time_slice][[('training','pcp')]].plot(ax=axes[0], label='training')\n",
    "    axes[0].legend()\n",
    "    if X_test.columns[0]=='pcp':\n",
    "        axes[0].set_ylabel('Precipitation [mm/day]')\n",
    "        climate_var = 'precipitation'\n",
    "    if 'temp' in X_test.columns[0]:\n",
    "        axes[0].set_ylabel(u'Temperature ['+u'\\{°}'+'C]')\n",
    "        climate_var = 'temperature'\n",
    "    axes[0].set_ylim(0,max(X_test.values))\n",
    "\n",
    "\n",
    "    # plot-precipitation\n",
    "    #targets[time_slice]['pcp'].plot(ax=axes[1], label='target')\n",
    "    y_test[time_slice][y_test.columns[0]].plot(ax=axes[1], label='target')\n",
    "    #y_test[time_slice][[('targets','pcp')]].plot(ax=axes[1], label='target')\n",
    "    axes[1].legend()\n",
    "    if y_test.columns[0]=='pcp':\n",
    "        str_ylabel='Precipitation [mm/day]'\n",
    "    if 'temp' in y_test.columns[0]:\n",
    "        if X_test.columns[0]=='temp':\n",
    "            str_ylabel='Temperature [°C]'\n",
    "        if X_test.columns[0]=='temp_max':\n",
    "            str_ylabel='Maximum temperature [°C]'\n",
    "        if X_test.columns[0]=='temp_min':\n",
    "            str_ylabel='Minimum temperature [°C]'\n",
    "    _ = axes[1].set_ylabel(str_ylabel)\n",
    "    axes[1].set_ylim(0,max(y_test.values))\n",
    "\n",
    "    # plot-precipitation\n",
    "    out[time_slice][out.columns[0]].plot(ax=axes[2], label='out')\n",
    "    #out[time_slice][[('training','pcp')]].plot(ax=axes[2], label='out')\n",
    "    axes[2].legend()\n",
    "    if X_test.columns[0]=='pcp':\n",
    "        str_ylabel='Precipitation [mm/day]'\n",
    "    if 'temp' in X_test.columns[0]:\n",
    "        if X_test.columns[0]=='temp':\n",
    "            str_ylabel='Temperature [°C]'\n",
    "        if X_test.columns[0]=='temp_max':\n",
    "            str_ylabel='Maximum temperature [°C]'\n",
    "        if X_test.columns[0]=='temp_min':\n",
    "            str_ylabel='Minimum temperature [°C]'\n",
    "    _ = axes[2].set_ylabel(str_ylabel)\n",
    "    axes[2].set_ylim(0,max(out.values))\n",
    "    \n",
    "    fig.suptitle('Comparison of observed and modeled data ('+name_model+') with '+climate_var+' bias corrected time serie')\n",
    "    return\n",
    "\n",
    "def plot_train_test(X_train, X_test, y_train, y_test,name_station,name_col):\n",
    "    if name_col == 'pcp':\n",
    "        climate_var = 'Precipitation'\n",
    "    if name_col == 'temp':\n",
    "        climate_var = 'Temperature'\n",
    "    if name_col == 'temp_max':\n",
    "        climate_var = 'Maximum temperature'\n",
    "    if name_col == 'temp_min':\n",
    "        climate_var = 'Minimum temperature'\n",
    "        \n",
    "    sns.set(style='whitegrid')\n",
    "    c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.scatter(X_train, y_train, c=c['train'], s=5, label='train')\n",
    "    plt.scatter(X_test, y_test, c=c['test'], s=5, label='test')\n",
    "    plt.title(climate_var+' train and test data from '+name_station)\n",
    "    plt.xlabel('modeled data')\n",
    "    plt.ylabel('observed data')\n",
    "    ax.legend()\n",
    "    return\n",
    "\n",
    "def plot_train_test_pred(X_train, X_test, y_train, y_test,pred,name_station,name_project,name_model,name_col):\n",
    "    import pyspark\n",
    "    from pyspark.sql import DataFrame\n",
    "    \n",
    "    if name_col == 'pcp':\n",
    "        climate_var = 'Precipitation'\n",
    "    if name_col == 'temp':\n",
    "        climate_var = 'Temperature'\n",
    "    if name_col == 'temp_max':\n",
    "        climate_var = 'Maximum temperature'\n",
    "    if name_col == 'temp_min':\n",
    "        climate_var = 'Minimum temperature'\n",
    "        \n",
    "    sns.set(style='whitegrid')\n",
    "    c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plt.scatter(np.sort(X_train, axis=0), np.sort(y_train, axis=0), c=c['train'], s=5, label='train')\n",
    "    if not isinstance(X_train, DataFrame): # test if it is a DataFrame\n",
    "        #if not sum(X_test - X_train)[0]==0: # test if it is the dataframe are the similar\n",
    "        plt.scatter(np.sort(X_test, axis=0), np.sort(y_test, axis=0), c=c['test'], s=5, label='test')\n",
    "    plt.plot(np.sort(X_test, axis=0), np.sort(pred, axis=0), c=c['predict'], lw=2, label='predictions')\n",
    "    plt.title(climate_var+' sorted train and test data from '+name_station+' and prediction for '+name_project+' modelled data with '+name_model)\n",
    "    plt.xlabel('modeled data')\n",
    "    plt.ylabel('observed data and prediction')\n",
    "    ax.legend()\n",
    "    return\n",
    "    \n",
    "def plot_test_pred(X_test,y_test, y_train, pred,name_station,name_project,name_model,name_col):\n",
    "    \n",
    "    if name_col == 'pcp':\n",
    "        climate_var = 'Precipitation'\n",
    "    if name_col == 'temp':\n",
    "        climate_var = 'Temperature'\n",
    "    if name_col == 'temp_max':\n",
    "        climate_var = 'Maximum temperature'\n",
    "    if name_col == 'temp_min':\n",
    "        climate_var = 'Minimum temperature'\n",
    "        \n",
    "    sns.set(style='whitegrid')\n",
    "    c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    #ax.plot(X_test[:, 0], y_test, \".\", label='data', c=c['test'])\n",
    "    #ax.plot(X_test[:, 0], pred, \".\", label=\"predictions\", c=c['predict'])\n",
    "    ax.plot(X_test, y_test, \".\", label='data', c=c['test'])\n",
    "    ax.plot(X_test, pred, \".\", label=\"predictions\", c=c['predict'])\n",
    "    #ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "    plt.title(climate_var+' test data '+name_station+' and prediction  for '+name_project+' data modelled with '+name_model)\n",
    "    plt.xlabel('modeled data')\n",
    "    plt.ylabel('observed data and prediction')\n",
    "    ax.legend()\n",
    "    return\n",
    "\n",
    "def plot_cdfs(X_test,y_test,out,name_station,name_project,name_model,name_col):\n",
    "    if name_col == 'pcp':\n",
    "        climate_var = 'Precipitation'\n",
    "        unit = '[mm/day]'\n",
    "    if name_col == 'temp':\n",
    "        climate_var = 'Temperature'\n",
    "        unit = '°C'\n",
    "    if name_col == 'temp_max':\n",
    "        climate_var = 'Maximum temperature'\n",
    "        unit = '°C'\n",
    "    if name_col == 'temp_min':\n",
    "        climate_var = 'Minimum temperature'\n",
    "        unit = '°C'\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    plot_cdf(ax=ax,X=X_test, y=y_test, out=out)\n",
    "    # set title and xaxis\n",
    "    ax.set_xlabel('Cumulative distribution function')\n",
    "    ax.set_ylabel(climate_var+unit)\n",
    "    fig.suptitle(climate_var+'cumulative distribution function with observed data from '+name_station+' and modelled data with '+name_model+' from '+name_project)\n",
    "    \n",
    "    #plot_cdf_by_month(X=X_test, y=y_test.loc[list(X_test.index)], out=out)\n",
    "    fig=plot_cdf_by_month(X=X_test, y=y_test, out=out)\n",
    "    fig.suptitle(climate_var+'cumulative distribution function with observed data from '+name_station+' and modelled data with '+name_model+' from '+name_project+' for each month')\n",
    "    \n",
    "    return\n",
    "\n",
    "# utilities for plotting cdfs\n",
    "def plot_cdf(ax=None, **kwargs):\n",
    "    if ax:\n",
    "        plt.sca(ax)\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "    LW = 4\n",
    "    for label, X in kwargs.items():\n",
    "        vals = np.sort(X, axis=0)\n",
    "        pp = scipy.stats.mstats.plotting_positions(vals)\n",
    "        ax.plot(pp, vals, label=label,linewidth=LW)\n",
    "        LW -= 1\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cdf_by_month(ax=None, **kwargs):\n",
    "    fig, axes = plt.subplots(4, 3, sharex=True, sharey=False, figsize=(12, 8))\n",
    "    for label, X in kwargs.items():\n",
    "        for month, ax in zip(range(1, 13), axes.flat):\n",
    "\n",
    "            vals = np.sort(X[X.index.month == month], axis=0)\n",
    "            pp = scipy.stats.mstats.plotting_positions(vals)\n",
    "            ax.plot(pp, vals, label=label)\n",
    "            ax.set_title(month)\n",
    "    ax.legend()\n",
    "    # set title and xaxis\n",
    "    if X.columns[0] == 'pcp':\n",
    "        climate_var = 'Precipitation '\n",
    "        unit = '[mm/day]'\n",
    "    if X.columns[0] == 'temp':\n",
    "        climate_var = 'Temperature '\n",
    "        unit = '°C'\n",
    "    if X.columns[0] == 'temp_max':\n",
    "        climate_var = 'Maximum temperature '\n",
    "        unit = '°C'\n",
    "    if X.columns[0] == 'temp_min':\n",
    "        climate_var = 'Minimum temperature '\n",
    "        unit = '°C'\n",
    "    \n",
    "    fig.supxlabel('Cumulative distribution function')\n",
    "    fig.supylabel(climate_var+unit)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc818cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0eae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b74e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment on fait pour savoir chronologie de donnees corrigees ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c0987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443700b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ee7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test bcsd one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC=climate_var_NEX_GDDP_CMIP6_EmplacementStation[climate_var_NEX_GDDP_CMIP6_EmplacementStation['Name project']==name_station].drop(['Name project','Year','Month','Season'],axis =1)\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC_model = climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC[climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC['Model'] =='ACCESS-CM2'].drop(['Model'],axis=1)\n",
    "training = climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC_model.rename(columns = {'Date':'time','Mean of the daily precipitation rate mm/day':'pcp'}).reset_index()\n",
    "\n",
    "# changing format of Date for training\n",
    "Date1 = training['time'].values\n",
    "for i in np.arange(0,len(training)):\n",
    "    training['time'][i] = Date1[i][6:10]+'-'+Date1[i][3:5]+'-'+Date1[i][0:2]#datetime.strptime(, '%Y-%M-%d').date()\n",
    "    print(training['time'][i])\n",
    "# .date() to avoid having the hours in the datetime\n",
    "training=training.set_index('time').drop(['index'],axis=1)\n",
    "\n",
    "\n",
    "# targets\n",
    "targets = data_obs_NOAA[['NAME','DATE','PRCP']] # select only 3 columns of interest\n",
    "targets = targets[targets['NAME']==name_station].rename(columns = {'DATE':'time','PRCP':'pcp'}).set_index('time').drop(['NAME'],axis=1) # the targets data is meant to represent our \"observations\"\n",
    "\n",
    "\n",
    "# to have the same size of vectors\n",
    "targets = targets.dropna() # drop rows with NaN\n",
    "training = training[training.index.isin(list(targets.index))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''df=pd.concat({'training': training, 'targets': targets}, axis=1)\n",
    "\n",
    "df=df.dropna()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''df = df.droplevel(1,axis=1)\n",
    "df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfdb021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=BCSD_Precipitation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1514efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return period before first BC\n",
    "#out3 = add_year_month_season(out.reset_index(),'time')\n",
    "#Z=out3.groupby('Year')[['pcp']].max()\n",
    "#(loc1,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "# choice of gumbel because suits to extreme precipitation\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 50 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,50) ## 113\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 100 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,100) # 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=BCSD_Precipitation_one_more_time(df,out) # second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789e8cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecf698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=BCSD_Precipitation_one_more_time(df,out) # third time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c340d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=BCSD_Precipitation_one_more_time(df,out) # fourth time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out3 = add_year_month_season(out.reset_index(),'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3273049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5571101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z=out3.groupby('Year')[['pcp']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08728c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(loc1,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "# choice of gumbel because suits to extreme precipitation\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 50 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,50) ## 220\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 100 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,100) # 245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out=BCSD_Precipitation_one_more_time(df,out) # fifth time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = add_year_month_season(out.reset_index(),'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z=out.groupby('Year')[['pcp']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(loc1,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "# choice of gumbel because suits to extreme precipitation\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 50 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,50) ## 245\n",
    "#return_period.loc[(name_p,ssp,model),('Value for return period 100 years mm/day')] = \n",
    "#threshold_coresponding_to_return_period(loc1,scale,100) # 274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d025688a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4269f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
