{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93dcc14",
   "metadata": {},
   "source": [
    "This notebook is meant to download data from copernicus CMIP6.\n",
    "\n",
    "Data source : https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a4269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### User input\n",
    "global_variable = 'pr'\n",
    "name_variable = 'precipitation'\n",
    "\n",
    "temporal_resolution = 'daily'\n",
    "\n",
    "y_start = 1950\n",
    "y_end = 2014\n",
    "\n",
    "# wind register at 10 m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fe416",
   "metadata": {},
   "source": [
    "# Functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9510fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4 as nc#not directly used but needs to be imported for some nc4 files manipulations, use for nc files\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import datetime # to have actual date\n",
    "import os\n",
    "import os.path\n",
    "import cdsapi # for copernicus function\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3262e08",
   "metadata": {},
   "source": [
    "# Out path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead08c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path=r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53516663",
   "metadata": {},
   "source": [
    "# Project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2fba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_projects = np.array(['WTP_Mutua_EIB', 'Gorongosa_EIB', 'Chimoio_WTP_EIB', 'Pemba_EIB'])\n",
    "\n",
    "lon_projects_data = np.array([34.5927839939706, 34.07824286310398 , 33.47333313659342, 40.52545156033736])\n",
    "lon_projects = pd.Series(lon_projects_data)\n",
    "\n",
    "lat_projects_data = np.array([-19.495079648575242, -18.68063728746643, -19.125095255188334,-12.973942656747809])\n",
    "lat_projects = pd.Series(lat_projects_data)\n",
    "buffer_area_project=2\n",
    "area_projects = [lat_projects - buffer_area_project, lat_projects+buffer_area_project, lon_projects-buffer_area_project,lon_projects+buffer_area_project] # list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01ba81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.495079648575242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_projects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3f294",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e29fa6",
   "metadata": {},
   "source": [
    "### Calendar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d6a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to define parameter of time that remain constant durinf the whole script\n",
    "class calendar:\n",
    "    default_month = [ \n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                ]\n",
    "    default_day = [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                '13', '14', '15',\n",
    "                '16', '17', '18',\n",
    "                '19', '20', '21',\n",
    "                '22', '23', '24',\n",
    "                '25', '26', '27',\n",
    "                '28', '29', '30',\n",
    "                '31',\n",
    "                ]\n",
    "    #actual_date = datetime.date.today()\n",
    "    #actual_year = actual_date.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c5e67",
   "metadata": {},
   "source": [
    "### Copernicus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f79fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of tuples that will be useful to search which data are available or not\n",
    "# make it tuples to make unchangeable\n",
    "class copernicus_elements:\n",
    "    # there is 58 models\n",
    "    models =('access_cm2','awi_cm_1_1_mr','bcc_csm2_mr','cams_csm1_0','canesm5_canoe','cesm2_fv2','cesm2_waccm_fv2','cmcc_cm2_hr4','cmcc_esm2','cnrm_cm6_1_hr','e3sm_1_0','e3sm_1_1_eca','ec_earth3_aerchem','ec_earth3_veg','fgoals_f3_l','fio_esm_2_0','giss_e2_1_g','hadgem3_gc31_ll','iitm_esm','inm_cm5_0','ipsl_cm6a_lr','kiost_esm','miroc6','miroc_es2l','mpi_esm1_2_hr','mri_esm2_0','norcpm1','noresm2_mm','taiesm1','access_esm1_5','awi_esm_1_1_lr','bcc_esm1','canesm5','cesm2','cesm2_waccm','ciesm','cmcc_cm2_sr5','cnrm_cm6_1','cnrm_esm2_1','e3sm_1_1','ec_earth3','ec_earth3_cc','ec_earth3_veg_lr','fgoals_g3','gfdl_esm4','giss_e2_1_h','hadgem3_gc31_mm','inm_cm4_8','ipsl_cm5a2_inca','kace_1_0_g','mcm_ua_1_0','miroc_es2h','mpi_esm_1_2_ham','mpi_esm1_2_lr','nesm3','noresm2_lm','sam0_unicon','ukesm1_0_ll')\n",
    "    experiments = ('ssp1_1_9','ssp1_2_6','ssp4_3_4','ssp5_3_4os','ssp2_4_5','ssp4_6_0','ssp3_7_0','ssp5_8_5')\n",
    "    #'ssp1_1_9',\n",
    "    experiments_historical=('historical',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c51b12",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee148fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separer la fonciton qui download de celle qui fait les files ?? Comme ca possible de choisir closest lat et lon avec fichier existant,\n",
    "# ou bien laisser comme ca mais trouver un momyen pour que ca run pas a chaque fois, ca doit runner une fois pour chaque projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bec7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Register data from nc file of Copernicus ############################################\n",
    "# Aim of the function: this function aims to register in a dataframe and a csv file the data from the nc file downloaded with\n",
    "# the function copernicus_data\n",
    "# Actions of this function\n",
    "#     1) Create the string indicating the period of interest\n",
    "#     2) Creating path and file name to register dataframe in csv file\n",
    "#     3) Register data, with its corresponding experiments and models, in dataframe and csv file\n",
    "#        3 a) Test if path does not exists (if dataframe is not registered) : \n",
    "#                1 . Thanks to copernicus_data, download nc fils from copernicus CMIP6 website for each experiment and each model\n",
    "#                2 . Open the dowloaded nc file in the jupyter notebook if it exists\n",
    "#                3 . In a dataframe, register the value in the nc file, for each experiment, model and day\n",
    "#                4 . If there no value for each experiments and models tested, the datfram is empty and the user is informed\n",
    "#        3 b) Test if path exists (dataframe is registered) : no need to register again, return in dataframe the existing \n",
    "#             csv file in a dataframe\n",
    "\n",
    "# Parameters of the function\n",
    "# temporal_resolution: 'daily', 'monthly', or 'fixed'. String type \n",
    "# year_str: list containing all the years under the string type and in the period of interest\n",
    "# experiments: copernicus_elements.experiments\n",
    "# models: copernicus_elements.models\n",
    "# out_path: path were the outputs are registered. Defined by the user at the beginning of the code \n",
    "# global_variable: global name of the climate variable of interest (example: Wind)\n",
    "# name_variable: name of the elements downloaded from copernicus (example: 'near_surface_wind_speed')\n",
    "# name_project: Name of the project for which the data are taken\n",
    "# area: list containing latitudes and logitudes around the project\n",
    "\n",
    "def csv_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_projects,area,lat_projects,lon_projects,source):    \n",
    "    ### PROBLEM WITH DATES, CAN T just pass one year. year str is a list, so if one year (2020,)\n",
    "    ## PROBLEM WITH PATH: not coherent between data csv, datasets, download. And not achieving to have project name in path for dataset\n",
    "    ## maybe the name for dataset is too long, but even if end at name project, does not work. Try doing one string with name project in it\n",
    "    ## PROBLEM WITH PATH: WORK BUT NOT IDEAL\n",
    "    ## pourquoi mettre toutes les donnees dans un dataframe ?? permet d'avoir cette organisation en multiindex. Sinon, on ne peut pas faire ca\n",
    "    df_final = []\n",
    "    \n",
    "    # create string for name of folder depending on type of period\n",
    "    if temporal_resolution == 'fixed':\n",
    "        period = 'fixed'\n",
    "    else:\n",
    "        period=year_str[0]+'-'+year_str[len(year_str)-1]\n",
    "    \n",
    "    (dates, index_dates)=date_copernicus(temporal_resolution,year_str) # create time vector depending on temporal resolution\n",
    "    \n",
    "    k = 0 # to find closest latitude and longitude for each project, without making the loop for each, ssp, each model, year and project\n",
    "    i = 0 # to have indexes of projects    \n",
    "        \n",
    "    for name_project in name_projects:\n",
    "        print('############################### Project name: '+name_project+' ###############################')\n",
    "        \n",
    "        # modification on name_project str to ensure no problem whent using this str as name of a folder\n",
    "        name_project = name_project.replace('-','_') # take off every blank space of project names\n",
    "        name_project = name_project.replace('/','_') # take off every / of project names\n",
    "        name_project = name_project.replace(r'\"\\\"','_') # take off every \\ of project names\n",
    "        # brackets shouldn't be a problem for name projects\n",
    "\n",
    "        title_file = name_project +'_' +period+ '_' + temporal_resolution + '_' +name_variable+'.csv'\n",
    "\n",
    "        path_for_csv = os.path.join(out_path,'csv',source,name_variable,name_project,period) # create path for csv file\n",
    "\n",
    "        if not os.path.isdir(path_for_csv): # test if the data were already downloaded; if not, first part if the if is applied\n",
    "            os.makedirs(path_for_csv) # to ensure the creation of the path\n",
    "            # the dataframe_copernicus functions aims to test if the data with the specific parameters exists (with copernicus_data)\n",
    "            # and then produce a csv file if the data exists\n",
    "            if k == 0:\n",
    "                (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)=dataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,[area[0][k],area[1][k],area[2][k],area[3][k]],lat_projects[k],lon_projects[k],period,index_dates,dates,path_for_csv,title_file,source,k,i)\n",
    "            if k ==1:\n",
    "                (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)=dataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,[area[0][k],area[1][k],area[2][k],area[3][k]],lat_projects[k],lon_projects[k],period,index_dates,dates,path_for_csv,title_file,source,k,i,index_closest_lat_d=index_closest_lat,index_closest_lon_d=index_closest_lon,closest_value_lat_d=closest_value_lat,closest_value_lon_d=closest_value_lon)\n",
    "                \n",
    "            #return df\n",
    "        else:# test if the data were already downloaded; if yes, this part of the if is applied\n",
    "            if len(os.listdir(path_for_csv)) == 0: #test if the directory is empty\n",
    "                # the csv file does not exist, even if the path exist\n",
    "                # the dataframe_copernicus functions aims to test if the data with the specific parameters exists (with copernicus_data)\n",
    "                # and then produce a csv file if the data exists\n",
    "                if k == 0:\n",
    "                    (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)=dataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,[area[0][k],area[1][k],area[2][k],area[3][k]],lat_projects[k],lon_projects[k],period,index_dates,dates,path_for_csv,title_file,source,k,i)\n",
    "                    \n",
    "                if k == 1:\n",
    "                    (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)=dataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,[area[0][k],area[1][k],area[2][k],area[3][k]],lat_projects[k],lon_projects[k],period,index_dates,dates,path_for_csv,title_file,source,k,i,index_closest_lat_d=index_closest_lat,index_closest_lon_d=index_closest_lon,closest_value_lat_d=closest_value_lat,closest_value_lon_d=closest_value_lon)\n",
    "            else: # the directory is not empty\n",
    "                df=file_already_downloaded(path_for_csv,title_file,name_variable)\n",
    "                \n",
    "        #df_final = pd.concat([df_final,df])\n",
    "        i+=1 # iterate indexes projects\n",
    "\n",
    "    return df#df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa0a2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe_copernicus functions aims to test if the data with the specific parameters exists (with copernicus_data)\n",
    "# and then produce a csv file if the data exists\n",
    "\n",
    "def dataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,area,lat_project,lon_project,period,index_dates,dates,path_for_csv,title_file,source,k,i,index_closest_lat_d=[],index_closest_lon_d=[],closest_value_lat_d=[],closest_value_lon_d=[]):    \n",
    "    print('FUNCTION DATAFRAME_COPERNICUS')\n",
    "    print('k = '+str(k))\n",
    "    df = pd.DataFrame() # create an empty dataframe\n",
    "    for SSP in experiments:\n",
    "        experiment = (SSP,) # create tuple for iteration of dataframe\n",
    "        print('Test with scenario '+SSP)\n",
    "        for model_simulation in models:\n",
    "            model =(model_simulation,) # create tuple for iteration of dataframe\n",
    "            print('Test with model '+model_simulation)\n",
    "            # path were the futur downloaded file is registered\n",
    "            path_for_file= os.path.join(out_path,name_variable,name_project,SSP,model_simulation,period)\n",
    "            # existence of path_for_file tested in copernicus function\n",
    "            climate_variable_path=copernicus_data(temporal_resolution,SSP,name_variable,model_simulation,year_str,area,path_for_file,out_path,name_project,source)\n",
    "            # area is determined in the \"Load shapefiles and plot\" part\n",
    "            if (climate_variable_path is not None):\n",
    "                if k == 0:\n",
    "                    # enter here only one time\n",
    "                    print('suppose to enter once')\n",
    "                    (index_closest_lat_d,index_closest_lon_d,closest_value_lat_d,closest_value_lon_d)=_lat_lon(climate_variable_path,lat_projects,lon_projects)\n",
    "\n",
    "                    print('\\nindex_closest_lat')\n",
    "                    print(index_closest_lat_d)                    \n",
    "                    print('\\nlen(index_closest_lat)')\n",
    "                    print(len(index_closest_lat_d))\n",
    "                    \n",
    "                    print('\\nindex_closest_lon')\n",
    "                    print(index_closest_lon_d)\n",
    "                    print('\\nlen(index_closest_lon)')\n",
    "                    print(len(index_closest_lon_d))\n",
    "                    \n",
    "                    print('\\nclosest_value_lat')\n",
    "                    print(closest_value_lat_d)                        \n",
    "                    print('\\nlen(closest_value_lat)')\n",
    "                    print(len(closest_value_lat_d))\n",
    "                    \n",
    "                    print('\\nclosest_value_lon')\n",
    "                    print(closest_value_lon_d)                    \n",
    "                    print('\\nlen(closest_value_lon)')\n",
    "                    print(len(closest_value_lon_d))\n",
    "                    #k = 1 # then, k is not equal to zero, so will not enter in this loop anymore\n",
    "                # register data concerning each project under the form of a csv, with the model, scenario, period, latitude and longitude\n",
    "                print('i = '+str(i))\n",
    "                print('k = '+str(k))\n",
    "                print('start register data')\n",
    "                df=register_data(climate_variable_path,name_project,name_variable,index_dates,dates,experiment,model,index_closest_lat_d,index_closest_lon_d,closest_value_lat_d,closest_value_lon_d,df,i)\n",
    "                print('\\nValue were found for the period and the project tested\\n')\n",
    "            else:\n",
    "                print('\\nNo value were found for the period and the project tested\\n')\n",
    "                continue # do the next for loop\n",
    "        # test if dataframe is empty, if values exist for this period\n",
    "    if not df.empty: # if dataframe is not empty, value were registered, the first part is run : a path to register the csv file is created, and the dataframe is registered in a csv file\n",
    "        full_name = os.path.join(path_for_csv,title_file)\n",
    "        print(full_name)\n",
    "        df.to_csv(full_name) # register dataframe in csv file\n",
    "        return (df,k,index_closest_lat_d,index_closest_lon_d,closest_value_lat_d,closest_value_lon_d)\n",
    "    else: # if the dataframe is empty, no value were found, there is no value to register or to return\n",
    "        #os.remove(path_for_file)# remove path\n",
    "        return (df,k,index_closest_lat_d,index_closest_lon_d,closest_value_lat_d,closest_value_lon_d)# no df to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f7ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register data concerning each project under the form of a csv, with the model, scenario, period, latitude and longitude\n",
    "def register_data(climate_variable_path,name_project,name_variable,index_dates,dates,experiment,model,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon,df,i):\n",
    "    print('Registering the data in a dataframe')\n",
    "    #Open_path = Dataset(climate_variable_path) # open netcdf file\n",
    "    #lat_dataframe = np.ma.getdata(Open_path.variables['lat']).data\n",
    "    #lon_dataframe = np.ma.getdata(Open_path.variables['lon']).data\n",
    "    #column_name = find_column_name(Open_path)\n",
    "    #data_with_all = ma.getdata(Open_path.variables[column_name]).data\n",
    "    \n",
    "    ds = xr.open_dataset(climate_variable_path)\n",
    "    r'''\n",
    "    for moment in index_dates: # case if temporal resolution is daily\n",
    "        data_dataframe = ds.variables[global_variable].isel(time=moment,lat=index_closest_lat[i],lon=index_closest_lon[i]) # data_with_all[moment,:,:]\n",
    "        Date = (dates[moment],) # create tuple for iteration of dataframe\n",
    "        Name_Project = (name_project,)\n",
    "\n",
    "        # Create the MultiIndex\n",
    "        midx = pd.MultiIndex.from_product([Name_Project,closest_value_lat[i],closest_value_lon[i],experiment, model, Date],names=['Name project', 'Latitude', 'Longitude','Experiment', 'Model', 'Date'])\n",
    "        # multiindex to name the columns\n",
    "        cols_str = [name_variable]\n",
    "        #cols = pd.MultiIndex.from_product([lon_str,lon_dataframe])\n",
    "        # Create the Dataframe\n",
    "        Variable_dataframe = pd.DataFrame(data = data_dataframe, \n",
    "                                    index = midx,\n",
    "                                    columns = cols_str)\n",
    "        Variable_dataframe\n",
    "        # Concatenate former and new dataframe\n",
    "        df = pd.concat([df,Variable_dataframe])# register information for project\n",
    "    '''\n",
    "    conversion_factor = 1\n",
    "    if global_variable =='pr':\n",
    "        conversion_factor = 86400\n",
    "        # convert precipitation data from kg.m^(-2).s^(-1) to mm/day :  1 kg/m2/s = 86400 mm/day\n",
    "    data_dataframe = ds.variables[global_variable].isel(lat=index_closest_lat[i],lon=index_closest_lon[i]).values*conversion_factor # data_with_all[moment,:,:]\n",
    "    # missing 29.02 ?\n",
    "    if len(ds.variables['time'].values)<len(index_dates):\n",
    "        max(ds.indexes['time'].year)\n",
    "        \n",
    "        max(ds.indexes['time'].day)\n",
    "            # yes, missing 29.02\n",
    "            for j in np.where((dates.month == 2) & (dates.day ==29))[0]:\n",
    "                data_dataframe=np.insert(data_dataframe,j,np.nan)\n",
    "    Date = dates.tolist() # create tuple for iteration of dataframe\n",
    "    Name_Project = (name_project,)\n",
    "    \n",
    "    print('\\ni = '+ str(i))\n",
    "    print('\\nclosest_value_lat[i]'+str(closest_value_lat[i]))\n",
    "    print('\\ntype(closest_value_lat[i])'+str(type(closest_value_lat[i])))\n",
    "    \n",
    "    # Create the MultiIndex\n",
    "    midx = pd.MultiIndex.from_product([Name_Project,(closest_value_lat[i],),(closest_value_lon[i],),experiment, model, Date],names=['Name project', 'Latitude', 'Longitude','Experiment', 'Model', 'Date'])\n",
    "    # multiindex to name the columns\n",
    "    cols_str = [name_variable]\n",
    "    #cols = pd.MultiIndex.from_product([lon_str,lon_dataframe])\n",
    "    # Create the Dataframe\n",
    "    Variable_dataframe = pd.DataFrame(data = data_dataframe, \n",
    "                                index = midx,\n",
    "                                columns = cols_str)\n",
    "    Variable_dataframe\n",
    "    # Concatenate former and new dataframe\n",
    "    df = pd.concat([df,Variable_dataframe])# register information for project\n",
    "    \n",
    "    ds.close() # to spare memory\n",
    "    #Open_path.close # to spare memory\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8778598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return column name in the netCDF file\n",
    "# all netCDF file form copernicus have this format for their variables names\n",
    "# ['time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds', Name of climate variable of interest]\n",
    "# take of 'time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds'\n",
    "def find_column_name(Open_path):\n",
    "    # make a list with every variables of the netCDF file of interest\n",
    "    climate_variable_variables=list(Open_path.variables)\n",
    "    # variables that are not the column name of interest \n",
    "    elements_not_climate_var =['time', 'time_bnds', 'bnds','lat', 'lat_bnds', 'lon', 'lon_bnds','time_bounds','bounds','lat_bounds','lon_bounds','height']\n",
    "    for str in elements_not_climate_var:\n",
    "        if str in climate_variable_variables:\n",
    "            climate_variable_variables.remove(str)\n",
    "    return climate_variable_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b868265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_already_downloaded(path_for_csv,title_file,name_variable):\n",
    "    print('The file was already downloaded')\n",
    "    df = pd.read_csv(os.path.join(path_for_csv,title_file)) # read the downloaded data for the analysis\n",
    "\n",
    "    # changing name of columns\n",
    "    name_columns=df.iloc[0].array\n",
    "    df.rename(columns={'Unnamed: 0':'Experiment','Unnamed: 1':'Model','Unnamed: 2':'Date','Unnamed: 3':'Latitude'}, inplace=True)\n",
    "\n",
    "    lon_dataframe=name_columns[4:len(name_columns)] # register data for columns of multiindex\n",
    "\n",
    "    df.drop([0,1], axis=0,inplace=True) # remove 2 first lines\n",
    "\n",
    "    # recreate multiindex \n",
    "\n",
    "    # .... with columns\n",
    "    df.set_index(['Name project', 'Latitude', 'Longitude','Experiment', 'Model', 'Date'],inplace=True)\n",
    "\n",
    "    # .... with lines\n",
    "\n",
    "    cols_str = [name_variable]\n",
    "    df.columns=cols_str\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b28d2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Period for copernicus function ################################################\n",
    "# Aim of the function: by giving it a first and last year of the period that must analyzed, this function produce several \n",
    "# vectors,containing time informations, useful to download and treat data from CMIP6 projections (https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=overview )\n",
    "# Those time vectors are used in the copernicus_data and the dataframe_copernicus and csv_copernicus functions\n",
    "\n",
    "# function year_copernicus produce \n",
    "# year: a vector containing all the year in the period of interest\n",
    "# year_str: an array containing all the year in the period of interest in the string format\n",
    "# index: an array containing the index of the year and year_str\n",
    "#### Parameters of the function\n",
    "# first_year: number in int format, of the first year of the period of interest\n",
    "# last_year: number in int format, of the last year of the period of interest\n",
    "def year_copernicus(first_year,last_year):\n",
    "    year = np.arange(first_year,(last_year+1),1) # create vector of years\n",
    "    year_str = [0]*len(year) # create initiale empty vector to convert years in int\n",
    "    index = np.arange(0,len(year)) # create vector of index for year\n",
    "    i = 0 # initialize index\n",
    "    for i in index: # convert all the date in string format\n",
    "        year_str[i]=str(year[i])\n",
    "    return (year, year_str, index)\n",
    "\n",
    "# function date_copernicus produce \n",
    "# dates: the format depend on the temporal reolution, but always contain the dates of the period of interest.\n",
    "#        with temporal_resolution=daily, dates is a DatetimeIndex\n",
    "#        with temporal_resolution=monthly, dates is a list\n",
    "# index_dates: an array containing the index of the dates\n",
    "#### Parameters of the function\n",
    "# temporal_resolution: daily or monthly\n",
    "# year_str: ???? produce by function year_copernicus, containing the year of the period of interest in string format\n",
    "def date_copernicus(temporal_resolution,year_str):\n",
    "    start_date = \"01-01-\"+year_str[0] # string start date based on start year\n",
    "    stop_date = \"31-12-\"+year_str[len(year_str)-1] # string stop date based on stop year\n",
    "    if temporal_resolution =='daily':\n",
    "        # vector of dates between start date and stop date\n",
    "        dates = pd.date_range(start_date,stop_date)# dates is a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "        # By default, freq = 'D', which means calendar day frequency (source : https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "        #index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    if temporal_resolution =='monthly':\n",
    "        dates = pd.date_range(start_date,stop_date,freq='MS') # vector of dates between start date and stop date\n",
    "        dates=list(dates.strftime('%m-%Y')) # dates is an pandas.core.indexes.base.Index, not a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "    #if temporal_resolution =='fixed': trouver donnees pour gerer cela\n",
    "    index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    return (dates, index_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6334e78a",
   "metadata": {},
   "source": [
    "### Copernicus function\n",
    "Some data comes from copernicus and can be directly taken form the website thans to CDS. The following functions serves this purpose\n",
    "#### Parameters of the function :\n",
    "projections-cmip6 : name of the web page, in this case, 'projections-cmip6'\n",
    "format : zip or tar.gz\n",
    "temporal_resolution : daily or monthly or fixed\n",
    "SSP : sscenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "Variable : variable to be studied\n",
    "model: model of projection to choose\n",
    "year: year of study to choose\n",
    "area: area of study\n",
    "month: month to be studied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350b5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Copernicus data function ###################################################\n",
    "# Aim of the function : read nc data found on copernicus CMIP6 projections (https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=overview )\n",
    "# Actions of this function\n",
    "#     1) check which parameters are asked or not in the variables dictionnary, and modify the last depend on the parameters \n",
    "#        chosen by the user before\n",
    "#     2) All this step is done in function try_download_copernicus: thanks to c.retrieve function and the variables dictionnary, \n",
    "#        the chosen data are download in zip format, dezipped and registered in a specific folder. \n",
    "#     3) the function looks in the specific folder for a nc format file, and once found, return the path of this nc format file\n",
    "\n",
    "#### Parameters of the function\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : sscenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# year: year(s) of study to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# out_path: path were all the outputs are registered, defined by the user in the begining of the main code\n",
    "# name_area : to specify if we are only looking data for a project or for a wider zone\n",
    "\n",
    "def copernicus_data(temporal_resolution,SSP,name_variable,model,year,area,path_for_file,out_path,name_area,source): \n",
    "    # create path for the downloaded file\n",
    "    start_path = os.path.join(out_path,'Data_download_zip')\n",
    "    file_download=create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source)\n",
    "    \n",
    "    if not os.path.isdir(path_for_file):\n",
    "        print('path_for_file does not exist: the data may not have been downloaded') \n",
    "        if not os.path.isdir(file_download):\n",
    "            print('file_download does not exist: the data were not downloaded')\n",
    "            # function try to download from copernicus\n",
    "            final_path = download_data(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "            return final_path\n",
    "            \n",
    "        else: # if the path already exist, the data in zip format should also exists\n",
    "            if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                print('The path for the download file exists, but is empty')\n",
    "                # function try to download from copernicus\n",
    "                final_path = download_data(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                return final_path\n",
    "            else:\n",
    "                print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                final_path=download_extract(path_for_file,file_download,source)\n",
    "                final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "                return final_path\n",
    "                \n",
    "    else: # the path for the file exists\n",
    "        if not os.listdir(path_for_file): # if the path is empty\n",
    "            if not os.path.isdir(file_download):\n",
    "                print('file_download does not exist: the data were not downloaded')\n",
    "                # function try to download from copernicus\n",
    "                final_path = download_data(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                return final_path\n",
    "\n",
    "            else: # if the path already exist, the data in zip format should also exists\n",
    "                if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                    print('The path for the download file exists, but is empty')\n",
    "                    # function try to download from copernicus\n",
    "                    final_path = download_data(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                    return final_path\n",
    "                else:\n",
    "                    print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                    final_path=download_extract(path_for_file,file_download,source)\n",
    "                    final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "                    return final_path\n",
    "        \n",
    "        else: # if the path is not empty\n",
    "            path_file=os.path.join(path_for_file,source)# data was added because of a problem during downloading\n",
    "            final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "            if final_path is None: # if no nc file exists, need to check again if the file with those parameters exists\n",
    "                test= os.path.join(file_download,source,'download.zip')\n",
    "                if not os.path.join(test):# the file was not downloaded \n",
    "                    final_path = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                else: # the file was already downloaded but not not extracted\n",
    "                    final_path=download_extract(path_for_file,file_download,source)\n",
    "                final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "            return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ccafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source):\n",
    "    path_file = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "    if path_file is None: # for this climate variable, the parameter do not fit\n",
    "        return path_file\n",
    "    final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "    print('\\n')\n",
    "    print('---------------  Path to nc file exists ?? ---------------\\n')\n",
    "    print(os.path.isfile(final_path))\n",
    "    print('\\n')\n",
    "    return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45837cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Copernicus data function ###################################################\n",
    "# Aim of the function : read nc data found on copernicus CMIP6 projections (https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=overview )\n",
    "# Actions of this function\n",
    "#     1) check which parameters are asked or not in the variables dictionnary, and modify the last depend on the parameters \n",
    "#        chosen by the user before\n",
    "#     2) All this step is done in function try_download_copernicus: thanks to c.retrieve function and the variables dictionnary, \n",
    "#        the chosen data are download in zip format, dezipped and registered in a specific folder. \n",
    "#     3) the function looks in the specific folder for a nc format file, and once found, return the path of this nc format file\n",
    "\n",
    "#### Parameters of the function\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : sscenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# year: year(s) of study to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# out_path: path were all the outputs are registered, defined by the user in the begining of the main code\n",
    "# name_area : to specify if we are only looking data for a project or for a wider zone\n",
    "\n",
    "def copernicus_data_former(temporal_resolution,SSP,name_variable,model,year,area,path_for_file,out_path,name_area,source): \n",
    "    # create path for the downloaded file\n",
    "    start_path = os.path.join(out_path,'Data_download_zip')\n",
    "    file_download=create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source) \n",
    "    # file_download does not have name of the download file, just the path\n",
    "    if not os.path.isdir(path_for_file):\n",
    "        print('path_for_file does not exist: the data may not have been downloaded') \n",
    "        if not os.path.isdir(file_download):\n",
    "            print('file_download does not exist: the data were not downloaded')\n",
    "            # function try to download from copernicus\n",
    "            path_file = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "            if path_file is None: # for this climate variable, the parameter do not fit\n",
    "                return path_file\n",
    "            final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "            print('\\n')\n",
    "            print('---------------  Path to nc file exists ?? ---------------\\n')\n",
    "            print(os.path.isfile(final_path))\n",
    "            print('\\n')\n",
    "            return final_path\n",
    "            \n",
    "        else: # if the path already exist, the data in zip format should also exists\n",
    "            if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                print('The path for the download file exists, but is empty')\n",
    "                # function try to download from copernicus\n",
    "                path_file = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                if path_file is None: # for this climate variable, the parameter do not fit\n",
    "                    return path_file\n",
    "                final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "                print('\\n')\n",
    "                print('---------------  Path to nc file exists ?? ---------------\\n')\n",
    "                print(os.path.isfile(final_path))\n",
    "                print('\\n')\n",
    "                return final_path\n",
    "            else:\n",
    "                print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                #path_file=os.path.join(path_for_file,source)# source was added because of a problem during downloading\n",
    "                final_path=download_extract(path_for_file,file_download,source)\n",
    "                #final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "                #if final_path is None:# if no nc file exists, need to check again if the file with those parameters exists\n",
    "                #    final_path = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "                return final_path\n",
    "                \n",
    "    else: # the path for the file exists\n",
    "        if not os.listdir(path_for_file): # if the path is empty\n",
    "            final_path=download_extract(path_for_file,file_download,source)\n",
    "            final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "        \n",
    "        \n",
    "        else: # if the path is not empty\n",
    "            path_file=os.path.join(path_for_file,source)# data was added because of a problem during downloading\n",
    "            final_path=search_for_nc(path_file) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "            if final_path is None: # if no nc file exists, need to check again if the file with those parameters exists\n",
    "                test= os.path.join(file_download,source,'download.zip')\n",
    "                if not os.path.join(test):# the file was not downloaded \n",
    "                    final_path = try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source)\n",
    "                else: # the file was already downloaded but not not extracted\n",
    "                    final_path=download_extract(path_for_file,file_download,source)\n",
    "                final_path = search_for_nc(final_path) # looking for the netCDF file in format .nc and look if path length is a problem at the same time\n",
    "            return final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c6d6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,source):\n",
    "    c = cdsapi.Client()# function to use the c.retrieve\n",
    "    # basic needed dictionnary to give to the c.retrieve function the parameters asked by the user\n",
    "    variables = {\n",
    "                'format': 'zip', # this function is only designed to download and unzip zip files\n",
    "                'temporal_resolution': temporal_resolution,\n",
    "                'experiment': SSP,\n",
    "                'variable': name_variable,\n",
    "                'model': model,\n",
    "    }\n",
    "\n",
    "    if area != []: # the user is interested by a sub region and not the whole region \n",
    "        variables.update({'area':area}) \n",
    "\n",
    "    if name_variable == 'air_temperature':\n",
    "        variables['level'] = '1000' # [hPa], value of the standard pressure at sea level is 1013.25 [hPa], so 1000 [hPa] is the neareste value. Other pressure value are available but there is no interest for the aim of this project\n",
    "\n",
    "    if temporal_resolution != 'fixed':# if 'fixed', no year, month, date to choose\n",
    "        variables['year']=year # period chosen by the user\n",
    "        variables['month']= calendar.default_month  # be default, all the months are given; defined in class calendar\n",
    "        if temporal_resolution == 'daily':\n",
    "            variables['day']= calendar.default_day # be default, all the days are given; defined in class calendar\n",
    "    # c.retrieve download the data from the website\n",
    "    try:\n",
    "        c.retrieve(\n",
    "            'projections-cmip6',\n",
    "            variables,\n",
    "            'download.zip') # the file in a zip format is registered in the current directory\n",
    "    except:\n",
    "        print('Some parameters are not matching')\n",
    "        return # stop the function, because some data the user entered are not matching\n",
    "    print('The file has been download')\n",
    "    # function to extract the downloaded zip\n",
    "    path_file=download_extract(path_for_file,file_download,source)\n",
    "    print('The file has been extracted')\n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4958584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_extract functions aims to return the path were the downloaded file in zip format is extracted\n",
    "\n",
    "def download_extract(path_for_file,file_download,source):\n",
    "    if not os.path.isdir(path_for_file): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(path_for_file) # to ensure the creation of the path\n",
    "        print('Path for the file is created, did not existed before')\n",
    "    # unzip the downloaded file\n",
    "    if 'download.zip' not in os.listdir(): # check if download is in the working directory\n",
    "        print('The download zip is moved to the working directory')\n",
    "        path_downloaded_zip=os.path.join(file_download,'download.zip')\n",
    "        shutil.move(path_downloaded_zip,r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool') # move download fil to working directory\n",
    "    \n",
    "    from zipfile import ZipFile\n",
    "    zf = ZipFile('download.zip', 'r')\n",
    "    zf.extractall(source) # if no precision of directory, extract in current directory\n",
    "    zf.close()\n",
    "\n",
    "    if not os.path.isdir(file_download): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(file_download) # to ensure the creation of the path\n",
    "    # moving download to appropriate place\n",
    "    #test = os.path.join(file_download,'download.zip')\n",
    "    #if not os.path.isfile(test):\n",
    "    shutil.move('download.zip',file_download) # no need to delete 'download.zip' from inital place\n",
    "    #test = os.path.join(path_for_file,source)\n",
    "    #if not os.path.isdir(test):\n",
    "    shutil.move(source,path_for_file) # move extracted data to the path created for them\n",
    "    path_file=os.path.join(path_for_file,source)\n",
    "    print('\\n The downloaded file is extracted')\n",
    "    return path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d383cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seach_for_nc is a function looking in path_for_file for a document in .nc format\n",
    "\n",
    "def search_for_nc(path_for_file):\n",
    "    print('path_for_file does exist Function copernicus search for nc')\n",
    "    for file in os.listdir(path_for_file):\n",
    "        if file.endswith(\".nc\"):\n",
    "            final_path=os.path.join(path_for_file, file)\n",
    "            \n",
    "            print('The file is in the path Function copernicus search for nc\\n')\n",
    "            print('Before path_length, The final path for the nc file is: '+final_path)\n",
    "            answer = str(os.path.isfile(final_path))\n",
    "            print('\\n The final path for nc file exists ? '+answer+'\\n')\n",
    "            final_path=path_length(final_path) # check if length of path is too long\n",
    "            print('After path_length, The final path for the nc file is: '+final_path)\n",
    "            answer = str(os.path.isfile(final_path))\n",
    "            print('\\n The final path for nc file exists ? '+answer+'\\n')\n",
    "            return final_path # the function returns the path of the nc file of interest\n",
    "            break # stop the function if a nc file was found \n",
    "        else:\n",
    "            pass\n",
    "    # the all folder has been search and there is no nc file in it\n",
    "    print('Problem : No nc file was found Function copernicus Function copernicus search for nc')# this line is out of the for loop, \n",
    "    #because it should only appear once all the folder has been examinated and if the break of the if was not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0cdf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions test if the path is too long\n",
    "# if the path is more than 250 char, the path wll be modified in order for windows to accept is as a path\n",
    "\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1770731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create path for the downloaded file\n",
    "def create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source):\n",
    "    # adapt the name of the folder fot the period, depending on the type of period\n",
    "    if len(year)==1:\n",
    "        file_download = os.path.join(start_path,name_variable,name_area,SSP,model,year,source)\n",
    "    elif len(year)>1:\n",
    "        period=year[0]+'-'+year[len(year)-1]\n",
    "        file_download = os.path.join(start_path,name_variable,name_area,SSP,model,period,source)\n",
    "    elif temporal_resolution == 'fixed':\n",
    "        file_download = os.path.join(start_path,name_variable,name_area,SSP,model,'fixed_period',source)\n",
    "    return file_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "592b5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify index of latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44d4dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_extract# this functions aims to return the closest latitudes and longitudes to the projects, and the respectives index \n",
    "#  in the lat and lon vectors of the file\n",
    "def _lat_lon(path,lat_projects,lon_projects):\n",
    "    ds =  xr.open_dataset(path) \n",
    "    # ds.indexes['time'] gives back CFTimeIndex format, with hours. The strftime('%d-%m-%Y') permits to have time \n",
    "    # as an index, with format '%d-%m-%Y'. The .values permits to have an array\n",
    "    lat  = ds.lat.values\n",
    "    lon  = ds.lon.values\n",
    "    ds.close() # to spare memory\n",
    "    # preallocate space for the future vectors\n",
    "    index_closest_lat = []\n",
    "    index_closest_lon = []\n",
    "    closest_value_lat = []\n",
    "    closest_value_lon = []\n",
    "    for j in np.arange(0,len(lat_projects)):\n",
    "        (A,B)=closest_lat_lon_to_proj(lat_projects[j],lat)\n",
    "        #return lat,lat_projects[j]\n",
    "        index_closest_lat.append(A[0])\n",
    "        closest_value_lat.append(B[0])\n",
    "        (C,D)=closest_lat_lon_to_proj(lon_projects[j],lon)\n",
    "        index_closest_lon.append(C[0])\n",
    "        closest_value_lon.append(D[0])\n",
    "    return index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon\n",
    "\n",
    "\n",
    "# this function aims to select the closest point to the geographical point of the project\n",
    "# the function takes as input \n",
    "#     location_project, which is a numpy.float64\n",
    "#     vector, which is a numpy.ndarray\n",
    "# the function returns\n",
    "#     closest_value[0], a numpy.float64\n",
    "\n",
    "def closest_lat_lon_to_proj(location_project,vector):\n",
    "    # the function any() returns a boolean value. Here, the function test if there are elements in the array \n",
    "    # containing the difference between the vector and the location_project, equal to the minimum of the absolute \n",
    "    # value of the difference between the vector and the location_project\n",
    "    if any(np.where((vector - location_project) == min(abs(vector - location_project)))[0]):\n",
    "        # the function any() returned True\n",
    "        # there is an element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    else:\n",
    "        # the function any() returned False\n",
    "        # there is NO element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == -min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == -min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    return index_closest, closest_value \n",
    "    # the function returns\n",
    "    #     first, the value of the index of the element of vector, that is the closest to location_project    \n",
    "    #     second, the array containing the element of vector, that is the closest to location_project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccff81",
   "metadata": {},
   "source": [
    "# Register copernicus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "358bee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################### Project name: WTP_Mutua_EIB ###############################\n",
      "FUNCTION DATAFRAME_COPERNICUS\n",
      "k = 0\n",
      "Test with scenario historical\n",
      "Test with model access_cm2\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\access_cm2\\1950-2014\\Copernicus-CMIP6\\pr_day_ACCESS-CM2_historical_r1i1p1f1_gn_19500101-20141231_v20191108.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\access_cm2\\1950-2014\\Copernicus-CMIP6\\pr_day_ACCESS-CM2_historical_r1i1p1f1_gn_19500101-20141231_v20191108.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[1, 2, 1, 6]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[27, 27, 26, 28]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.375, -18.125, -19.375, -13.125]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[34.6875, 34.6875, 32.8125, 36.5625]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n",
      "\n",
      "i = 0\n",
      "\n",
      "closest_value_lat[i]-19.375\n",
      "\n",
      "type(closest_value_lat[i])<class 'numpy.float64'>\n",
      "\n",
      "Value were found for the period and the project tested\n",
      "\n",
      "Test with model awi_cm_1_1_mr\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:37:27,133 INFO Welcome to the CDS\n",
      "2023-07-04 15:37:27,134 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:37:27,248 INFO Request is queued\n",
      "2023-07-04 15:37:28,283 INFO Request is failed\n",
      "2023-07-04 15:37:28,284 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-04 15:37:28,285 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'AWI-CM-1-1-MR', 'temporal_resolution': 'day', 'variable': 'pr'}\n",
      "2023-07-04 15:37:28,285 ERROR   Traceback (most recent call last):\n",
      "2023-07-04 15:37:28,286 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-04 15:37:28,286 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-04 15:37:28,287 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-04 15:37:28,287 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-04 15:37:28,289 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-04 15:37:28,289 ERROR       return p(*args, **kwargs)\n",
      "2023-07-04 15:37:28,290 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-04 15:37:28,290 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-04 15:37:28,291 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-04 15:37:28,291 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-04 15:37:28,292 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-04 15:37:28,292 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-04 15:37:28,292 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'AWI-CM-1-1-MR', 'temporal_resolution': 'day', 'variable': 'pr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "\n",
      "No value were found for the period and the project tested\n",
      "\n",
      "Test with model bcc_csm2_mr\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\bcc_csm2_mr\\1950-2014\\Copernicus-CMIP6\\pr_day_BCC-CSM2-MR_historical_r2i1p1f1_gn_19500101-20141231_v20181116.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\bcc_csm2_mr\\1950-2014\\Copernicus-CMIP6\\pr_day_BCC-CSM2-MR_historical_r2i1p1f1_gn_19500101-20141231_v20181116.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[1, 2, 1, 7]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[46, 45, 45, 47]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.62606908419931, -18.504579849136462, -19.62606908419931, -12.897132601745176]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[34.875, 33.75, 33.75, 36.0]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:37:59,915 INFO Welcome to the CDS\n",
      "2023-07-04 15:37:59,917 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:37:59,977 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i = 0\n",
      "\n",
      "closest_value_lat[i]-19.62606908419931\n",
      "\n",
      "type(closest_value_lat[i])<class 'numpy.float64'>\n",
      "\n",
      "Value were found for the period and the project tested\n",
      "\n",
      "Test with model cams_csm1_0\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:38:01,015 INFO Request is failed\n",
      "2023-07-04 15:38:01,016 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-04 15:38:01,016 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CAMS-CSM1-0', 'temporal_resolution': 'day', 'variable': 'pr'}\n",
      "2023-07-04 15:38:01,017 ERROR   Traceback (most recent call last):\n",
      "2023-07-04 15:38:01,017 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-04 15:38:01,019 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-04 15:38:01,019 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-04 15:38:01,020 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-04 15:38:01,021 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-04 15:38:01,022 ERROR       return p(*args, **kwargs)\n",
      "2023-07-04 15:38:01,023 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-04 15:38:01,024 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-04 15:38:01,024 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-04 15:38:01,025 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-04 15:38:01,025 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-04 15:38:01,026 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-04 15:38:01,026 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CAMS-CSM1-0', 'temporal_resolution': 'day', 'variable': 'pr'}\n",
      "2023-07-04 15:38:01,069 INFO Welcome to the CDS\n",
      "2023-07-04 15:38:01,069 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:38:01,126 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "\n",
      "No value were found for the period and the project tested\n",
      "\n",
      "Test with model canesm5_canoe\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:38:02,171 INFO Request is failed\n",
      "2023-07-04 15:38:02,172 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-04 15:38:02,172 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CanESM5-CanOE', 'temporal_resolution': 'day', 'variable': 'pr'}\n",
      "2023-07-04 15:38:02,173 ERROR   Traceback (most recent call last):\n",
      "2023-07-04 15:38:02,174 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-04 15:38:02,175 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-04 15:38:02,175 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-04 15:38:02,175 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-04 15:38:02,176 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-04 15:38:02,178 ERROR       return p(*args, **kwargs)\n",
      "2023-07-04 15:38:02,178 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-04 15:38:02,179 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-04 15:38:02,180 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-04 15:38:02,180 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-04 15:38:02,181 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-04 15:38:02,181 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-04 15:38:02,183 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CanESM5-CanOE', 'temporal_resolution': 'day', 'variable': 'pr'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "\n",
      "No value were found for the period and the project tested\n",
      "\n",
      "Test with model cesm2_fv2\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cesm2_fv2\\1950-2014\\Copernicus-CMIP6\\pr_day_CESM2-FV2_historical_r1i1p1f1_gn_19500101-20141231_v20191120.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cesm2_fv2\\1950-2014\\Copernicus-CMIP6\\pr_day_CESM2-FV2_historical_r1i1p1f1_gn_19500101-20141231_v20191120.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[0, 1, 0, 4]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[20, 20, 19, 20]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.89473684210526, -18.0, -19.89473684210526, -12.31578947368422]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[35.0, 35.0, 32.5, 35.0]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:38:04,416 INFO Welcome to the CDS\n",
      "2023-07-04 15:38:04,417 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i = 0\n",
      "\n",
      "closest_value_lat[i]-19.89473684210526\n",
      "\n",
      "type(closest_value_lat[i])<class 'numpy.float64'>\n",
      "\n",
      "Value were found for the period and the project tested\n",
      "\n",
      "Test with model cesm2_waccm_fv2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:38:04,486 INFO Request is queued\n",
      "2023-07-04 15:38:05,539 INFO Request is running\n",
      "2023-07-04 15:38:12,794 INFO Request is failed\n",
      "2023-07-04 15:38:12,794 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-04 15:38:12,794 ERROR Reason:  Process error: Resulting object does not have monotonic global indexes along dimension time\n",
      "2023-07-04 15:38:12,795 ERROR   Traceback (most recent call last):\n",
      "2023-07-04 15:38:12,795 ERROR     File \"/usr/local/lib/python3.6/site-packages/rooki/results.py\", line 33, in url\n",
      "2023-07-04 15:38:12,796 ERROR       return self.response.get()[0]\n",
      "2023-07-04 15:38:12,797 ERROR     File \"/usr/local/lib/python3.6/site-packages/birdy/client/outputs.py\", line 40, in get\n",
      "2023-07-04 15:38:12,798 ERROR       raise ProcessFailed(\"Sorry, process failed.\")\n",
      "2023-07-04 15:38:12,799 ERROR   birdy.exceptions.ProcessFailed: Sorry, process failed.\n",
      "2023-07-04 15:38:12,848 INFO Welcome to the CDS\n",
      "2023-07-04 15:38:12,848 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:38:12,923 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "\n",
      "No value were found for the period and the project tested\n",
      "\n",
      "Test with model cmcc_cm2_hr4\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:38:13,957 INFO Request is running\n",
      "2023-07-04 15:41:04,394 INFO Request is completed\n",
      "2023-07-04 15:41:04,395 INFO Downloading https://download-0003-clone.copernicus-climate.eu/cache-compute-0003/cache/data9/adaptor.esgf_wps.retrieve-1688478055.9662063-19665-11-65e07e45-de4f-4188-8ac4-219abb8f4030.zip to download.zip (188M)\n",
      "2023-07-04 15:41:43,479 INFO Download rate 4.8M/s                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been download\n",
      "Path for the file is created, did not existed before\n",
      "\n",
      " The downloaded file is extracted\n",
      "The file has been extracted\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cmcc_cm2_hr4\\1950-2014\\Copernicus-CMIP6\\pr_day_CMCC-CM2-HR4_historical_r1i1p1f1_gn_19500101-20141231_v20200904.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cmcc_cm2_hr4\\1950-2014\\Copernicus-CMIP6\\pr_day_CMCC-CM2-HR4_historical_r1i1p1f1_gn_19500101-20141231_v20200904.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "\n",
      "\n",
      "---------------  Path to nc file exists ?? ---------------\n",
      "\n",
      "True\n",
      "\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[2, 3, 2, 9]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[41, 40, 40, 42]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.31937172774869, -18.376963350785346, -19.31937172774869, -12.722513089005233]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[35.0, 33.75, 33.75, 36.25]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n",
      "\n",
      "i = 0\n",
      "\n",
      "closest_value_lat[i]-19.31937172774869\n",
      "\n",
      "type(closest_value_lat[i])<class 'numpy.float64'>\n",
      "\n",
      "Value were found for the period and the project tested\n",
      "\n",
      "Test with model cmcc_esm2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:43:07,800 INFO Welcome to the CDS\n",
      "2023-07-04 15:43:07,802 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:43:07,882 INFO Request is queued\n",
      "2023-07-04 15:43:08,959 INFO Request is running\n",
      "2023-07-04 15:45:59,749 INFO Request is completed\n",
      "2023-07-04 15:45:59,750 INFO Downloading https://download-0019.copernicus-climate.eu/cache-compute-0019/cache/data2/adaptor.esgf_wps.retrieve-1688478311.7067168-30684-14-d1bf47af-0ab5-499c-bab0-6fc6aa09e91e.zip to download.zip (201.6M)\n",
      "2023-07-04 15:46:42,896 INFO Download rate 4.7M/s                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been download\n",
      "Path for the file is created, did not existed before\n",
      "\n",
      " The downloaded file is extracted\n",
      "The file has been extracted\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cmcc_esm2\\1950-2014\\Copernicus-CMIP6\\pr_day_CMCC-ESM2_historical_r1i1p1f1_gn_19500101-20141231_v20210114.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cmcc_esm2\\1950-2014\\Copernicus-CMIP6\\pr_day_CMCC-ESM2_historical_r1i1p1f1_gn_19500101-20141231_v20210114.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "\n",
      "\n",
      "---------------  Path to nc file exists ?? ---------------\n",
      "\n",
      "True\n",
      "\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[2, 3, 2, 9]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[41, 40, 40, 42]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.31937172774869, -18.376963350785346, -19.31937172774869, -12.722513089005233]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[35.0, 33.75, 33.75, 36.25]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n",
      "\n",
      "i = 0\n",
      "\n",
      "closest_value_lat[i]-19.31937172774869\n",
      "\n",
      "type(closest_value_lat[i])<class 'numpy.float64'>\n",
      "\n",
      "Value were found for the period and the project tested\n",
      "\n",
      "Test with model cnrm_cm6_1_hr\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:48:14,344 INFO Welcome to the CDS\n",
      "2023-07-04 15:48:14,345 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-04 15:48:14,450 INFO Request is queued\n",
      "2023-07-04 15:48:15,512 INFO Request is running\n",
      "2023-07-04 16:00:35,230 INFO Request is completed\n",
      "2023-07-04 16:00:35,231 INFO Downloading https://download-0017.copernicus-climate.eu/cache-compute-0017/cache/data3/adaptor.esgf_wps.retrieve-1688479048.1472487-5080-17-c8bd1d41-2823-4111-9846-51c3ad78fe26.zip to download.zip (907.5M)\n",
      "2023-07-04 16:03:16,569 INFO Download rate 5.6M/s                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has been download\n",
      "Path for the file is created, did not existed before\n",
      "\n",
      " The downloaded file is extracted\n",
      "The file has been extracted\n",
      "path_for_file does exist Function copernicus search for nc\n",
      "The file is in the path Function copernicus search for nc\n",
      "\n",
      "Before path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cnrm_cm6_1_hr\\1950-2014\\Copernicus-CMIP6\\pr_day_CNRM-CM6-1-HR_historical_r1i1p1f2_gr_19500101-20080905_v20191021.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "After path_length, The final path for the nc file is: \\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cnrm_cm6_1_hr\\1950-2014\\Copernicus-CMIP6\\pr_day_CNRM-CM6-1-HR_historical_r1i1p1f2_gr_19500101-20080905_v20191021.nc\n",
      "\n",
      " The final path for nc file exists ? True\n",
      "\n",
      "\n",
      "\n",
      "---------------  Path to nc file exists ?? ---------------\n",
      "\n",
      "True\n",
      "\n",
      "\n",
      "suppose to enter once\n",
      "\n",
      "index_closest_lat\n",
      "[3, 5, 4, 17]\n",
      "\n",
      "len(index_closest_lat)\n",
      "4\n",
      "\n",
      "index_closest_lon\n",
      "[103, 102, 101, 107]\n",
      "\n",
      "len(index_closest_lon)\n",
      "4\n",
      "\n",
      "closest_value_lat\n",
      "[-19.72258773329993, -18.723975773164938, -19.22328175486926, -12.732303775515172]\n",
      "\n",
      "len(closest_value_lat)\n",
      "4\n",
      "\n",
      "closest_value_lon\n",
      "[34.5, 34.0, 33.5, 36.5]\n",
      "\n",
      "len(closest_value_lon)\n",
      "4\n",
      "i = 0\n",
      "k = 0\n",
      "start register data\n",
      "Registering the data in a dataframe\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 22704 is out of bounds for axis 0 with size 21448",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m (year, year_str, index)\u001b[38;5;241m=\u001b[39myear_copernicus(y_start,y_end)\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcsv_copernicus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemporal_resolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43myear_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcopernicus_elements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiments_historical\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcopernicus_elements\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mglobal_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname_projects\u001b[49m\u001b[43m,\u001b[49m\u001b[43marea_projects\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlat_projects\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlon_projects\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCopernicus-CMIP6\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mcsv_copernicus\u001b[1;34m(temporal_resolution, year_str, experiments, models, out_path, global_variable, name_variable, name_projects, area, lat_projects, lon_projects, source)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(path_for_csv)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m#test if the directory is empty\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# the csv file does not exist, even if the path exist\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# the dataframe_copernicus functions aims to test if the data with the specific parameters exists (with copernicus_data)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# and then produce a csv file if the data exists\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m         (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)\u001b[38;5;241m=\u001b[39m\u001b[43mdataframe_copernicus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemporal_resolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43myear_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_project\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43marea\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43marea\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43marea\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43marea\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlat_projects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlon_projects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath_for_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtitle_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     78\u001b[0m         (df,k,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon)\u001b[38;5;241m=\u001b[39mdataframe_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable, name_project,[area[\u001b[38;5;241m0\u001b[39m][k],area[\u001b[38;5;241m1\u001b[39m][k],area[\u001b[38;5;241m2\u001b[39m][k],area[\u001b[38;5;241m3\u001b[39m][k]],lat_projects[k],lon_projects[k],period,index_dates,dates,path_for_csv,title_file,source,k,i,index_closest_lat_d\u001b[38;5;241m=\u001b[39mindex_closest_lat,index_closest_lon_d\u001b[38;5;241m=\u001b[39mindex_closest_lon,closest_value_lat_d\u001b[38;5;241m=\u001b[39mclosest_value_lat,closest_value_lon_d\u001b[38;5;241m=\u001b[39mclosest_value_lon)\n",
      "Cell \u001b[1;32mIn[10], line 49\u001b[0m, in \u001b[0;36mdataframe_copernicus\u001b[1;34m(temporal_resolution, year_str, experiments, models, out_path, global_variable, name_variable, name_project, area, lat_project, lon_project, period, index_dates, dates, path_for_csv, title_file, source, k, i, index_closest_lat_d, index_closest_lon_d, closest_value_lat_d, closest_value_lon_d)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(k))\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart register data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m     df\u001b[38;5;241m=\u001b[39m\u001b[43mregister_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_variable_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname_project\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_closest_lat_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_closest_lon_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclosest_value_lat_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclosest_value_lon_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValue were found for the period and the project tested\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m, in \u001b[0;36mregister_data\u001b[1;34m(climate_variable_path, name_project, name_variable, index_dates, dates, experiment, model, index_closest_lat, index_closest_lon, closest_value_lat, closest_value_lon, df, i)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ds\u001b[38;5;241m.\u001b[39mvariables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m<\u001b[39m\u001b[38;5;28mlen\u001b[39m(index_dates):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# yes, missing 29.02\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mwhere((dates\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (dates\u001b[38;5;241m.\u001b[39mday \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m29\u001b[39m))[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m---> 39\u001b[0m         data_dataframe\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m Date \u001b[38;5;241m=\u001b[39m dates\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;66;03m# create tuple for iteration of dataframe\u001b[39;00m\n\u001b[0;32m     41\u001b[0m Name_Project \u001b[38;5;241m=\u001b[39m (name_project,)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\numpy\\lib\\function_base.py:5332\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   5330\u001b[0m index \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   5331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mN \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m>\u001b[39m N:\n\u001b[1;32m-> 5332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5333\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   5335\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m N\n",
      "\u001b[1;31mIndexError\u001b[0m: index 22704 is out of bounds for axis 0 with size 21448"
     ]
    }
   ],
   "source": [
    "(year, year_str, index)=year_copernicus(y_start,y_end)\n",
    "\n",
    "df = csv_copernicus(temporal_resolution,year_str,copernicus_elements.experiments_historical,copernicus_elements.models,out_path,global_variable, name_variable,name_projects,area_projects,lat_projects,lon_projects,'Copernicus-CMIP6')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb09f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem, do not find lat and lon closest to the project !!! why ? because lat in the path is smaller than the one of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62933030",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\cnrm_cm6_1_hr\\1950-2014\\Copernicus-CMIP6\\pr_day_CNRM-CM6-1-HR_historical_r1i1p1f2_gr_19500101-20080905_v20191021.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ee1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf45b97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-21.22050565)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.variables['lat'][0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b9d8513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds.variables['time'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a17f54b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2008"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ds.indexes['time'].year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d68a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909969e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c1ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "    (dates, index_dates)=date_copernicus(temporal_resolution,year_str) # create time vector depending on temporal resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1bfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1079486",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.variables['time'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.variables['time_bnds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c990534",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cft=ds.indexes['time'].to_datetimeindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(time_cft[0].month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8283021",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time_cft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cft_to_comp=[str(time_cft[k].year)+'-'+str(time_cft[k].month)+'-'+str(time_cft[k].day) for k in np.arange(0,len(time_cft))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f2734",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(time_cft_to_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d09f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1950, 1950, 1950, 1950, 1950, 1950, 1950, 1950, 1950, 1950,\n",
       "       ...\n",
       "       2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008],\n",
       "      dtype='int32', name='time', length=21433)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.indexes['time'].year#.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da1295ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mto_period(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "test.dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86e5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ca778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c6fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c95e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a441dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\precipitation\\WTP_Mutua_EIB\\historical\\access_cm2\\1950-2014\\Copernicus-CMIP6\\pr_day_ACCESS-CM2_historical_r1i1p1f1_gn_19500101-20141231_v20191108.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31950ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = xr.open_dataset(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.variables['pr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54514ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ds2.variables['pr'].isel(lat=40,lon=10).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.variables['time'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ds2.variables['pr'].isel(time=index_dates,lat=10,lon=10).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(ds2.variables['time'])[0].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.to_datetime(ds2.variables['time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ab11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_compare = [str(pd.to_datetime(ds2.variables['time'])[k].year)+'-'+str(pd.to_datetime(ds2.variables['time'])[k].month)+'-'+str(pd.to_datetime(ds2.variables['time'])[k].day) for k in np.arange(0,len(pd.to_datetime(ds2.variables['time'])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307026cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(time_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(time_to_compare) - set(time_cft_to_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abda73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of the problem found !! bissextle years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c670bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds2.variables['time'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec299255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=ds.variables['pr'].isel(lat=10,lon=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a276e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.where((dates.month == 2) & (dates.day ==29))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "index[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test\n",
    "for i in index:\n",
    "    test3=np.insert(test3,i,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test\n",
    "test2[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf29516",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=np.insert(test2,index,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c360fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d4bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[np.where((dates.month == 2) & (dates.day ==29))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3171d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.where((dates.month == 2) & (dates.day ==29))[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.shape(np.where((dates.month == 2) & (dates.day ==29))[0]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.empty((len(np.where((dates.month == 2) & (dates.day ==29))[0]+1)),)\n",
    "a.fill(np.nan)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2cbf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf427416",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = [1,1,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebd689",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[np.where(m==2)[0]]='nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66747a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(m==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d820283",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ce309",
   "metadata": {},
   "outputs": [],
   "source": [
    "val =[8,8,8,8,8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f23fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.insert(val,[2,4],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3588154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
