{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebaef011",
   "metadata": {},
   "source": [
    "This notebook aims to contain all functions for indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gumbel_r\n",
    "from scipy.stats import gumbel_l\n",
    "import os\n",
    "import os.path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e471b1eb",
   "metadata": {},
   "source": [
    "# Treat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_station(df,name_col,name_station):\n",
    "    df_name_station = df[df[name_col]==name_station]\n",
    "    return df_name_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b53d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Year, Month and Season to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_year_month_season(df,column_date):\n",
    "    # add Year, month and season columns for graphs\n",
    "    Year = df[[column_date]].values.reshape(len(df[[column_date]].values),)\n",
    "    Month = df[[column_date]].values.reshape(len(df[[column_date]].values),)\n",
    "    Season = df[[column_date]].values.reshape(len(df[[column_date]].values),)\n",
    "    \n",
    "    if str(Year[1]).find('-')==2 or str(Year[1]).find('/')==2:\n",
    "        for i in np.arange(0,len(df[[column_date]].values)):\n",
    "            Year[i]=int(Year[i][6:10])\n",
    "            Month[i]=int(Month[i][3:5])\n",
    "            if Month[i]>3 and Month[i]<10: # dry season in Mozambique is between April and September\n",
    "                Season[i]='Dry'\n",
    "            else:# humid season is between October and March\n",
    "                Season[i]='Humid'\n",
    "            \n",
    "            Month[i]=str_month(Month[i])\n",
    "            \n",
    "    if str(Year[1]).find('-')==4 or str(Year[1]).find('/')==4:\n",
    "        for i in np.arange(0,len(df[[column_date]].values)):\n",
    "            Year[i]=int(Year[i][0:4])\n",
    "            Month[i]=int(Month[i][5:7])\n",
    "            if Month[i]>3 and Month[i]<10: # dry season in Mozambique is between April and September\n",
    "                Season[i]='Dry'\n",
    "            else:# humid season is between October and March\n",
    "                Season[i]='Humid'\n",
    "            \n",
    "            Month[i]=str_month(Month[i])\n",
    "                \n",
    "    df['Year'] = Year\n",
    "    df['Month'] = Month\n",
    "    df['Season'] = Season\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_month(int_m):\n",
    "    if int_m==1:\n",
    "        str_m = 'Jan'\n",
    "    if int_m==2:\n",
    "        str_m = 'Feb'    \n",
    "    if int_m==3:\n",
    "        str_m = 'Mar'\n",
    "    if int_m==4:\n",
    "        str_m = 'Apr'\n",
    "    if int_m==5:\n",
    "        str_m = 'May'\n",
    "    if int_m==6:\n",
    "        str_m = 'Jun'\n",
    "    if int_m==7:\n",
    "        str_m = 'Jul'\n",
    "    if int_m==8:\n",
    "        str_m = 'Aug'    \n",
    "    if int_m==9:\n",
    "        str_m = 'Sep'\n",
    "    if int_m==10:\n",
    "        str_m = 'Oct'\n",
    "    if int_m==11:\n",
    "        str_m = 'Nov'\n",
    "    if int_m==12:\n",
    "        str_m = 'Dec'\n",
    "    return str_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced5bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to filter the data wnated \n",
    "def filter_dataframe(df,name_projects,list_model_to_kill,start_y=1950,stop_y=2100):\n",
    "    df = df.reset_index() # to take out multiindex that may exist and complicate filtering process\n",
    "    \n",
    "    if list_model_to_kill!=[]:\n",
    "        for name_model in list_model_to_kill:\n",
    "            df = df[df['Model']!=name_model]\n",
    "    \n",
    "    df_final= pd.DataFrame()\n",
    "    for name_project in name_projects:\n",
    "        df_temp = df[df['Name project']==name_project] # select only data of interest\n",
    "        df_final = pd.concat([df_final,df_temp])\n",
    "    \n",
    "    if 'Year' not in list(df_final.columns):\n",
    "        df_final=add_year_month_season(df_final,'Date') # add column 'Year', 'Month', 'Season'\n",
    "    \n",
    "    if start_y!=1950 or stop_y!=2100:\n",
    "        df_final = df_final[df_final['Year'].between(start_y,stop_y)] # select only the years of interest\n",
    "    if 'index' in df_final.columns:\n",
    "        df_final= df_final.drop('index',axis=1)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dacb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to find the correct name of the column of interest\n",
    "\n",
    "def find_name_col(df,climate_var_longName):\n",
    "    try:\n",
    "        try:\n",
    "            try:\n",
    "                old_title_column=df.filter(like=climate_var_longName, axis=1).columns[0]\n",
    "            except:\n",
    "                old_title_column=df.filter(like=climate_var_longName.capitalize(), axis=1).columns[0]\n",
    "        except:\n",
    "            old_title_column=df.filter(like=climate_var_longName.upper(), axis=1).columns[0]\n",
    "    except:\n",
    "        old_title_column=df.filter(like=climate_var_longName.lower(), axis=1).columns[0]\n",
    "    return old_title_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function df_to_csv aims to return the filled dataframe in a csv format\n",
    "# Inputs are:\n",
    "#       df: the dataframe that should be register in a csv file\n",
    "#      path_for_csv: this is the path where the csv file should be registered, in a string format\n",
    "#      title_file: this is the name of the csv file to be created in a string format\n",
    "#                  CAREFUL --> title_file MUST have the extension of the file in the string (.csv for example)\n",
    "# Output is:\n",
    "#      in the case where the dataframe is not empty, the ouput is the full path to the created csv file\n",
    "#      in the case where the dataframe is empty, the output is an empty list\n",
    "\n",
    "def df_to_csv(df,path_for_csv,title_file):\n",
    "    # test if dataframe is empty, if values exist for this period\n",
    "    if not df.empty: \n",
    "        # if dataframe is not empty, value were registered, the first part is run : \n",
    "        # a path to register the csv file is created, .....\n",
    "        if not os.path.isdir(path_for_csv):\n",
    "            # the path to the file does not exist\n",
    "            os.makedirs(path_for_csv) # to ensure creation of the folder\n",
    "            # creation of the path for the csv file, in a string format\n",
    "        full_name = os.path.join(path_for_csv,title_file)\n",
    "        # ..... and the dataframe is registered in a csv file\n",
    "        df.to_csv(full_name) # register dataframe in csv file\n",
    "        print('Path for csv file is: ' + full_name)\n",
    "        return full_name # return the full path that leads to the created csv file\n",
    "    else: # if the dataframe is empty, no value were found, there is no value to register or to return\n",
    "        print('The dataframe is empty')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b3b6c",
   "metadata": {},
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85f54c",
   "metadata": {},
   "source": [
    "### Return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return period for each project, model, scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd81392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function value for return period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_coresponding_to_return_period(loc,scale,T):\n",
    "    p_non_exceedance = 1 - (1/T)\n",
    "    try:\n",
    "        threshold_coresponding = round(gumbel_r.ppf(p_non_exceedance,loc,scale))\n",
    "    except OverflowError: # the result is not finite\n",
    "        if math.isinf(gumbel_r.ppf(p_non_exceedance,loc,scale)) and gumbel_r.ppf(p_non_exceedance,loc,scale)<0:\n",
    "            # ppf is the inverse of cdf\n",
    "            # the result is -inf\n",
    "            threshold_coresponding = 0 # the value of wero is imposed\n",
    "    return threshold_coresponding\n",
    "    # ppf: Percent point function\n",
    "    #print('Threshold '+str(threshold_coresponding)+' mm/day will be exceeded at least once in '+str(n)+' year, with a probability of '+str(round(p_exceedance*100))+ ' %')\n",
    "    #print('This threshold corresponds to a return period of '+str(round(return_period))+ ' year event over a '+str(n)+' year period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return return period for dataframe of modelled data\n",
    "def dataframe_threshold_coresponding_to_return_period_model(df,name_col):\n",
    "    df_copy=df.copy(deep=True)\n",
    "    df_copy=df_copy.drop(labels='Date',axis=1)\n",
    "    df_max = df_copy.groupby(['Name project','Experiment','Model','Year']).max() # maximum    \n",
    "    midx = pd.MultiIndex.from_product([list(set(df_copy[df_copy.columns[0]])),list(set(df_copy[df_copy.columns[1]])),list(set(df_copy[df_copy.columns[2]]))],names=['Name project','Experiment', 'Model'])\n",
    "    cols = ['Value for return period 50 years mm/day','Value for return period 100 years mm/day']\n",
    "    return_period = pd.DataFrame(data = [], \n",
    "                                index = midx,\n",
    "                                columns = cols)\n",
    "    for name_p in return_period.index.levels[0].tolist():\n",
    "        for ssp in return_period.index.levels[1].tolist():\n",
    "            for model in return_period.index.levels[2].tolist():\n",
    "                print('Name project '+name_p+ ' ssp '+ssp+ ' model '+model)\n",
    "                Z=df_max.loc[(name_p,ssp,model)][name_col].values.reshape(len(df_max.loc[(name_p,ssp,model)][name_col]),)\n",
    "                (loc1,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "                # choice of gumbel because suits to extreme precipitation\n",
    "                return_period.loc[(name_p,ssp,model),('Value for return period 50 years mm/day')] = threshold_coresponding_to_return_period(loc1,scale,50)\n",
    "                return_period.loc[(name_p,ssp,model),('Value for return period 100 years mm/day')] = threshold_coresponding_to_return_period(loc1,scale,100)\n",
    "                \n",
    "    return return_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return return period for dataframe of observed data\n",
    "def dataframe_threshold_coresponding_to_return_period_obs(df,name_col):\n",
    "    df_copy=df.copy(deep=True)\n",
    "    df_copy=df_copy.drop(labels='Date',axis=1)\n",
    "    df_max = df_copy.groupby(['Name project','Year'])[[name_col]].max() # maximum    \n",
    "    midx = pd.MultiIndex.from_product([list(set(df_copy[df_copy.columns[0]]))],names=['Name project'])\n",
    "    cols = ['Value for return period 50 years mm/day','Value for return period 100 years mm/day']\n",
    "    return_period = pd.DataFrame(data = [], \n",
    "                                index = midx,\n",
    "                                columns = cols)\n",
    "    for name_p in return_period.index.levels[0].tolist():\n",
    "        print('Name project '+name_p)\n",
    "        Z=df_max.loc[(name_p)][name_col].values.reshape(len(df_max.loc[(name_p)][name_col]),)\n",
    "        (loc1,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "        # choice of gumbel because suits to extreme precipitation\n",
    "        return_period.loc[(name_p,ssp,model),('Value for return period 50 years mm/day')] = threshold_coresponding_to_return_period(loc1,scale,50)\n",
    "        return_period.loc[(name_p,ssp,model),('Value for return period 100 years mm/day')] = threshold_coresponding_to_return_period(loc1,scale,100)\n",
    "\n",
    "    return return_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5491bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function a check\n",
    "def return_period_coresponding_to_threshold(Z):\n",
    "    (loc,scale)=stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "    # gumbel_r is chosen because\n",
    "    #try:\n",
    "    p_non_exceedance = round(gumbel_r.cdf(max(Z),loc,scale))\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.ppf.html\n",
    "    #except OverflowError: # the result is not finite\n",
    "        \n",
    "   #     if math.isinf(gumbel_r.cdf(threshold,loc,scale)) and gumbel_r.cdf(max(Z),loc,scale)<0:\n",
    "   #         # the result is -inf\n",
    "    #        threshold_coresponding = 0 # the value of wero is imposed\n",
    "    return_period_coresponding = 1/(1-p_non_exceedance)\n",
    "    return return_period_coresponding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_period(df,T,start_y,stop_y):\n",
    "    Z = df[df['Year'].between(start_y,stop_y)].groupby('Year')[['pr']].agg(np.nanmax)#.reshape(len(pr_obs_gorongosa_from_gorongosa.groupby('Year')[['pr']].max()),)\n",
    "    #Z = Z[~np.isnan(Z)]\n",
    "    (loc1,scale1)=scipy.stats.gumbel_r.fit(Z) # return the function necessary to establish the continous function\n",
    "    value_for_T=threshold_coresponding_to_return_period(loc1,scale1,T)\n",
    "    return value_for_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01687c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions Temps retour :\n",
    "#      \n",
    "#      besoin de caler mieux distribution ? package pour le faire automatiquement ? si on fiat pas avec maxima, mais on va faire que avec maxima pour le moment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19779648",
   "metadata": {},
   "source": [
    "## calculation Yearly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bca0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function only works for projections\n",
    "# example of use df_monthly_avg_tas_NEXGDDPCMIP6_gorongosa=temporal_avg(df_tas_NEXGDDPCMIP6_gorongosa,'temperature','Monthly average temperature','month')\n",
    "def temporal_avg(df,climate_var_long_name,title_column,temporal_resolution):\n",
    "    df_yearly_avg = df.copy(deep =True)\n",
    "    old_name_column = find_name_col(df,climate_var_long_name)\n",
    "    df_yearly_avg=df_yearly_avg.rename(columns={old_name_column:title_column})\n",
    "    if 'pr' in title_column.lower():\n",
    "        if temporal_resolution == 'year':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Year'])[[title_column]].mean()*365.25\n",
    "        if temporal_resolution == 'month':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Month'])[[title_column]].mean()*30\n",
    "    else:\n",
    "        if temporal_resolution == 'year':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Year'])[[title_column]].mean()\n",
    "        if temporal_resolution == 'month':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Month'])[[title_column]].mean()\n",
    "    return df_yearly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67320c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function only works for projections\n",
    "# example of use df_monthly_avg_tas_NEXGDDPCMIP6_gorongosa=temporal_avg(df_tas_NEXGDDPCMIP6_gorongosa,'temperature','Monthly average temperature','month')\n",
    "def temporal_max(df,climate_var_long_name,title_column,temporal_resolution):\n",
    "    df_yearly_avg = df.copy(deep =True)\n",
    "    old_name_column = find_name_col(df,climate_var_long_name)\n",
    "    df_yearly_avg=df_yearly_avg.rename(columns={old_name_column:title_column})\n",
    "    if 'pr' in title_column.lower():\n",
    "        if temporal_resolution == 'year':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Year'])[[title_column]].max()*365.25\n",
    "        if temporal_resolution == 'month':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Month'])[[title_column]].max()*30\n",
    "    else:\n",
    "        if temporal_resolution == 'year':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Year'])[[title_column]].max()\n",
    "        if temporal_resolution == 'month':\n",
    "            df_yearly_avg = df_yearly_avg.groupby(['Name project','Experiment','Model','Month'])[[title_column]].max()\n",
    "    return df_yearly_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac6016",
   "metadata": {},
   "source": [
    "### N - number of days above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_day_above_threshold(df,climate_var_longName,threshold):\n",
    "    new_name='Average annual number of days with '+climate_var_longName+' above '+str(threshold)\n",
    "    #df = df.rename(columns={old_title_column:new_name})\n",
    "    \n",
    "    df = df.drop(['Date','Month','Season'],axis=1) \n",
    "    df=df.reset_index()\n",
    "    #df=df.groupby(['Experiment','Model','Year']).apply(lambda x: x[x[new_name]>40].count()).reset_index()\n",
    "    df[new_name]=0\n",
    "    df[new_name].iloc[np.where(df[old_title_column]>40)[0]]=1    \n",
    "    df = df.groupby(['Experiment','Model','Year'])[[new_name]].sum()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a9615",
   "metadata": {},
   "source": [
    "# Precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfaec75",
   "metadata": {},
   "source": [
    "### N-day event "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5383ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some models to not have any values for some scenarios\n",
    "# need to delete them from the global dataset\n",
    "\n",
    "# PROBLEM AVEC CETTE FUNCTION\n",
    "\n",
    "def delete_NaN_model(df):\n",
    "    df_copy=df.copy(deep=True) # copy the original dataframe, not to modify the original one    \n",
    "    model_to_delete =[]\n",
    "    longitude=[]\n",
    "    for project in df_copy.index.levels[0].tolist(): # projects\n",
    "        # look value of longitude for each project\n",
    "        for j in np.arange(0,len(df_copy.loc[[project]].columns)):\n",
    "            if ~df_copy[[df_copy.columns[j]]].isnull().values.all():\n",
    "                # can check if a pandas DataFrame contains NaN/None values in any cell \n",
    "                # (all rows & columns ). This method returns True if it finds NaN/None \n",
    "                # on any cell of a DataFrame, returns False when not found\n",
    "                longitude.append(df_copy.columns[j])\n",
    "                continue\n",
    "        \n",
    "        for scenario in df_copy.index.levels[1].tolist(): # scenarios\n",
    "            for model in df_copy.index.levels[2].tolist(): # models\n",
    "                if df_copy.loc[(project,scenario, model)].isnull().values.all():\n",
    "                    print('No data for Project '+ project+', scenario '+scenario+', model '+model)\n",
    "                    # all the values for the given project, scenario and model are NaN\n",
    "                    if model not in model_to_delete:\n",
    "                        model_to_delete.append(model)# keep unique values\n",
    "    \n",
    "    if model_to_delete!=[]:\n",
    "        # for some given project, scenario and model, there is no values\n",
    "        for model in model_to_delete:\n",
    "            models_index = df_copy.index.levels[2].tolist()\n",
    "            models_index.remove(model)\n",
    "            df_copy.drop(labels=model,level=2,inplace=True)\n",
    "        \n",
    "        return models_index\n",
    "        # create new dataframe with correct index\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051817a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions aims to calculate the n_day_event\n",
    "def n_day_maximum_rainfall(number_day,df):\n",
    "    df1=df.copy(deep=True)\n",
    "    # df.use function rolling(n).sum() to calculate cumulative precipitation over n days\n",
    "    df1[['Precipitation mm']]=df1[['Precipitation mm']].rolling(number_day).sum()\n",
    "    time=df1.index.tolist()\n",
    "    for k in np.arange(len(time)-number_day,-1,-1):\n",
    "        time[number_day-1+k] = time[k] + ' to '+time[number_day-1+k]\n",
    "    df1.drop(df1.index[np.arange(0,number_day-1)], inplace=True) # delete first elements which are NaNs\n",
    "    del time[0:number_day-1] # delete firsts elements, which have no value associated with\n",
    "    #midx = pd.MultiIndex.from_product([ time],names=['Date'])\n",
    "    name_col = ['Precipitation mm']\n",
    "    Dataframe_n_day_event = pd.DataFrame(data = df1.values, \n",
    "                                index = [time],\n",
    "                                columns = name_col)\n",
    "    return Dataframe_n_day_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to create the empty dataframe that will be filled\n",
    "\n",
    "def fill_dataframe(name_project,scenario,model,time,data_df,name_col):\n",
    "    #df = pd.DataFrame()\n",
    "    #for i in np.arange(0,len(name_project)):\n",
    "    midx = pd.MultiIndex.from_product([name_project,scenario,model , time],names=['Name project','Experiment', 'Model', 'Date'])\n",
    "    name_col = [name_col]#['Precipitation '+str(number_day)+' day event mm']\n",
    "    Variable_dataframe = pd.DataFrame(data = data_df, \n",
    "                                index = midx,\n",
    "                                columns = name_col)\n",
    "        #df = pd.concat([df,Variable_dataframe])\n",
    "    return Variable_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function dataframe_n_day_event produce a dataframe, with the n_day event precipitation for the period, models and scenarios asked\n",
    "# this function use the function : 'delete_NaN_model', 'n_day_maximum_rainfall' and 'fill_dataframe'\n",
    "\n",
    "\n",
    "def dataframe_n_day_event(df,number_day):\n",
    "    df_copy=df.copy(deep=True) # copy the original dataframe, not to modify the original one    \n",
    "    df_n_day_event = pd.DataFrame() # create empty dataframe, that will be filled later\n",
    "    # extract years of the period of interest, make a vector containing all the years of interest\n",
    "    years = np.arange(int(df.index.levels[3].tolist()[0][6:10]),int(df.index.levels[3].tolist()[len(df.index.levels[3].tolist())-1][6:10])+1)\n",
    "    #models_index=delete_NaN_model(df_copy) # use function 'delete_NaN_model' to know which models have no Nan values\n",
    "    models_index = df_copy.index.levels[2].tolist()\n",
    "    models_index.remove('NESM3')\n",
    "    df_copy=df_copy.droplevel(level=4) # drop latitude index\n",
    "    df_copy.columns = df_copy.columns.droplevel(0) # drop first level of column name\n",
    "    for project in df_copy.index.levels[0].tolist(): # projects\n",
    "        for scenario in df_copy.index.levels[1].tolist(): # scenarios\n",
    "            for model in models_index: # models\n",
    "                print('Project '+ project+', scenario '+scenario+', model '+model)\n",
    "                # select on project, one scenario, one model and drop Latitude index\n",
    "                df_temp_all_years = df_copy.loc[(project,scenario,model)]\n",
    "                # find which columns does not only have NaN\n",
    "                for j in np.arange(0,len(df_temp_all_years.columns)): # for loop to have number of the column\n",
    "                    if ~df_temp_all_years[[df_temp_all_years.columns[j]]].isnull().values.all():\n",
    "                        # the column does not only have Nan values\n",
    "                        df_temp_all_years=df_temp_all_years[[df_temp_all_years.columns[j]]] # register only column with values, and not the NaN values\n",
    "                        df_temp_all_years=df_temp_all_years.rename(columns={df_temp_all_years.columns[0]:'Precipitation mm'})\n",
    "                        # rename the column\n",
    "                        break # stop the for loop with the number of columns, because values were found\n",
    "                        # go to line if df_temp_all_years.columns.nlevels!=1:\n",
    "                if df_temp_all_years.columns.nlevels!=1:\n",
    "                    # the dataframe still has two levels of columns, so the precedent if condition was never fullfilled\n",
    "                    print('The model '+model+' has no data')\n",
    "                    continue # try with the next model\n",
    "                else:\n",
    "                    # the dataframe still has one level of columns, there was one column not containing only NaN values\n",
    "                    for year in years:\n",
    "                        print(year)\n",
    "                        df_temp_one_year = df_temp_all_years.filter(like = str(year), axis=0) # select only data for one year\n",
    "                        #return df_temp_one_year\n",
    "                        df_temp_one_year_n_event=n_day_maximum_rainfall(number_day,df_temp_one_year) # use function to calculate cumulative precipitation\n",
    "                        #return df_temp_one_year_n_event\n",
    "                        # format time vector differently\n",
    "                        time = [df_temp_one_year_n_event.index.tolist()[i][0] for i in np.arange(0,len(df_temp_one_year_n_event.index.tolist()))]\n",
    "                        # fill dataframe\n",
    "                        df_temp_one_year_n_event = fill_dataframe((project,),(scenario,),(model,),time,df_temp_one_year_n_event.values,'Maximum '+str(number_day)+' days rainfall mm')\n",
    "                        df_n_day_event = pd.concat([df_n_day_event,df_temp_one_year_n_event])\n",
    "    return df_n_day_event # return a dataframe, with all the projects, scenarios, models and period of n day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_1_day_event(df):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_max = df_copy.groupby(['Name project','Experiment','Model','Year']).max() # maximum\n",
    "    df_max=df_max.drop(labels='Date',axis=1)# drop columns Date\n",
    "    df_max=df_max.rename(columns={df_max.columns[0]:'Maximum 1 day rainfall mm '+str(df_max.index.levels[3][0])+'-'+str(df_max.index.levels[3][len(df_max.index.levels[3])-1])})\n",
    "    return df_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e354b6",
   "metadata": {},
   "source": [
    "### Seasonal average precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ed57b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function a check\n",
    "def avg_dry_season_precipitation(df,title_column):\n",
    "    df_season = df.copy(deep=True)\n",
    "    df_season=df_season.rename(columns={df_season.columns[4]:title_column})\n",
    "    \n",
    "    Month = df_season[['Date']].values.reshape(len(df_season[['Date']].values),)\n",
    "    Season = df_season[['Date']].values.reshape(len(df_season[['Date']].values),)\n",
    "    for i in np.arange(0,len(df_season[['Date']].values)):\n",
    "        Month[i]=Month[i][3:5]\n",
    "        if int(Month[i])>3 and int(Month[i])<10:\n",
    "            Season[i]='Dry'\n",
    "        else:\n",
    "            Season[i]='Humid'\n",
    "\n",
    "    #df_season['Month'] = Month\n",
    "    df_season['Season'] = Season\n",
    "    df_season=df_season.drop(labels='Date',axis=1)\n",
    "    df_season=df_season.groupby(['Name project','Experiment','Model','Season','Year']).sum()\n",
    "    df_season=df_season.groupby(['Name project','Experiment','Model','Season']).mean()\n",
    "    df_season=df_season.groupby(['Name project','Season']).describe(percentiles=[.1, .5, .9])\n",
    "    pr_dry_season_mean_distribution=df_season.query('Season==\"Dry\"')\n",
    "    pr_dry_season_mean_distribution=pr_dry_season_mean_distribution.reset_index().drop('Season',axis=1).set_index('Name project')\n",
    "    return pr_dry_season_mean_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b648914",
   "metadata": {},
   "source": [
    "# Changes in indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse columns and rows for final df\n",
    "\n",
    "def changes_in_indicators(df_past,df_futur,title_indicator, unit,climate_var):\n",
    "    # create empty dataframe\n",
    "    #midx = pd.MultiIndex.from_product([df_years_avg_2041_2060_distribution.index.tolist(),precipitation_2021_2060_copy.index.levels[1].tolist(),models],names=['Name project','Experiment', 'Model'])\n",
    "    cols = pd.MultiIndex.from_product([(climate_var,),(title_indicator,),('Median for the past period '+unit,'Change in the median in %','10-th percentile for the past period '+unit, 'Change in 10-th percentile %','90-th percentile for the past period '+unit,'Change in 90-th percentile %')])\n",
    "    changes_past_future_indicator = pd.DataFrame(data = [], \n",
    "        index = df_past.index.tolist(),\n",
    "        columns = cols)\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[0]]]=df_past[[df_past.columns[5]]]\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[1]]]=(((df_futur[[df_futur.columns[5]]].values-df_past[[df_past.columns[5]]].values)/df_past[[df_past.columns[5]]].values)*100).reshape(len(df_past[[df_past.columns[5]]].values,),1)\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[2]]]=df_past[[df_past.columns[4]]]\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[3]]]=(((df_futur[[df_futur.columns[4]]].values-df_past[[df_past.columns[4]]].values)/df_past[[df_past.columns[4]]].values)*100).reshape(len(df_past[[df_past.columns[4]]].values,),1)\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[4]]]=df_past[[df_past.columns[6]]]\n",
    "    \n",
    "    changes_past_future_indicator[[changes_past_future_indicator.columns[5]]]=(((df_futur[[df_futur.columns[6]]].values-df_past[[df_past.columns[6]]].values)/df_past[[df_past.columns[6]]].values)*100).reshape(len(df_past[[df_past.columns[6]]].values,),1)\n",
    "    \n",
    "    return changes_past_future_indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb04ed1",
   "metadata": {},
   "source": [
    "# Level of exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fe840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inverse columns and rows for final df\n",
    "\n",
    "def level_exposure(df):\n",
    "    # level of exposure by climate variable\n",
    "    \n",
    "    # create empty dataframe\n",
    "    #midx = pd.MultiIndex.from_product([df_years_avg_2041_2060_distribution.index.tolist(),precipitation_2021_2060_copy.index.levels[1].tolist(),models],names=['Name project','Experiment', 'Model'])\n",
    "    cols = pd.MultiIndex.from_product([('Exposure level',),df.columns.levels[0].tolist()]) # df.columns.levels[0].tolist() is liste of climate variable\n",
    "    ExposureLevel = pd.DataFrame(data = [],\n",
    "                            index = df.index.tolist(),\n",
    "                            columns = cols)\n",
    "    \n",
    "    for name_p in ExposureLevel.index.tolist():\n",
    "        for climate_variable in df.columns.levels[0].tolist():\n",
    "            print('For project '+name_p+', climate variable '+climate_variable)\n",
    "            if ExposureLevel.loc[name_p,('Exposure level',climate_variable)] != 'High':\n",
    "                # for the moemnt, no other indicator for the climate variable made the exposure high (big changes with bug uncertainty)\n",
    "                \n",
    "                # select the columns of interest in the list of columns\n",
    "                col_interest_med= [cols for cols in df.columns.tolist() if climate_variable in cols and 'Change in the median in %' in cols]\n",
    "                col_interest_p10= [cols for cols in df.columns.tolist() if climate_variable in cols and 'Change in 10-th percentile %' in cols]\n",
    "                col_interest_p90= [cols for cols in df.columns.tolist() if climate_variable in cols and 'Change in 90-th percentile %' in cols]\n",
    "                \n",
    "                if ExposureLevel.loc[name_p,('Exposure level',climate_variable)] != 'Medium':\n",
    "                    if (df.loc[(name_p),col_interest_p10][abs(df.loc[(name_p),col_interest_p10])<20].notnull().values.any() or df.loc[(name_p),col_interest_p90][abs(df.loc[(name_p),col_interest_p90])<20].notnull().values.any()):\n",
    "                        # test if there are any True, if any value is under the threshold indicated\n",
    "                        ExposureLevel.loc[name_p,('Exposure level',climate_variable)] = 'No' # attribute value to exposure level\n",
    "\n",
    "                    if (df.loc[(name_p),col_interest_p10][abs(df.loc[(name_p),col_interest_p10])>20].notnull().values.any() or df.loc[(name_p),col_interest_p90][abs(df.loc[(name_p),col_interest_p90])>20].notnull().values.any()):\n",
    "                    # test if there are any True, if any value is over the threshold indicated\n",
    "                        ExposureLevel.loc[name_p,('Exposure level',climate_variable)] = 'Medium' # attribute value to exposure level\n",
    "\n",
    "\n",
    "                if (df.loc[(name_p),col_interest_med][abs(df.loc[(name_p),col_interest_med])>20].notnull().values.any()) or (df.loc[(name_p),col_interest_p10][abs(df.loc[(name_p),col_interest_p10])>50].notnull().values.any() or df.loc[(name_p),col_interest_p90][abs(df.loc[(name_p),col_interest_p90])>50].notnull().values.any()):\n",
    "                    # test if there are any True, if any value is over the threshold indicated\n",
    "                    ExposureLevel.loc[name_p,('Exposure level',climate_variable)] = 'High' # attribute value to exposure level\n",
    "    \n",
    "    # those 2 next lines are meant to put colors for Exposure, but prevent from using it as a dataframe after, so give up for the moement\n",
    "    #ExposureLevel=ExposureLevel.style.apply(exposureColor) # apply color depending on value of Exposure\n",
    "    #ExposureLevel=ExposureLevel.set_table_styles([{'selector': 'th.col_heading', 'props': 'text-align: left;'}],[{'selector': 'td', 'props': 'text-align: center;'}],overwrite = True) # place first level column to the left\n",
    "    # meant to place element in dataframe, but do not work very well\n",
    "    return ExposureLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function use in function 'level_exposure' to color result depending on the result\n",
    "# function not in use for the moment\n",
    "def exposureColor(series):\n",
    "    green = 'background-color: lightgreen'\n",
    "    orange = 'background-color: orange'\n",
    "    red = 'background-color: red'\n",
    "    return [red if value == 'High' else orange if value == 'Medium' else green for value in series]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe0910",
   "metadata": {},
   "source": [
    "# Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function only makes sense if data are in the past or the future\n",
    "# input of this function is a dataframe with no multi evel index. If the dataframe is with multilevel index, should .reset_index()\n",
    "# Should just put a datfarme of 2 columns as df. The 2 columns sould be ['Name project'] and the colummn of interest\n",
    "def df_stat_distr(df):\n",
    "    df = df.groupby(['Name project']).describe(percentiles=[.1, .5, .9])\n",
    "    # if describe() does not return al wanted statistics, it is maybe because the elements in it are not recognized as int\n",
    "    # add astype(int) as in following example; df.astype(int).groupby(['Name project']).describe(percentiles=[.1, .5, .9])\n",
    "    return df"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0e740a0b",
   "metadata": {},
   "source": [
    "permit to have the foloowing matrix\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca21388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vulnerability(df_sensitivity,df_exposure):\n",
    "    \n",
    "    if len(df_sensitivity.columns.levels[1])!=len(df_exposure.columns.levels[1]): # check if both dataframe have the same numbers of indicators we are checking in\n",
    "        print('The number of climate variables is the sensitivity and in exposure is different')\n",
    "        return\n",
    "    \n",
    "    df_vulnerability = df_sensitivity.copy(deep=True)\n",
    "        \n",
    "    df_vulnerability.loc[:,:]='No' # default value\n",
    "    df_vulnerability=df_vulnerability.rename(columns={'Sensitivity level':'Vulnerability level'}) # chnage name of the column\n",
    "    \n",
    "    for name_p in list(df_exposure.index):# go throught projects\n",
    "        print(name_p)\n",
    "        for k in np.arange(0,len(df_vulnerability.index.levels[1])): # go through project elements\n",
    "            for i in np.arange(0,len(df_exposure.columns.levels[1])): # go through climate variables\n",
    "                #print('i = '+str(i))\n",
    "                if df_exposure.loc[name_p,('Exposure level',ExposureLevel_tasmax.columns.levels[1][i])]=='No':\n",
    "                    if df_sensitivity.loc[name_p,('Sensitivity level',df_sensitivity.columns.levels[1][i])][k]=='High':\n",
    "                        # assign vulnerability to 'Medium'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='Medium'\n",
    "                if df_exposure.loc[name_p,('Exposure level',ExposureLevel_tasmax.columns.levels[1][i])]=='Medium':\n",
    "                    if df_sensitivity.loc[name_p,('Sensitivity level',ExposureLevel_tasmax.columns.levels[1][i])][k]=='Medium':\n",
    "                        # assign vulnerability to 'Medium'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='Medium'\n",
    "                    if df_sensitivity.loc[name_p,('Exposure level',ExposureLevel_tasmax.columns.levels[1][i])][k]=='High':\n",
    "                        # assign vulnerability to 'High'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='High'\n",
    "                if df_exposure.loc[name_p,('Exposure level',ExposureLevel_tasmax.columns.levels[1][i])]=='High':\n",
    "                    if df_sensitivity.loc[name_p,('Sensitivity level',ExposureLevel_tasmax.columns.levels[1][i])][k]=='No':\n",
    "                        # assign vulnerability to 'Medium'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='Medium'\n",
    "                    if df_sensitivity.loc[name_p,('Sensitivity level',ExposureLevel_tasmax.columns.levels[1][i])][k]=='Medium':\n",
    "                        # assign vulnerability to 'High'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='High'\n",
    "                    if df_sensitivity.loc[name_p,('Sensitivity level',ExposureLevel_tasmax.columns.levels[1][i])][k]=='High':\n",
    "                        # assign vulnerability to 'High'\n",
    "                        df_vulnerability.loc[name_p,('Vulnerability level',df_vulnerability.columns.levels[1][i])][k]=='High'\n",
    "\n",
    "    return df_vulnerability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
