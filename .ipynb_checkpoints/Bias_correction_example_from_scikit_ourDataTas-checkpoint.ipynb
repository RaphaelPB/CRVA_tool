{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6781fd",
   "metadata": {},
   "source": [
    "Example from scikit downscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import get_sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a17ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities for plotting cdfs\n",
    "def plot_cdf(ax=None, **kwargs):\n",
    "    if ax:\n",
    "        plt.sca(ax)\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    for label, X in kwargs.items():\n",
    "        vals = np.sort(X, axis=0)\n",
    "        pp = scipy.stats.mstats.plotting_positions(vals)\n",
    "        ax.plot(pp, vals, label=label)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cdf_by_month(ax=None, **kwargs):\n",
    "    fig, axes = plt.subplots(4, 3, sharex=True, sharey=False, figsize=(12, 8))\n",
    "\n",
    "    for label, X in kwargs.items():\n",
    "        for month, ax in zip(range(1, 13), axes.flat):\n",
    "\n",
    "            vals = np.sort(X[X.index.month == month], axis=0)\n",
    "            pp = scipy.stats.mstats.plotting_positions(vals)\n",
    "            ax.plot(pp, vals, label=label)\n",
    "            ax.set_title(month)\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319607e",
   "metadata": {},
   "source": [
    "https://github.com/pangeo-data/scikit-downscale/blob/main/examples/2020ECAHM-scikit-downscale.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import xarray as xr\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91720d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions_ImportData import import_treat_modeled_NEX_GDDP_CMIP6\n",
    "from Functions_ImportData import import_treat_obs_NOAA\n",
    "from Functions_ImportData import import_treat_modeled_NEX_GDDP_CMIP6_close_to_stationNOAA\n",
    "from Bias_correction_function import BC\n",
    "from Bias_correction_function import treat_data_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4a3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_NOAA=import_treat_obs_NOAA()\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6_close_to_stationNOAA('tas', 'Celsius')\n",
    "df_tas = treat_data_for_test(data_obs_NOAA,'TAVG',climate_var_NEX_GDDP_CMIP6_EmplacementStation,'Daily Near-Surface Air Temperature Â°C','BEIRA, MZ','ACCESS-CM2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ec1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "r'''\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='training')\n",
    "# extract 1 point of training data for precipitation and temperature\n",
    "df = (\n",
    "    data.isel(point=0)\n",
    "    .to_dataframe()[['T2max', 'PREC_TOT']]\n",
    "    .rename(columns={'T2max': 'tmax', 'PREC_TOT': 'pcp'})\n",
    ")\n",
    "df['tmax'] -= 273.13\n",
    "df['pcp'] *= 24\n",
    "training= df.resample('1d').first()\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='targets')\n",
    "        # extract 1 point of training data for precipitation and temperature\n",
    "targets =data.isel(point=0).to_dataframe()[['Tmax', 'Prec']].rename(columns={'Tmax': 'tmax', 'Prec': 'pcp'})\n",
    "\n",
    "\n",
    "# print a table of the training/targets data\n",
    "display(pd.concat({'training': training, 'targets': targets}, axis=1))\n",
    "'''\n",
    "training=df_tas['training']\n",
    "targets=df_tas['targets']\n",
    "# make a plot of the temperature and precipitation data\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(8, 6), sharex=True)\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "# plot-temperature\n",
    "training[time_slice]['pcp'].plot(ax=axes[0], label='training')\n",
    "targets[time_slice]['pcp'].plot(ax=axes[0], label='targets')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('Precipitation [mm/day]')\n",
    "\n",
    "# plot-precipitation\n",
    "training[time_slice]['pcp'].plot(ax=axes[1])\n",
    "targets[time_slice]['pcp'].plot(ax=axes[1])\n",
    "_ = axes[1].set_ylabel('Precipitation [mm/day]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1321d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory data analysis for arrm model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "\n",
    "def ARRM(n_bins=7):\n",
    "    return Pipeline([\n",
    "        ('')\n",
    "    ])\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "qqwargs = {'n_quantiles': 1e6, 'copy': True, 'subsample': 1e6}\n",
    "n_bins = 7\n",
    "\n",
    "X = training[['tmax']]['1980': '2000'].values\n",
    "y = targets[['tmax']]['1980': '2000'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:, 0]\n",
    "for strat in ['kmeans', 'uniform', 'quantile']:\n",
    "    model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=strat))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(strat, model.score(X_test, y_test))\n",
    "    \n",
    "model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='kmeans'))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(X_train, y_train, c=c['train'], s=5, label='train')\n",
    "plt.scatter(X_test, y_test, c=c['test'], s=5, label='test')\n",
    "ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(np.sort(X_train, axis=0), np.sort(y_train, axis=0), c=c['train'], s=5, label='train')\n",
    "plt.scatter(np.sort(X_test, axis=0), np.sort(y_test, axis=0), c=c['test'], s=5, label='test')\n",
    "plt.plot(np.sort(X_test, axis=0), np.sort(pred, axis=0), c=c['predict'], lw=2, label='predictions')\n",
    "ax.legend()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# ax.plot(Xq_test[:, 0], yq_test, \".\", label='data', c=c['test'])\n",
    "# ax.plot(Xq_test[:, 0], predq, \".\", label=\"predictions\", c=c['predict'])\n",
    "# ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(X_test[:, 0], y_test, \".\", label='data', c=c['test'])\n",
    "ax.plot(X_test[:, 0], pred, \".\", label=\"predictions\", c=c['predict'])\n",
    "ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30c7ae",
   "metadata": {},
   "source": [
    "https://github.com/pangeo-data/scikit-downscale/blob/main/examples/bcsd_example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a small dataset for training\n",
    "training = xr.open_zarr(\"../data/downscale_test_data.zarr.zip\", group=\"training\")\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd01e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a small dataset of observations (targets)\n",
    "targets = xr.open_zarr(\"../data/downscale_test_data.zarr.zip\", group=\"targets\")\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 1 point of training data for precipitation and temperature\n",
    "X_temp = training.isel(point=0).to_dataframe()[[\"T2max\"]].resample(\"MS\").mean() - 273.13\n",
    "X_pcp = training.isel(point=0).to_dataframe()[[\"PREC_TOT\"]].resample(\"MS\").sum() * 24\n",
    "display(X_temp.head(), X_pcp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92849948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 1 point of target data for precipitation and temperature\n",
    "y_temp = targets.isel(point=0).to_dataframe()[[\"Tmax\"]].resample(\"MS\").mean()\n",
    "y_pcp = targets.isel(point=0).to_dataframe()[[\"Prec\"]].resample(\"MS\").sum()\n",
    "display(y_temp.head(), y_pcp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/predict the BCSD Precipitation model\n",
    "from skdownscale.pointwise_models import BcsdPrecipitation\n",
    "bcsd_pcp = BcsdPrecipitation()\n",
    "bcsd_pcp.fit(X_pcp.loc['1979':'2013'], y_pcp.loc['1979':'2013'])\n",
    "out = bcsd_pcp.predict(X_pcp.loc['1979':'2013']) * X_pcp.loc['1979':'2013']\n",
    "plot_cdf(X=X_pcp.loc['1979':'2013'], y=y_pcp.loc['1979':'2013'], out=out)\n",
    "plot_cdf_by_month(X=X_pcp, y=y_pcp, out=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/predict the BCSD Precipitation model\n",
    "from skdownscale.pointwise_models import BcsdTemperature\n",
    "bcsd_temp = BcsdTemperature()\n",
    "bcsd_temp.fit(X_temp.loc['1979':'2013'], y_temp.loc['1979':'2013'])\n",
    "out = bcsd_temp.predict(X_temp.loc['1979':'2013']) * X_temp.loc['1979':'2013']\n",
    "plot_cdf(X=X_temp.loc['1979':'2013'], y=y_temp.loc['1979':'2013'], out=out)\n",
    "plot_cdf_by_month(X=X_pcp, y=y_pcp, out=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08da767",
   "metadata": {},
   "source": [
    "## 2.2 Models as cattle, not pets\n",
    "\n",
    "https://github.com/earthcube2020/ec20_hamman_etal/blob/master/2020ECAHM-scikit-downscale.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86508ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b199ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='training')\n",
    "# extract 1 point of training data for precipitation and temperature\n",
    "df = (\n",
    "    data.isel(point=0)\n",
    "    .to_dataframe()[['T2max', 'PREC_TOT']]\n",
    "    .rename(columns={'T2max': 'tmax', 'PREC_TOT': 'pcp'})\n",
    ")\n",
    "df['tmax'] -= 273.13\n",
    "df['pcp'] *= 24\n",
    "training= df.resample('1d').first()\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='targets')\n",
    "        # extract 1 point of training data for precipitation and temperature\n",
    "targets =data.isel(point=0).to_dataframe()[['Tmax', 'Prec']].rename(columns={'Tmax': 'tmax', 'Prec': 'pcp'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3eaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARRM(n_bins=7):\n",
    "    return Pipeline([\n",
    "        ('')\n",
    "    ])\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "qqwargs = {'n_quantiles': 1e6, 'copy': True, 'subsample': 1e6}\n",
    "n_bins = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50349209",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training[['tmax']]['1980': '2000'].values\n",
    "y = targets[['tmax']]['1980': '2000'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12433bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:, 0]\n",
    "    \n",
    "model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='kmeans'))\n",
    "#print(strat, model.score(X_test, y_test))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skdownscale.pointwise_models import PureAnalog, AnalogRegression\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GARD: PureAnalog-best-1': PureAnalog(kind='best_analog', n_analogs=1),\n",
    "    'GARD: PureAnalog-sample-10': PureAnalog(kind='sample_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-10': PureAnalog(kind='weight_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-100': PureAnalog(kind='weight_analogs', n_analogs=100),\n",
    "    'GARD: PureAnalog-mean-10': PureAnalog(kind='mean_analogs', n_analogs=10),\n",
    "    'GARD: AnalogRegression-100': AnalogRegression(n_analogs=100),\n",
    "    'GARD: LinearRegression': LinearRegression(),\n",
    "    'BCSD: BcsdTemperature': BcsdTemperature(return_anoms=False),\n",
    "    'Sklearn: RandomForestRegressor': RandomForestRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "train_slice = slice('1980-01-01', '1989-12-31')\n",
    "predict_slice = slice('1990-01-01', '1999-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8402719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training / prediction data\n",
    "X_train = training[['tmax']][train_slice]\n",
    "y_train = targets[['tmax']][train_slice]\n",
    "X_predict = training[['tmax']][predict_slice]\n",
    "\n",
    "# Fit all models\n",
    "for key, model in models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predicted results in this dataframe\n",
    "predict_df = pd.DataFrame(index = X_predict.index)\n",
    "\n",
    "for key, model in models.items():\n",
    "    print('key')\n",
    "    print(key)\n",
    "    print('model')\n",
    "    print(model)\n",
    "    print(model.predict(X_predict))\n",
    "    if type(model.predict(X_predict))==pd.core.frame.DataFrame:\n",
    "        if len(list(model.predict(X_predict).columns))>1:\n",
    "            predict_df[key] = model.predict(X_predict)[['pred']].values # [['pred']] added to deal with piecewise regressor\n",
    "        else:\n",
    "            predict_df[key] = model.predict(X_predict)\n",
    "    else:\n",
    "        predict_df[key] = model.predict(X_predict) # [['pred']] added to deal with piecewise regressor\n",
    "\n",
    "# show a table of the predicted data\n",
    "display(predict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "targets['tmax'][time_slice].plot(ax=ax, label='target', c='k', lw=1, alpha=0.75, legend=True, zorder=10)\n",
    "X_predict['tmax'][time_slice].plot(label='original', c='grey', ax=ax, alpha=0.75, legend=True)\n",
    "predict_df[time_slice].plot(ax=ax, lw=0.75)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "_ = ax.set_ylabel('Temperature [C]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2\n",
    "score = (predict_df.corrwith(targets.tmax[predict_slice]) **2).sort_values().to_frame('r2_score')\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108565c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prob_plots\n",
    "\n",
    "fig = prob_plots(X_predict, targets['tmax'], predict_df[score.index.values], shape=(3, 3), figsize=(12, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bcf01",
   "metadata": {},
   "source": [
    "## Zscore\n",
    "\n",
    "Z-Score bias correction is a good technique for target variables with Gaussian probability distributions, such as zonal wind speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34324535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skdownscale.pointwise_models import ZScoreRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='training')\n",
    "# extract 1 point of training data for precipitation and temperature\n",
    "df = (\n",
    "    data.isel(point=0)\n",
    "    .to_dataframe()[['T2max', 'PREC_TOT']]\n",
    "    .rename(columns={'T2max': 'tmax', 'PREC_TOT': 'pcp'})\n",
    ")\n",
    "df['tmax'] -= 273.13\n",
    "df['pcp'] *= 24\n",
    "training= df.resample('1d').first()\n",
    "data = xr.open_zarr('../data/downscale_test_data.zarr.zip', group='targets')\n",
    "        # extract 1 point of training data for precipitation and temperature\n",
    "targets =data.isel(point=0).to_dataframe()[['Tmax', 'Prec']].rename(columns={'Tmax': 'tmax', 'Prec': 'pcp'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainings = training[['tmax']][train_slice]\n",
    "target = targets[['tmax']][train_slice]\n",
    "future = training[['tmax']][predict_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# open a small dataset\n",
    "training = get_sample_data('wind-hist')\n",
    "target = get_sample_data('wind-obs')\n",
    "future = get_sample_data('wind-rcp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias correction using ZScoreRegresssor\n",
    "zscore = ZScoreRegressor()\n",
    "zscore.fit(Trainings, target)\n",
    "fit_stats = zscore.fit_stats_dict_\n",
    "out = zscore.predict(future)\n",
    "predict_stats = zscore.predict_stats_dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the datasets\n",
    "from utils import zscore_ds_plot\n",
    "\n",
    "zscore_ds_plot(training, target, future, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import zscore_correction_plot\n",
    "\n",
    "zscore_correction_plot(zscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd181d",
   "metadata": {},
   "source": [
    "## Automatic parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "train_slice = slice('1980', '1982')  # train time range\n",
    "holdout_slice = slice('1990', '1991')  # prediction time range\n",
    "\n",
    "# bounding box of downscaling region\n",
    "lon_slice = slice(-124.8, -120.0) \n",
    "lat_slice = slice(50, 45)\n",
    "\n",
    "# chunk shape for dask execution (time must be contiguous, ie -1)\n",
    "chunks = {'lat': 10, 'lon': 10, 'time': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129907e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "fnames = [f'http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/tmmx/tmmx_{year}.nc'\n",
    "          for year in range(int(train_slice.start), int(train_slice.stop) + 1)]\n",
    "# open the data and cleanup a bit of metadata\n",
    "obs = xr.open_mfdataset(fnames, engine='pydap',combine='nested', concat_dim='day').rename({'day': 'time'}).drop('crs')\n",
    "\n",
    "obs_subset = obs['air_temperature'].sel(time=train_slice, lon=lon_slice, lat=lat_slice).resample(time='1d').mean().load(scheduler='threads').chunk(chunks)\n",
    "\n",
    "# display\n",
    "display(obs_subset)\n",
    "obs_subset.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b8876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a564571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2ff02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "580eb488",
   "metadata": {},
   "source": [
    "# Add models to list to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import QuantileLinearRegression\n",
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "from mlinsights.mlmodel import QuantileMLPRegressor\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARRM(n_bins=7):\n",
    "    return Pipeline([\n",
    "        ('')\n",
    "    ])\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "qqwargs = {'n_quantiles': 1e6, 'copy': True, 'subsample': 1e6}\n",
    "n_bins = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa52b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training[['temp']]['1980': '2000'].values\n",
    "y = targets[['temp']]['1980': '2000'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a1df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skdownscale.pointwise_models import PureAnalog, AnalogRegression\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GARD: PureAnalog-best-1': PureAnalog(kind='best_analog', n_analogs=1),\n",
    "    'GARD: PureAnalog-sample-10': PureAnalog(kind='sample_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-10': PureAnalog(kind='weight_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-100': PureAnalog(kind='weight_analogs', n_analogs=100),\n",
    "    'GARD: PureAnalog-mean-10': PureAnalog(kind='mean_analogs', n_analogs=10),\n",
    "    'GARD: AnalogRegression-100': AnalogRegression(n_analogs=100),\n",
    "    'GARD: LinearRegression': LinearRegression(),\n",
    "    'BCSD: BcsdTemperature': BcsdTemperature(return_anoms=False),\n",
    "    'Sklearn: RandomForestRegressor': RandomForestRegressor(random_state=0),\n",
    "    'Sklearn: QuantileMLPRegressor': QuantileMLPRegressor(),\n",
    "    'Sklearn: QuantileLinearRegression': QuantileLinearRegression(),\n",
    "    #'Sklearn: PiecewiseRegressor': PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='kmeans'))\n",
    "    \n",
    "}\n",
    "\n",
    "train_slice = slice('1980-01-01', '1989-12-31')\n",
    "predict_slice = slice('1990-01-01', '1999-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c13b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training / prediction data\n",
    "X_train = training[['temp']][train_slice]\n",
    "y_train = targets[['temp']][train_slice]\n",
    "X_predict = training[['temp']][predict_slice]\n",
    "\n",
    "# Fit all models\n",
    "for key, model in models.items():\n",
    "    print(model)\n",
    "    if 'PiecewiseRegressor' in key: # does't work\n",
    "        model.fit(X_train.values.reshape((len(X_train),1)), y_train.values.reshape((len(y_train),)))\n",
    "    if 'QuantileLinearRegression' in key:\n",
    "        model.fit(X_train.values.reshape((len(X_train.values),1)), y_train.values.reshape((len(y_train.values),)))\n",
    "    else:\n",
    "        model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8649a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predicted results in this dataframe\n",
    "predict_df = pd.DataFrame(index = X_predict.index)\n",
    "\n",
    "for key, model in models.items():\n",
    "    print('key')\n",
    "    print(key)\n",
    "    print('model')\n",
    "    print(model)\n",
    "    if 'PiecewiseRegressor' in key: # does't work\n",
    "        predict_df[key] = model.predict(X_predict)\n",
    "    if type(model.predict(X_predict))==pd.core.frame.DataFrame:\n",
    "        if len(list(model.predict(X_predict).columns))>1:\n",
    "            predict_df[key] = model.predict(X_predict)[['pred']].values # [['pred']] added to deal with piecewise regressor\n",
    "        else:\n",
    "            predict_df[key] = model.predict(X_predict)\n",
    "    else:\n",
    "        predict_df[key] = model.predict(X_predict) # [['pred']] added to deal with piecewise regressor\n",
    "\n",
    "# show a table of the predicted data\n",
    "display(predict_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f10cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict.values.reshape((len(X_predict.values),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 3.5))\n",
    "targets['temp'][time_slice].plot(ax=ax, label='target', c='k', lw=1, alpha=0.75, legend=True, zorder=10)\n",
    "X_predict['temp'][time_slice].plot(label='original', c='grey', ax=ax, alpha=0.75, legend=True)\n",
    "predict_df[time_slice].plot(ax=ax, lw=0.75)\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "_ = ax.set_ylabel('Temperature [C]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08051ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2\n",
    "score = (predict_df.corrwith(targets.tmax[predict_slice]) **2).sort_values().to_frame('r2_score')\n",
    "display(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import prob_plots\n",
    "\n",
    "fig = prob_plots(X_predict, targets['temp'], predict_df[score.index.values], shape=(4, 3), figsize=(16, 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be863db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe06475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
