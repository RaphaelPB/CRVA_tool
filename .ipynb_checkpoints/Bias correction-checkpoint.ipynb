{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81928141",
   "metadata": {},
   "source": [
    "Bias correction based on the [python Package scikit-downscale](https://github.com/pangeo-data/scikit-downscale/blob/main/examples/2020ECAHM-scikit-downscale.ipynb)\n",
    "\n",
    "Here, only the pointwise method to apply\n",
    "\n",
    "First, comparison of observation and modelled data's behaviour\n",
    "        Comparison of the distribution of data with boxplots\n",
    "        Evolution through time with graphs\n",
    "\n",
    "Second, BC at each meteorological station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511ff44",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090f897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# climate variable wanted\n",
    "# observation data wanted\n",
    "\n",
    "# modeled data wanted\n",
    "# station of observation wanted \n",
    "\n",
    "climate_var = 'pr' # 'tas'\n",
    "\n",
    "# precipitation : 'pr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ee0b7",
   "metadata": {},
   "source": [
    "# Packages and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd92a25",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe408c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3f8bc",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e2efed",
   "metadata": {},
   "source": [
    "### Data treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829de48",
   "metadata": {},
   "source": [
    "#### NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9fedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to import the NOAA observation data\n",
    "def import_treat_obs_NOAA():\n",
    "    # path where the file is placed\n",
    "    path_file_NOAA = r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\NOAA-ClimateDataOnline\\3370204.csv'\n",
    "    # read the information in the file\n",
    "    data_obs_NOAA = pd.read_csv(path_file_NOAA)\n",
    "    # unit of PRCP are mm\n",
    "    # unit of temperature are degrees Celsius\n",
    "    \n",
    "    # add Year, month and season columns for graphs\n",
    "    Year = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    Month = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    Season = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    for i in np.arange(0,len(data_obs_NOAA[['DATE']].values)):\n",
    "        Year[i]=int(Year[i][0:4])\n",
    "        Month[i]=int(Month[i][5:7])\n",
    "        if int(Month[i])>3 and int(Month[i])<10: # dry season in Mozambique is between April and September\n",
    "            Season[i]='Dry'\n",
    "        else:# humid season is between October and March\n",
    "            Season[i]='Humid'\n",
    "\n",
    "    data_obs_NOAA['Year'] = Year\n",
    "    data_obs_NOAA['Month'] = Month\n",
    "    data_obs_NOAA['Season'] = Season\n",
    "    return data_obs_NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to find which meteo stations are the closest to the projects of interest\n",
    "# find which stations are of interest, which one are the closest to the coordinates of the projects\n",
    "def find_closest_meteo_station_to_projects(data_obs_NOAA,name_projects):\n",
    "    # save in a dataframe name, latitudes and longitudes informations for each station\n",
    "    df_station_NOAA=data_obs_NOAA.loc[:, [\"NAME\", \"LATITUDE\",\"LONGITUDE\"]]\n",
    "    df_station_NOAA.drop_duplicates(inplace = True) # drop duplicates to only have name of the towns and latitudes and longitudes\n",
    "    df_station_NOAA.reset_index(drop=True,inplace = True)  # drop = true avoids to keep the former index\n",
    "    # inplace = True modifies the original dataframe\n",
    "    \n",
    "    name_closest_station_to_project = [] # create an empty list to contain the name of the closest station to each project\n",
    "    index_closest_station_to_project = []\n",
    "    for (i,name_project) in zip(np.arange(0,len(name_projects)),name_projects):\n",
    "        # calculate difference between the different coordinates\n",
    "        df_station_NOAA['Diff latitude project '+str(i)] = abs(abs(df_station_NOAA['LATITUDE']) - abs(lat_projects[i]))\n",
    "        df_station_NOAA['Diff longitude project '+str(i)] = abs(abs(df_station_NOAA['LONGITUDE']) - abs(lon_projects[i]))\n",
    "        df_station_NOAA['Diff coordinates project '+str(i)] = df_station_NOAA['Diff latitude project '+str(i)]+df_station_NOAA['Diff longitude project '+str(i)]\n",
    "        # register the name of the stations that are the closest to the projects and the index in df_station_NOAA corresponding to those closest stations\n",
    "        name_closest_station = df_station_NOAA['NAME'].iloc[np.where(df_station_NOAA['Diff coordinates project '+str(i)]==min(df_station_NOAA['Diff coordinates project '+str(i)]))[0][0]]\n",
    "        name_closest_station_to_project.append(name_closest_station)\n",
    "        index_closest_station_to_project.append(np.where(df_station_NOAA['Diff coordinates project '+str(i)]==min(df_station_NOAA['Diff coordinates project '+str(i)]))[0][0])\n",
    "        print('The closest meteorological station to the project '+name_project+' is the one located in '+name_closest_station)\n",
    "\n",
    "\n",
    "    # take off the duplicates from the list of name of station which are the closest to our projects and the indexes in the dataframe of those corresponding stations\n",
    "    name_closest_station_to_project_without_duplicates=list(set(name_closest_station_to_project))\n",
    "    index_closest_station_to_project_without_duplicates=list(set(index_closest_station_to_project))\n",
    "    print('\\n')\n",
    "    print('The coordinates for the meteorological stations which are the closest to the project of interest are :')\n",
    "    print('\\n')\n",
    "    for k in np.arange(len(index_closest_station_to_project_without_duplicates)):\n",
    "        print('Name '+df_station_NOAA['NAME'][index_closest_station_to_project_without_duplicates[k]])\n",
    "        print('Longitude '+str(df_station_NOAA['LONGITUDE'][index_closest_station_to_project_without_duplicates[k]]))\n",
    "        print('Latitude '+str(df_station_NOAA['LATITUDE'][index_closest_station_to_project_without_duplicates[k]]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e6878e",
   "metadata": {},
   "source": [
    "#### NEX-GDDP-CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a38d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_treat_modeled_NEX_GDDP_CMIP6(climate_var):\n",
    "    # import data\n",
    "    #path_NEX_GDDP_CMIP6_EmplacementStation = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file\\'+climate_var+'\\pr_mm_per_day_day_1970-2014\\EmplacementStationNOAA_pr_1970-2014_projectsMoz.csv'\n",
    "    #out_path = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file'\n",
    "    path_NEX_GDDP_CMIP6_EmplacementStation=os.path.join(r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file',climate_var,climate_var+'_mm_per_day_day_1970-2014','EmplacementStationNOAA_'+climate_var+'_1970-2014_projectsMoz.csv')\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation = pd.read_csv(path_NEX_GDDP_CMIP6_EmplacementStation)\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation = data_NEX_GDDP_CMIP6_EmplacementStation.drop(['Experiment','Latitude','Longitude'],axis=1)\n",
    "    \n",
    "    # add Year, month and season columns for graphs\n",
    "    Year = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    Month = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    Season = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    \n",
    "    for i in np.arange(0,len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values)):\n",
    "        Year[i]=int(Year[i][6:10])\n",
    "        Month[i]=int(Month[i][3:5])\n",
    "        if int(Month[i])>3 and int(Month[i])<10: # dry season in Mozambique is between April and September\n",
    "            Season[i]='Dry'\n",
    "        else:# humid season is between October and March\n",
    "            Season[i]='Humid'\n",
    "\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Year'] = Year\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Month'] = Month\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Season'] = Season\n",
    "    \n",
    "    return data_NEX_GDDP_CMIP6_EmplacementStation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a96b2",
   "metadata": {},
   "source": [
    "### Compare climate variable at one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_(climate_var,data_obs_NOAA,name_station):\n",
    "    # meteorological data from NOAA\n",
    "    # unit of precipitation is mm\n",
    "    if (climate_var == 'pr') or (climate_var == 'Pr') or (climate_var == 'PR') or (climate_var == 'precipitation') or (climate_var == 'Precipitation') or (climate_var == 'PRECIPITATION'):\n",
    "        title_column_obs = 'PRCP'\n",
    "        title_column_modeled = 'Mean of the daily precipitation rate mm/day'\n",
    "        climate_var_full_name = 'precipitation'\n",
    "        climate_var_abreviation = 'pr'\n",
    "        climate_var_obs_NOAA_station=data_obs_NOAA[['DATE',title_column_obs,'Year','Month','Season']][data_obs_NOAA['NAME']==name_station].reset_index(drop=True)\n",
    "        # data from NEX GDDP CMIP6 at the emplacement of the station\n",
    "        data_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6(climate_var_abreviation)\n",
    "        data_NEX_GDDP_CMIP6_EmplacementStation_station=data_NEX_GDDP_CMIP6_EmplacementStation[data_NEX_GDDP_CMIP6_EmplacementStation['Name station']==name_station]\n",
    "        list_models_NEX_GDDP_CMIP6 = list(set(data_NEX_GDDP_CMIP6_EmplacementStation_station['Model']))\n",
    "        data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station.drop(['Name station'],axis =1)\n",
    "    # Select only part of the dataframe, to have the same period in both\n",
    "    (climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station,start_year,stop_year)=take_out_years_not_overlaping(climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station)\n",
    "    \n",
    "    # do box plot for different model\n",
    "    plot_boxplots(climate_var_abreviation,data_NEX_GDDP_CMIP6_EmplacementStation_station,climate_var_obs_NOAA_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6)\n",
    "\n",
    "    # graphs\n",
    "    \n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly sum',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly average',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly median',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)    \n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal sum',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal average',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal median',climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year,list_models_NEX_GDDP_CMIP6)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_out_years_not_overlaping(climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station):\n",
    "    if max(climate_var_obs_NOAA_station['Year'])>max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])        \n",
    "    else:\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year,stop_year)]\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year,stop_year)]\n",
    "\n",
    "    if max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>max(climate_var_obs_NOAA_station['Year']):\n",
    "        stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    else:\n",
    "        stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    if min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>min(climate_var_obs_NOAA_station['Year']):\n",
    "        start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    else:\n",
    "        start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year, stop_year)]\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year, stop_year)]\n",
    "    \n",
    "    return climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station,start_year,stop_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8566f",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(climate_var,data_NEX_GDDP_CMIP6_EmplacementStation_station,climate_var_obs_NOAA_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6):\n",
    "    if climate_var == 'pr':\n",
    "        column_name_obs = 'PRCP'\n",
    "    # constructing the dictionarry for the boxplot\n",
    "    data_boxplot = []\n",
    "    labels_boxplot=[]\n",
    "    colors = []\n",
    "    # add observational data\n",
    "    data_of_interest = climate_var_obs_NOAA_station[column_name_obs].values\n",
    "    data_filtered = data_of_interest[~np.isnan(data_of_interest)]\n",
    "    data_boxplot.append(data_filtered)\n",
    "    labels_boxplot.append('Obs NOAA')\n",
    "    #colors.append('pink')\n",
    "    for model in list_models_NEX_GDDP_CMIP6:\n",
    "        data_of_interest = data_NEX_GDDP_CMIP6_EmplacementStation_station['Mean of the daily precipitation rate mm/day'][data_NEX_GDDP_CMIP6_EmplacementStation_station['Model']==model].values\n",
    "        data_filtered = data_of_interest[~np.isnan(data_of_interest)]\n",
    "        data_boxplot.append(data_filtered)\n",
    "        labels_boxplot.append(model)\n",
    "        #colors.append('lightblue')\n",
    "\n",
    "\n",
    "    # problem where there are NaN in a series of values, does not produce a boxplot\n",
    "    # need to take the Nan out\n",
    "\n",
    "    # count how much Nan and for which models\n",
    "\n",
    "    several_boxplot(data_boxplot,labels_boxplot,start_year,stop_year,'precipitation','NOAA','NEX-GDDP-CMIP6','Mean of the daily precipitation rate mm/day','Observational data vs Models','no need for path for the moment but then out_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function several_boxplot is a function to plot several boxplots in one graph (to compare them)\n",
    "# the inputs:\n",
    "#    the data in a certainn format, the length should be the same as the text_label\n",
    "#    text_label contains the name of each set of data to be presented in boxplots\n",
    "#   All the following inputs are used for titles or labels\n",
    "#    climate_var is the climate variable of interest (example:'precipitation')\n",
    "#    source_obs is the source of the observation data\n",
    "#    source_modeled is the source of the modeled data\n",
    "#    full_name_climate_var is the complete name of the climate variable of interest (example:'Mean of the daily precipitation rate mm/day')\n",
    "#    y_label_text is the label for the y axis (example:'Observational data vs Models')\n",
    "#    path is the out_path where to register data\n",
    "def several_boxplot(data_boxplot,text_label,start_year,stop_year,climate_var,source_obs,source_modeled,full_name_climate_var,y_label_text,path_figure):\n",
    "    fig, ax = plt.subplots()\n",
    "    colors = []\n",
    "    bp=plt.boxplot(data_boxplot,labels = text_label,notch=True, whis =(10,90),patch_artist = True,showfliers=False)\n",
    "    # showfliers=False permits to have the boxplot without outliers\n",
    "    # documentation about boxplot\n",
    "    # ... present boxplot over the period for each models\n",
    "    # this functions returns varius parameters of the boxplot in the dict_boxplot. This funcitons also returns an image of it\n",
    "    # here, numpy_array is a vector. But can also include array with several columns. Each columns will have a boxplot\n",
    "    # 'notch' is true to enhance part where the median is\n",
    "    # 'whis' is the percentile value for the whiskers, every data out of the range indicted by those 2 floats are represented as points\n",
    "    # 'widths' determine width of the boxes\n",
    "    # 'patch_artist' colors the boxplots\n",
    "    # 'labels' gives a name to every column included in the data part\n",
    "\n",
    "    # prepare color depending on content of labels\n",
    "    for i in np.arange(0,len(text_label)):\n",
    "        if ('obs' in text_label[i]) or ('Obs' in text_label[i]):\n",
    "            colors.append('lightpink')\n",
    "        else:\n",
    "            colors.append('lightblue')\n",
    "    # fill colors with vector just prepared\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    plt.xticks(rotation=90) # to have the labels vertical\n",
    "    # label axes and figure\n",
    "    plt.xlabel(y_label_text)\n",
    "    plt.ylabel(full_name_climate_var)\n",
    "    plt.title('Boxplot presenting ditribution of '+climate_var+' data of the '+source_obs+' observation\\ndata vs '+source_modeled+' modeled data between '+str(start_year)+' and '+str(stop_year))\n",
    "    # add legend\n",
    "    ax.legend([bp['boxes'][0],bp['boxes'][1]], ['Observed', 'Modeled'])\n",
    "    #title_png = climate_var+'_'+source_obs+'_'+source_modeled+'.png'\n",
    "    #plt.savefig(os.path.join(path_figure,'figures','Boxplots',title_png),format ='png') # savefig or save text must be before plt.show. for savefig, format should be explicity written\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# this function is to plot the statistics of the evolution of the climate variable of interest for a certain station\n",
    "def plot_(data_obs,data_model,stats,climate_var,title_column_obs,title_column_modeled,source_obs,source_modeled,name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6):\n",
    "    if stats == 'Yearly sum':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].sum().rename(columns = {title_column_modeled:'Yearly '+climate_var+' mm/year'})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].sum()\n",
    "    if stats == 'Yearly average':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].mean().rename(columns = {title_column_modeled:'Average yearly '+climate_var+' mm/day'})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].mean()\n",
    "        #plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')    \n",
    "        #plt.ylim(0,1.5)\n",
    "        #plt.xlabel('Years')\n",
    "        #plt.ylabel('Average yearly '+climate_var+' mm/day')\n",
    "        #plt.title('Average yearly '+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at name station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "    if stats == 'Yearly median':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].median().rename(columns = {title_column_modeled:'Median yearly '+climate_var+' mm/day'})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].median()\n",
    "        #plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')    \n",
    "        plt.ylim(0,1.5)\n",
    "        #plt.xlabel('Years')\n",
    "        #plt.ylabel('Median yearly '+climate_var+' mm/day')\n",
    "        #plt.title('Median yearly '+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at name station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "    if 'Seasonal' in stats:\n",
    "        # convert Years in columns 'Year' for a future aggregation of two columns\n",
    "        #data_model['Year'] = data_model[['Year']].applymap(str)\n",
    "        #data_obs['Year'] = data_obs[['Year']].applymap(str)\n",
    "        \n",
    "        if stats == 'Seasonal sum':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].sum().rename(columns = {title_column_modeled:stats+' '+climate_var+' mm/season each year'})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                #yearly_climate_var_NEX_GDDP_CMIP6[\"Time\"] = yearly_climate_var_NEX_GDDP_CMIP6[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "                #yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Time') # set the column with both information as the new column\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year')\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].sum()\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.reset_index() # put Year and Season as columns\n",
    "            #climate_var_yearly_obs[\"Time\"] = climate_var_yearly_obs[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.set_index('Year') # set the colomun with both information as the new column\n",
    "            plt.xticks(np.arange(start_year, stop_year, step=5))  # Set label locations.\n",
    "            #plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')\n",
    "            #plt.xlabel('Years')\n",
    "            #plt.ylabel(stats+climate_var+' mm/year')\n",
    "            #plt.title(stats+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "        if stats == 'Seasonal average':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].mean().rename(columns = {title_column_modeled:stats+' '+climate_var+' mm/day'})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                #yearly_climate_var_NEX_GDDP_CMIP6[\"Time\"] = yearly_climate_var_NEX_GDDP_CMIP6[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year') # set the colomun with both information as the new column\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].mean()\n",
    "            \n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.reset_index() # put Year and Season as columns\n",
    "            #climate_var_yearly_obs[\"Time\"] = climate_var_yearly_obs[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.set_index('Year') # set the colomun with both information as the new column\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "            plt.xticks(np.arange(start_year, stop_year, step=5))  # Set label locations.\n",
    "            #plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')    \n",
    "            #plt.ylim(0,1.5)\n",
    "            #plt.xlabel('Years')\n",
    "            #plt.ylabel(stats+climate_var+' mm/day')\n",
    "            #plt.title(stats+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at name station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "        if stats == 'Seasonal median':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].median().rename(columns = {title_column_modeled:stats+' '+climate_var+' mm/day'})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                #yearly_climate_var_NEX_GDDP_CMIP6[\"Time\"] = yearly_climate_var_NEX_GDDP_CMIP6[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year') # set the colomun with both information as the new column\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "                \n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].median()\n",
    "            #plt.plot(climate_var_yearly_obs.index.levels[0],climate_var_yearly_obs,'k',label='observation')    \n",
    "            #plt.ylim(0,1.5)\n",
    "            #plt.xlabel('Years')\n",
    "            #plt.ylabel(stats+climate_var+' mm/day')\n",
    "            #plt.title(stats+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at name station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "\n",
    "        # managed the observation data for seasonal stats\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.reset_index() # put Year and Season as columns\n",
    "            #climate_var_yearly_obs[\"Time\"] = climate_var_yearly_obs[[\"Year\", \"Season\"]].apply(\"-\".join, axis=1) # define a new column containing Year and Season information\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.set_index('Year') # set the colomun with both information as the new column\n",
    "            climate_var_yearly_obs = climate_var_yearly_obs.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "            plt.xticks(np.arange(start_year, stop_year, step=5))  # Set label locations.\n",
    "    plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel(stats+' '+climate_var+' mm/year')\n",
    "    plt.title(stats+' '+climate_var+' mm accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f2771",
   "metadata": {},
   "source": [
    "# Project information\n",
    "Those project were chosen based on the interest of the company (decided with SIPA and RAPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074319a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_projects_data = np.array(['WTP_Mutua_EIB', 'Gorongosa_EIB', 'Chimoio_WTP_EIB', 'Pemba_EIB'])\n",
    "name_projects = pd.Series(name_projects_data)\n",
    "\n",
    "lon_projects_data = np.array([34.5927839939706, 34.07824286310398 , 33.47333313659342, 40.52545156033736])\n",
    "lon_projects = pd.Series(lon_projects_data)\n",
    "\n",
    "lat_projects_data = np.array([-19.495079648575242, -18.68063728746643, -19.125095255188334,-12.973942656747809])\n",
    "lat_projects = pd.Series(lat_projects_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b5031",
   "metadata": {},
   "source": [
    "# Comparaison between observational data and modeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4639cc",
   "metadata": {},
   "source": [
    "## Observation data coming from the place\n",
    "\n",
    "Excel 'Dados_e_grafico_P_812.xls', was given by SIPA, who has received it from André Görgens (Cosnultant, Water resources Management, Zutari) in an email, on the 20th of June 2023.\n",
    "\n",
    "Those data can be use as precipitation observation data for the town of Gorongosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_SIPA = r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\DirecltyfromMoz\\Dados_e_grafico_P_812.xls'\n",
    "obs_SIPA=pd.read_excel(path_file_SIPA)\n",
    "obs_SIPA # need to register them in a more convenient way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12043c4f",
   "metadata": {},
   "source": [
    "## Observational data coming from NOAA\n",
    "[Global Historical Climatology Network daily (GHCNd) | National Centers for Environmental Information (NCEI) (noaa.gov)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily), climate data online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_NOAA=import_treat_obs_NOAA()\n",
    "data_obs_NOAA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b210274",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_meteo_station_to_projects(data_obs_NOAA,name_projects)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bda3814e",
   "metadata": {},
   "source": [
    "# Data at the same emplacement coming from NEX GDDP CMIP6\n",
    " \n",
    "[NEX-GDDP-CMIP6](https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6) data are CMIP6 data, bias corrected by NASA, with [Global Meteorological Forcing Dataset (GMFD) for Land Surface Modeling](https://aquaknow.jrc.ec.europa.eu/en/content/global-meteorological-forcing-dataset-land-surface-modeling-pgfprinceton) (which are [reanalysis data](https://www.researchgate.net/publication/200472354_Development_of_a_50-Year_High-Resolution_Global_Dataset_of_Meteorological_Forcings_for_Land_Surface_Modeling)). More information about NEX-GDDP-CMIP6 data in the [technical note](https://www.nccs.nasa.gov/sites/default/files/NEX-GDDP-CMIP6-Tech_Note.pdf).\n",
    " \n",
    " \n",
    " With information found with precedent file, the values produced by NEX-GDDP-CMIP6 at the emplacement of the meteorological stations of interest are compiled in a file named EmplacementStationNOAA_pr_1970-2014_projectsMoz.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6(climate_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9695b52",
   "metadata": {},
   "source": [
    "## Compare Pemba station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fbe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select climate variable and meteorological station; select data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ef3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'PEMBA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'BEIRA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'CHIMOIO, MZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a1727",
   "metadata": {},
   "source": [
    "# Note concerning distribution of precipitation data\n",
    "Observational data over this period much bigger than modeled data. However, mediane of all set of data close to 0 --> much more smaller values than big values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae4103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot temporal evolution accross years for each models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eba970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot yearly average precipitation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af492760",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(pr_obs_NOAA_to_compare_pemba,data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba,'sum','precipitation',pr_obs_NOAA_to_compare_pemba.columns[2],data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba.columns[6],'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db685b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(pr_obs_NOAA_to_compare_pemba,data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba,'average','precipitation',pr_obs_NOAA_to_compare_pemba.columns[2],data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba.columns[6],'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ce218",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_(pr_obs_NOAA_to_compare_pemba,data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba,'median','precipitation',pr_obs_NOAA_to_compare_pemba.columns[2],data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba.columns[6],'NOAA','NEX-GDDP-CMIP6','PEMBA, MZ',start_year,stop_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfbe6b",
   "metadata": {},
   "source": [
    "# BIAS CORRECTION - POINT WISE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from utils import get_sample_data\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece6836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date1 = pr_obs_NOAA_to_compare_pemba['DATE'].values\n",
    "pr_obs_NOAA_to_compare2_pemba = pr_obs_NOAA_to_compare_pemba.copy(deep=True)\n",
    "for i in np.arange(0,len(pr_obs_NOAA_to_compare_pemba)):\n",
    "    pr_obs_NOAA_to_compare2_pemba['DATE'][i] = datetime.strptime(Date1[i], '%Y-%M-%d').date() #Date1[0][8:10] +'-'+Date1[i][5:7]+'-'+Date1[i][0:4]\n",
    "pr_obs_NOAA_to_compare2_pemba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e329127",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_obs_NOAA_to_compare2_pemba=pr_obs_NOAA_to_compare2_pemba.drop(['NAME','Year','Month'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28326f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date1 = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba['Date'].values\n",
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba.copy(deep=True).reset_index()\n",
    "for i in np.arange(0,len(data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba)):\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Date'][i] = datetime.strptime(Date1[i][6:10]+'-'+Date1[i][3:5]+'-'+Date1[i][0:2], '%Y-%M-%d').date()\n",
    "    #print(data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Date'][i])\n",
    "# .date() to avoid having the hours in the datetime\n",
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba # 2h54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85134970",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba=data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba.drop(['Name station','Experiment','Latitude','Longitude','Year','index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba=data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3124316",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba=data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba.drop('Month',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a51c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba[data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Model']=='ACCESS-CM2'].drop('Model',axis=1).rename(columns = {'Date':'time'}) # training data is meant to represent data from a typical climate model \n",
    "targets = pr_obs_NOAA_to_compare2_pemba.drop('Year',axis=1).rename(columns = {'DATE':'time'}) # the targets data is meant to represent our \"observations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f709c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample data\n",
    "training = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba[data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Model']=='ACCESS-CM2'].drop('Model',axis=1).rename(columns = {'Date':'time','Mean of the daily precipitation rate mm/day':'pcp'}).set_index('time') # training data is meant to represent data from a typical climate model \n",
    "targets = pr_obs_NOAA_to_compare2_pemba.rename(columns = {'DATE':'time','PRCP':'pcp'}).set_index('time') # the targets data is meant to represent our \"observations\"\n",
    "# to have the same size of vectors\n",
    "training=training[training.index.isin(list(targets.dropna().index))]\n",
    "targets = targets.dropna()\n",
    "# print a table of the training/targets data\n",
    "#display(pd.concat({'training': training, 'targets': targets}, axis=1))\n",
    "display(pd.DataFrame.merge(training,targets,on='time'))\n",
    "\n",
    "# make a plot of the temperature and precipitation data\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(8, 6), sharex=True) # nrows = 2 of temp\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "# plot-temperature\n",
    "#training[time_slice]['tmax'].plot(ax=axes[0], label='training')\n",
    "#targets[time_slice]['tmax'].plot(ax=axes[0], label='targets')\n",
    "#axes[0].legend()\n",
    "#axes[0].set_ylabel('Temperature [C]')\n",
    "\n",
    "# plot-precipitation\n",
    "i = 0 # 1 if temperature\n",
    "training[time_slice]['pcp'].plot(ax=axes[0],label='training')\n",
    "targets[time_slice]['pcp'].plot(ax=axes[0], label='targets')\n",
    "axes[0].legend()\n",
    "_ = axes[0].set_ylabel('Precipitation [mm/day]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training=training.set_index('time')\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlinsights.mlmodel import PiecewiseRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31df339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory data analysis for arrm model\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "\n",
    "def ARRM(n_bins=7):\n",
    "    return Pipeline([\n",
    "        ('')\n",
    "    ])\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "qqwargs = {'n_quantiles': int(1e6), 'copy': True, 'subsample': int(1e6)} # add int for n_quantiles and subsample to avoid\n",
    "# foloowing problem:  InvalidParameterError: The 'n_quantiles' parameter of QuantileTransformer must be an int in the range [1, inf). Got 1000000.0 instead.\n",
    "n_bins = 7\n",
    "\n",
    "X = training[['pcp']]['1980': '2000'].values\n",
    "y = targets[['pcp']]['1980': '2000'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xqt = QuantileTransformer(**qqwargs).fit(X_train)\n",
    "\n",
    "Xq_train = xqt.transform(X_train)\n",
    "Xq_test = xqt.transform(X_test)\n",
    "\n",
    "yqt = QuantileTransformer(**qqwargs).fit(y_train)\n",
    "yq_train = xqt.transform(y_train)[:, 0]\n",
    "yq_test = xqt.transform(y_test)[:, 0]\n",
    "\n",
    "\n",
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='quantile'))\n",
    "# model.fit(Xq_train, yq_train)\n",
    "# predq = model.predict(Xq_test)\n",
    "# pred = qt.inverse_transform(predq.reshape(-1, 1))\n",
    "\n",
    "y_train = y_train[:, 0]\n",
    "for strat in ['kmeans', 'uniform', 'quantile']:\n",
    "    model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=strat))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(strat, model.score(X_test, y_test))\n",
    "    \n",
    "model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='kmeans'))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(X_train, y_train, c=c['train'], s=5, label='train')\n",
    "plt.scatter(X_test, y_test, c=c['test'], s=5, label='test')\n",
    "ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(np.sort(X_train, axis=0), np.sort(y_train, axis=0), c=c['train'], s=5, label='train')\n",
    "plt.scatter(np.sort(X_test, axis=0), np.sort(y_test, axis=0), c=c['test'], s=5, label='test')\n",
    "plt.plot(np.sort(X_test, axis=0), np.sort(pred, axis=0), c=c['predict'], lw=2, label='predictions')\n",
    "ax.legend()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# ax.plot(Xq_test[:, 0], yq_test, \".\", label='data', c=c['test'])\n",
    "# ax.plot(Xq_test[:, 0], predq, \".\", label=\"predictions\", c=c['predict'])\n",
    "# ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(X_test[:, 0], y_test, \".\", label='data', c=c['test'])\n",
    "ax.plot(X_test[:, 0], pred, \".\", label=\"predictions\", c=c['predict'])\n",
    "ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ea7a2",
   "metadata": {},
   "source": [
    "Scikit-downscale, the ability to test and compare arbitrary combinations of models under a common interface. This allows us to try many combinations of models and parameters, choosing only the best combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b77467bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skdownscale\n",
    "from skdownscale.pointwise_models import bcsd # name of the model to write \n",
    "# C:\\Users\\CLMRX\\AppData\\Local\\miniconda3\\envs\\geodata\\Lib\\site-packages\\skdownscale\\pointwise_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65323ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af910d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skdownscale.pointwise_models import PureAnalog, AnalogRegression\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GARD: PureAnalog-best-1': PureAnalog(kind='best_analog', n_analogs=1),\n",
    "    'GARD: PureAnalog-sample-10': PureAnalog(kind='sample_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-10': PureAnalog(kind='weight_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-100': PureAnalog(kind='weight_analogs', n_analogs=100),\n",
    "    'GARD: PureAnalog-mean-10': PureAnalog(kind='mean_analogs', n_analogs=10),\n",
    "    'GARD: AnalogRegression-100': AnalogRegression(n_analogs=100),\n",
    "    'GARD: LinearRegression': LinearRegression(),\n",
    "    'BCSD: BcsdTemperature': BcsdTemperature(return_anoms=False),\n",
    "    'Sklearn: RandomForestRegressor': RandomForestRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "#train_slice = slice('1980-01-01', '1989-12-31')\n",
    "#predict_slice = slice('1990-01-01', '1999-12-31')\n",
    "train_slice = slice(datetime.date(1980, 1, 1), datetime.date(1989, 12, 31))\n",
    "predict_slice = slice(datetime.date(1990, 1, 1), datetime.date(1999, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ae841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training / prediction data\n",
    "X_train = training[['pcp']][train_slice]\n",
    "y_train = targets[['pcp']][train_slice]\n",
    "X_predict = training[['pcp']][predict_slice]\n",
    "\n",
    "# Fit all models\n",
    "for key, model in models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba824db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['1973-01-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa87a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7b4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d73784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
