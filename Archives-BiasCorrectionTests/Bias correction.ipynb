{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81928141",
   "metadata": {},
   "source": [
    "Bias correction based on the [python Package scikit-downscale](https://github.com/pangeo-data/scikit-downscale/blob/main/examples/2020ECAHM-scikit-downscale.ipynb)\n",
    "\n",
    "Here, only the pointwise method to apply\n",
    "\n",
    "First, comparison of observation and modelled data's behaviour\n",
    "        Comparison of the distribution of data with boxplots\n",
    "        Evolution through time with graphs\n",
    "\n",
    "Second, BC at each meteorological station"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3511ff44",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090f897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# climate variable wanted\n",
    "# observation data wanted\n",
    "\n",
    "# modeled data wanted\n",
    "# station of observation wanted \n",
    "\n",
    "climate_var = 'pr' # 'tas'\n",
    "\n",
    "# precipitation : 'pr'\n",
    "\n",
    "name_station = 'BEIRA, MZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ee0b7",
   "metadata": {},
   "source": [
    "# Packages and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd92a25",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe408c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a3f8bc",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5f3fc",
   "metadata": {},
   "source": [
    "### Data treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047b0d36",
   "metadata": {},
   "source": [
    "#### NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2caf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to import the NOAA observation data\n",
    "def import_treat_obs_NOAA():\n",
    "    # path where the file is placed\n",
    "    path_file_NOAA = r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\NOAA-ClimateDataOnline\\3370204.csv'\n",
    "    # read the information in the file\n",
    "    data_obs_NOAA = pd.read_csv(path_file_NOAA)\n",
    "    # unit of PRCP are mm\n",
    "    # unit of temperature are degrees Celsius\n",
    "    \n",
    "    # add Year, month and season columns for graphs\n",
    "    Year = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    Month = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    Season = data_obs_NOAA[['DATE']].values.reshape(len(data_obs_NOAA[['DATE']].values),)\n",
    "    for i in np.arange(0,len(data_obs_NOAA[['DATE']].values)):\n",
    "        Year[i]=int(Year[i][0:4])\n",
    "        Month[i]=int(Month[i][5:7])\n",
    "        if int(Month[i])>3 and int(Month[i])<10: # dry season in Mozambique is between April and September\n",
    "            Season[i]='Dry'\n",
    "        else:# humid season is between October and March\n",
    "            Season[i]='Humid'\n",
    "\n",
    "    data_obs_NOAA['Year'] = Year\n",
    "    data_obs_NOAA['Month'] = Month\n",
    "    data_obs_NOAA['Season'] = Season\n",
    "    return data_obs_NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d861f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to find which meteo stations are the closest to the projects of interest\n",
    "# find which stations are of interest, which one are the closest to the coordinates of the projects\n",
    "def find_closest_meteo_station_to_projects(data_obs_NOAA,name_projects,lat_projects,lon_projects):\n",
    "    # save in a dataframe name, latitudes and longitudes informations for each station\n",
    "    df_station_NOAA=data_obs_NOAA.loc[:, [\"NAME\", \"LATITUDE\",\"LONGITUDE\"]]\n",
    "    df_station_NOAA.drop_duplicates(inplace = True) # drop duplicates to only have name of the towns and latitudes and longitudes\n",
    "    df_station_NOAA.reset_index(drop=True,inplace = True)  # drop = true avoids to keep the former index\n",
    "    # inplace = True modifies the original dataframe\n",
    "    \n",
    "    name_closest_station_to_project = [] # create an empty list to contain the name of the closest station to each project\n",
    "    index_closest_station_to_project = []\n",
    "    for (i,name_project) in zip(np.arange(0,len(name_projects)),name_projects):\n",
    "        # calculate difference between the different coordinates\n",
    "        df_station_NOAA['Diff latitude project '+str(i)] = abs(abs(df_station_NOAA['LATITUDE']) - abs(lat_projects[i]))\n",
    "        df_station_NOAA['Diff longitude project '+str(i)] = abs(abs(df_station_NOAA['LONGITUDE']) - abs(lon_projects[i]))\n",
    "        df_station_NOAA['Diff coordinates project '+str(i)] = df_station_NOAA['Diff latitude project '+str(i)]+df_station_NOAA['Diff longitude project '+str(i)]\n",
    "        # register the name of the stations that are the closest to the projects and the index in df_station_NOAA corresponding to those closest stations\n",
    "        name_closest_station = df_station_NOAA['NAME'].iloc[np.where(df_station_NOAA['Diff coordinates project '+str(i)]==min(df_station_NOAA['Diff coordinates project '+str(i)]))[0][0]]\n",
    "        name_closest_station_to_project.append(name_closest_station)\n",
    "        index_closest_station_to_project.append(np.where(df_station_NOAA['Diff coordinates project '+str(i)]==min(df_station_NOAA['Diff coordinates project '+str(i)]))[0][0])\n",
    "        print('The closest meteorological station to the project '+name_project+' is the one located in '+name_closest_station)\n",
    "\n",
    "\n",
    "    # take off the duplicates from the list of name of station which are the closest to our projects and the indexes in the dataframe of those corresponding stations\n",
    "    name_closest_station_to_project_without_duplicates=list(set(name_closest_station_to_project))\n",
    "    index_closest_station_to_project_without_duplicates=list(set(index_closest_station_to_project))\n",
    "    print('\\n')\n",
    "    print('The coordinates for the meteorological stations which are the closest to the project of interest are :')\n",
    "    print('\\n')\n",
    "    for k in np.arange(len(index_closest_station_to_project_without_duplicates)):\n",
    "        print('Name '+df_station_NOAA['NAME'][index_closest_station_to_project_without_duplicates[k]])\n",
    "        print('Longitude '+str(df_station_NOAA['LONGITUDE'][index_closest_station_to_project_without_duplicates[k]]))\n",
    "        print('Latitude '+str(df_station_NOAA['LATITUDE'][index_closest_station_to_project_without_duplicates[k]]))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb42d78",
   "metadata": {},
   "source": [
    "#### Gorongosa observation precipitation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00cf3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to import and format data from Gorongosa in a certain format\n",
    "def import_treat_observed_Gorongosa():\n",
    "    \n",
    "    if not os.path.isfile(r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\DirecltyfromMoz\\Precipitation_Gorongosa_reformat.csv'):\n",
    "        path_file_SIPA = r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\DirecltyfromMoz\\Dados_e_grafico_P_812.xls'\n",
    "        obs_SIPA=pd.read_excel(path_file_SIPA)\n",
    "        obs_SIPA # need to register them in a more convenient way\n",
    "\n",
    "        # create dataframe for register data from xls\n",
    "        obs_pr_gorongosa_SIPA = pd.DataFrame()\n",
    "        obs_pr_gorongosa_SIPA['time'] = pd.date_range('1980-01-01','2020-12-31') # create time column\n",
    "        obs_pr_gorongosa_SIPA['time']=pd.to_datetime(obs_pr_gorongosa_SIPA[\"time\"]).dt.strftime(\"%Y-%m-%d\") # convert time information in str format\n",
    "\n",
    "        obs_pr_gorongosa_SIPA['pr'] = np.nan\n",
    "        obs_pr_gorongosa_SIPA = obs_pr_gorongosa_SIPA.set_index('time')\n",
    "\n",
    "        name_column_list = list(obs_SIPA.columns)\n",
    "        name_column_list.remove('Unnamed: 0')\n",
    "\n",
    "        for square_of_data_index in np.where(obs_SIPA['Unnamed: 0']=='Dias')[0]:\n",
    "            print('square_of_data_index '+str(square_of_data_index))\n",
    "            for name_column in name_column_list:\n",
    "                print('name_column '+name_column)\n",
    "                for day in np.arange(1,32,1):\n",
    "                    print('day '+str(day))\n",
    "                    print('---------------')\n",
    "                    date_str = str_year(obs_SIPA.iloc[square_of_data_index-1][name_column][obs_SIPA.iloc[square_of_data_index-1][name_column].rfind('.')+1:len(obs_SIPA.iloc[square_of_data_index-1][name_column])])+'-'+int_to_str_month(obs_SIPA.iloc[square_of_data_index-1][name_column][0:obs_SIPA.iloc[square_of_data_index-1][name_column].rfind('.')])+'-'+str_day(day)\n",
    "                    print('index in pr'+ date_str)\n",
    "                    value_excel = int()\n",
    "                    print('value in excel '+ str(obs_SIPA.iloc[square_of_data_index+day][name_column] ))\n",
    "                    obs_pr_gorongosa_SIPA['pr'].loc[date_str] = obs_SIPA.iloc[square_of_data_index+day][name_column]\n",
    "        # export as a csv\n",
    "        obs_pr_gorongosa_SIPA.to_csv(r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\DirecltyfromMoz\\Precipitation_Gorongosa_reformat.csv')\n",
    "    else: # the reformated file was already produced\n",
    "        obs_pr_gorongosa_SIPA = pd.read_csv(r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\DirecltyfromMoz\\Precipitation_Gorongosa_reformat.csv')\n",
    "        obs_pr_gorongosa_SIPA = obs_pr_gorongosa_SIPA.set_index('time')\n",
    "    return obs_pr_gorongosa_SIPA\n",
    "    \n",
    "# the following functions are used in the former function\n",
    "\n",
    "# int_to_str_month transforms writen month in Portuguese in numbers\n",
    "def int_to_str_month(str_month):\n",
    "    if str_month == 'Out':\n",
    "        int_m = '10'\n",
    "    if str_month == 'Nov':\n",
    "        int_m = '11'     \n",
    "    if str_month == 'Dez':\n",
    "        int_m = '12'\n",
    "    if str_month == 'Jan':\n",
    "        int_m = '01'      \n",
    "    if str_month == 'Fev':\n",
    "        int_m = '02'\n",
    "    if str_month == 'Mar':\n",
    "        int_m = '03'     \n",
    "    if str_month == 'Abr':\n",
    "        int_m = '04'\n",
    "    if str_month == 'Mai':\n",
    "        int_m = '05'\n",
    "    if str_month == 'Jun':\n",
    "        int_m = '06'\n",
    "    if str_month == 'Jul':\n",
    "        int_m = '07'     \n",
    "    if str_month == 'Ago':\n",
    "        int_m = '08'\n",
    "    if str_month == 'Set':\n",
    "        int_m = '09'   \n",
    "    return int_m\n",
    "\n",
    "# str_day transforms the number representing the day into a str\n",
    "def str_day(day):\n",
    "    if day <10:\n",
    "        day = '0'+str(day)\n",
    "    else:\n",
    "        day = str(day)\n",
    "    return day\n",
    "\n",
    "# str_year transforms the abbreviation of the year into a year with 4 digits, in a str format\n",
    "def str_year(year):\n",
    "    if int(year)>=80:\n",
    "        year = '19'+year\n",
    "    else:\n",
    "        year = '20'+year\n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a669bb",
   "metadata": {},
   "source": [
    "#### NEX-GDDP-CMIP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c1310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_treat_modeled_NEX_GDDP_CMIP6(climate_var):\n",
    "    # import data\n",
    "    #path_NEX_GDDP_CMIP6_EmplacementStation = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file\\'+climate_var+'\\pr_mm_per_day_day_1970-2014\\Station_at_same_emplacement_as_NOAA_stationBeiraPembaChimoio_pr_1970-2014_projectsMoz.csv'\n",
    "    #out_path = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file'\n",
    "    if climate_var =='pr':\n",
    "        path_NEX_GDDP_CMIP6_EmplacementStation=os.path.join(r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file',climate_var,climate_var+'_mm_per_day_day_1970-2014','NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_'+climate_var+'_1970-2014_projectsMoz.csv')\n",
    "    else: # temperature\n",
    "        path_NEX_GDDP_CMIP6_EmplacementStation=os.path.join(r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6-AllMoz\\csv_file',climate_var,climate_var+'_Celsius_day_1970-2014','NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_'+climate_var+'_1970-2014_projectsMoz.csv')\n",
    "        \n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation = pd.read_csv(path_NEX_GDDP_CMIP6_EmplacementStation)\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation = data_NEX_GDDP_CMIP6_EmplacementStation.drop(['Experiment','Latitude','Longitude'],axis=1)\n",
    "    \n",
    "    # add Year, month and season columns for graphs\n",
    "    Year = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    Month = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    Season = data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values.reshape(len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values),)\n",
    "    \n",
    "    for i in np.arange(0,len(data_NEX_GDDP_CMIP6_EmplacementStation[['Date']].values)):\n",
    "        Year[i]=int(Year[i][6:10])\n",
    "        Month[i]=int(Month[i][3:5])\n",
    "        if int(Month[i])>3 and int(Month[i])<10: # dry season in Mozambique is between April and September\n",
    "            Season[i]='Dry'\n",
    "        else:# humid season is between October and March\n",
    "            Season[i]='Humid'\n",
    "\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Year'] = Year\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Month'] = Month\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation['Season'] = Season\n",
    "    \n",
    "    return data_NEX_GDDP_CMIP6_EmplacementStation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195bb60",
   "metadata": {},
   "source": [
    "### Compare climate variable at one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a62321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_(climate_var,data_obs_NOAA,name_station):\n",
    "    path_figure= r'C:\\Users\\CLMRX\\COWI\\A248363 - Climate analysis - Documents\\General\\CRVA_tool\\Master_thesis\\Project\\3 - Implementation\\1 - Data\\1-BC\\ComparisonBetweenObsAndModeled'# path to register figure\n",
    "    # meteorological data from NOAA\n",
    "    # unit of precipitation is mm\n",
    "    if (climate_var == 'pr') or (climate_var == 'Pr') or (climate_var == 'PR') or (climate_var == 'precipitation') or (climate_var == 'Precipitation') or (climate_var == 'PRECIPITATION'):\n",
    "        title_column_obs = 'PRCP'\n",
    "        title_column_modeled = 'Mean of the daily precipitation rate mm/day'\n",
    "        climate_var_full_name = 'precipitation'\n",
    "        climate_var_abreviation = 'pr'\n",
    "        #climate_var_obs_NOAA_station=data_obs_NOAA[['DATE',title_column_obs,'Year','Month','Season']][data_obs_NOAA['NAME']==name_station].reset_index(drop=True)\n",
    "        # data from NEX GDDP CMIP6 at the emplacement of the station\n",
    "        #data_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6(climate_var_abreviation)\n",
    "        #data_NEX_GDDP_CMIP6_EmplacementStation_station=data_NEX_GDDP_CMIP6_EmplacementStation[data_NEX_GDDP_CMIP6_EmplacementStation['Name station']==name_station]\n",
    "        #list_models_NEX_GDDP_CMIP6 = list(set(data_NEX_GDDP_CMIP6_EmplacementStation_station['Model']))\n",
    "        #data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station.drop(['Name station'],axis =1)\n",
    "    \n",
    "    if (climate_var == 'tas') or (climate_var == 'TAS') or (climate_var == 'Tas') or (climate_var == 'temperature') or (climate_var == 'Temperature') or (climate_var == 'TEMPERATURE'):\n",
    "        title_column_obs = 'TAVG'\n",
    "        title_column_modeled = 'Daily Near-Surface Air Temperature °C'\n",
    "        climate_var_full_name = 'temperature'\n",
    "        climate_var_abreviation = 'tas'\n",
    "        \n",
    "    if (climate_var == 'tasmax') or (climate_var == 'TASMAX') or (climate_var == 'Tasmax') or (climate_var == 'temperature maximum') or (climate_var == 'Temperature maximum') or (climate_var == 'TEMPERATURE MAXIMUM'):\n",
    "        title_column_obs = 'TMAX'\n",
    "        title_column_modeled = 'Daily Maximum Near-Surface Air Temperature °C'\n",
    "        climate_var_full_name = 'maximum temperature'\n",
    "        climate_var_abreviation = 'tasmax'\n",
    "        \n",
    "    if (climate_var == 'tasmin') or (climate_var == 'TASMIN') or (climate_var == 'Tasmin') or (climate_var == 'temperature minimum') or (climate_var == 'Temperature minimum') or (climate_var == 'TEMPERATURE MINIMUM'):\n",
    "        title_column_obs = 'TMIN'\n",
    "        title_column_modeled = 'Daily Minimum Near-Surface Air Temperature °C'\n",
    "        climate_var_full_name = 'minimum temperature'\n",
    "        climate_var_abreviation = 'tasmin'\n",
    "        \n",
    "    # deal with the degree symbol in title_column_modeled\n",
    "    if '°' in title_column_modeled:\n",
    "        title_column_modeled=title_column_modeled[0:title_column_modeled.rfind('°')]+u'\\N{DEGREE SIGN}C'\n",
    "    climate_var_obs_NOAA_station=data_obs_NOAA[['DATE',title_column_obs,'Year','Month','Season']][data_obs_NOAA['NAME']==name_station].reset_index(drop=True)\n",
    "    # data from NEX GDDP CMIP6 at the emplacement of the station\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6(climate_var_abreviation)\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station=data_NEX_GDDP_CMIP6_EmplacementStation[data_NEX_GDDP_CMIP6_EmplacementStation['Name station']==name_station]\n",
    "    list_models_NEX_GDDP_CMIP6 = list(set(data_NEX_GDDP_CMIP6_EmplacementStation_station['Model']))\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station.drop(['Name station'],axis =1)\n",
    "    #return title_column_modeled,data_NEX_GDDP_CMIP6_EmplacementStation_station\n",
    "    \n",
    "    # Select only part of the dataframe, to have the same period in both\n",
    "    (climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station,start_year,stop_year)=take_out_years_not_overlaping(climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station)\n",
    "    \n",
    "    # prepare name_station to be used for plots\n",
    "    name_station = name_station[0:name_station.rfind(',')].lower()\n",
    "    # do box plot for different model\n",
    "    plot_boxplots(climate_var_abreviation,data_NEX_GDDP_CMIP6_EmplacementStation_station,climate_var_obs_NOAA_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,title_column_obs,title_column_modeled,climate_var_abreviation,climate_var_full_name,path_figure,name_station)\n",
    "\n",
    "    # graphs\n",
    "    if climate_var_abreviation =='pr':\n",
    "        plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly sum',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)\n",
    "        plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal sum',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)\n",
    "        \n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly average',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Yearly median',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)    \n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal average',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)\n",
    "    plot_(climate_var_obs_NOAA_station,data_NEX_GDDP_CMIP6_EmplacementStation_station,'Seasonal median',climate_var_abreviation,climate_var_full_name,title_column_obs,title_column_modeled,'NOAA','NEX-GDDP-CMIP6',name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc9fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_out_years_not_overlaping(climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station):\n",
    "    if max(climate_var_obs_NOAA_station['Year'])>max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])        \n",
    "    else:\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year,stop_year)]\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year,stop_year)]\n",
    "\n",
    "    if max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>max(climate_var_obs_NOAA_station['Year']):\n",
    "        stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    else:\n",
    "        stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    if min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>min(climate_var_obs_NOAA_station['Year']):\n",
    "        start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    else:\n",
    "        start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year, stop_year)]\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year, stop_year)]\n",
    "    \n",
    "    return climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station,start_year,stop_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f581ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_out_years_not_overlaping2(climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station):\n",
    "    if max(climate_var_obs_NOAA_station['Year'])>max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])        \n",
    "    else:\n",
    "        if min(climate_var_obs_NOAA_station['Year'])>min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year']):\n",
    "            start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "        else:\n",
    "            start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "            stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year,stop_year)]\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year,stop_year)]\n",
    "\n",
    "    if max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>max(climate_var_obs_NOAA_station['Year']):\n",
    "        stop_year = max(climate_var_obs_NOAA_station['Year'])\n",
    "    else:\n",
    "        stop_year = max(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    if min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])>min(climate_var_obs_NOAA_station['Year']):\n",
    "        start_year = min(data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'])\n",
    "    else:\n",
    "        start_year = min(climate_var_obs_NOAA_station['Year'])\n",
    "\n",
    "    climate_var_obs_NOAA_station = climate_var_obs_NOAA_station[climate_var_obs_NOAA_station['Year'].between(start_year, stop_year)]\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_station = data_NEX_GDDP_CMIP6_EmplacementStation_station[data_NEX_GDDP_CMIP6_EmplacementStation_station['Year'].between(start_year, stop_year)]\n",
    "    \n",
    "    return climate_var_obs_NOAA_station, data_NEX_GDDP_CMIP6_EmplacementStation_station,start_year,stop_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aaa4e5",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aeeaddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(climate_var,data_NEX_GDDP_CMIP6_EmplacementStation_station,climate_var_obs_NOAA_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,column_name_obs,title_column_model,climate_var_abreviation,climate_var_full_name,path_figure,name_station):\n",
    "    # constructing the dictionarry for the boxplot\n",
    "    data_boxplot = []\n",
    "    labels_boxplot=[]\n",
    "    colors = []\n",
    "    # add observational data\n",
    "    data_of_interest = climate_var_obs_NOAA_station[column_name_obs].values\n",
    "    data_filtered = data_of_interest[~np.isnan(data_of_interest)]\n",
    "    data_boxplot.append(data_filtered)\n",
    "    labels_boxplot.append('Obs NOAA')\n",
    "    #colors.append('pink')\n",
    "    for model in list_models_NEX_GDDP_CMIP6:\n",
    "        data_of_interest = data_NEX_GDDP_CMIP6_EmplacementStation_station[title_column_model][data_NEX_GDDP_CMIP6_EmplacementStation_station['Model']==model].values\n",
    "        data_filtered = data_of_interest[~np.isnan(data_of_interest)]\n",
    "        data_boxplot.append(data_filtered)\n",
    "        labels_boxplot.append(model)\n",
    "        #colors.append('lightblue')\n",
    "\n",
    "\n",
    "    # problem where there are NaN in a series of values, does not produce a boxplot\n",
    "    # need to take the Nan out\n",
    "\n",
    "    # count how much Nan and for which models\n",
    "\n",
    "    several_boxplot(data_boxplot,labels_boxplot,start_year,stop_year,climate_var_abreviation,climate_var_full_name,'NOAA','NEX-GDDP-CMIP6',title_column_model,'Observational data vs Models',path_figure,name_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f2112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function several_boxplot is a function to plot several boxplots in one graph (to compare them)\n",
    "# the inputs:\n",
    "#    the data in a certainn format, the length should be the same as the text_label\n",
    "#    text_label contains the name of each set of data to be presented in boxplots\n",
    "#   All the following inputs are used for titles or labels\n",
    "#    climate_var is the climate variable of interest (example:'precipitation')\n",
    "#    source_obs is the source of the observation data\n",
    "#    source_modeled is the source of the modeled data\n",
    "#    full_name_climate_var is the complete name of the climate variable of interest (example:'Mean of the daily precipitation rate mm/day')\n",
    "#    y_label_text is the label for the y axis (example:'Observational data vs Models')\n",
    "#    path is the out_path where to register data\n",
    "def several_boxplot(data_boxplot,text_label,start_year,stop_year,climate_var_abreviation,climate_var,source_obs,source_modeled,full_name_climate_var,y_label_text,path_figure,name_station):\n",
    "    fig, ax = plt.subplots(figsize=(8,6))  # decide size of the figure, WIDTH_SIZE,HEIGHT_SIZE\n",
    "    colors = [] # prepare empty list to registere wanted colors\n",
    "    # fontsize of grpahs elements\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 16\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "    bp=plt.boxplot(data_boxplot,labels = text_label,notch=True, whis =(10,90),patch_artist = True,showfliers=True)\n",
    "    # showfliers=False permits to have the boxplot without outliers\n",
    "    # documentation about boxplot\n",
    "    # ... present boxplot over the period for each models\n",
    "    # this functions returns varius parameters of the boxplot in the dict_boxplot. This funcitons also returns an image of it\n",
    "    # here, numpy_array is a vector. But can also include array with several columns. Each columns will have a boxplot\n",
    "    # 'notch' is true to enhance part where the median is\n",
    "    # 'whis' is the percentile value for the whiskers, every data out of the range indicted by those 2 floats are represented as points\n",
    "    # 'widths' determine width of the boxes\n",
    "    # 'patch_artist' colors the boxplots\n",
    "    # 'labels' gives a name to every column included in the data part\n",
    "\n",
    "    # prepare color depending on content of labels\n",
    "    for i in np.arange(0,len(text_label)):\n",
    "        if ('obs' in text_label[i]) or ('Obs' in text_label[i]):\n",
    "            colors.append('lightpink')\n",
    "        else:\n",
    "            colors.append('lightblue')\n",
    "    # fill colors with vector just prepared\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    plt.xticks(rotation=90) # to have the labels vertical\n",
    "    # label axes and figure\n",
    "    plt.xlabel(y_label_text)\n",
    "    plt.ylabel(full_name_climate_var)\n",
    "    plt.title('Boxplot presenting ditribution of '+climate_var+' data of the '+source_obs+'\\nobservation data vs '+source_modeled+' modeled data between '+str(start_year)+' and '+str(stop_year))\n",
    "    plt.tight_layout() # Adjust the padding between and around subplots.\n",
    "    \n",
    "    # add legend\n",
    "    ax.legend([bp['boxes'][0],bp['boxes'][1]], ['Observed', 'Modeled'])\n",
    "    title_png = climate_var+'_'+'boxplot'+'_'+source_obs+'_'+source_modeled+'_'+name_station+'.png'\n",
    "    #if not os.path.isfile(path_to_figure):\n",
    "    if not os.path.isdir(os.path.join(path_figure,'figures3','Boxplots',climate_var_abreviation,name_station)):\n",
    "        os.makedirs(os.path.join(path_figure,'figures3','Boxplots',climate_var_abreviation,name_station)) # ensure creation of the path\n",
    "    \n",
    "    path_to_figure = os.path.join(path_figure,'figures3','Boxplots',climate_var_abreviation,name_station,title_png)\n",
    "    path_to_figure=path_length(path_to_figure)\n",
    "    plt.savefig(path_to_figure,format ='png') # savefig or save text must be before plt.show. for savefig, format should be explicity written\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# this function is to plot the statistics of the evolution of the climate variable of interest for a certain station\n",
    "def plot_(data_obs,data_model,stats,climate_var_abreviation,climate_var,title_column_obs,title_column_modeled,source_obs,source_modeled,name_station,start_year,stop_year,list_models_NEX_GDDP_CMIP6,path_figure):\n",
    "    if 'temperature' in climate_var:\n",
    "        unit = u'\\N{DEGREE SIGN}C'\n",
    "    if climate_var == 'precipitation':\n",
    "        if 'sum' in stats:\n",
    "            unit ='mm/year'\n",
    "        else:\n",
    "            unit ='mm/day'\n",
    "    plt.figure(figsize=(10,6)) # decide size of the figure, WIDTH_SIZE,HEIGHT_SIZE\n",
    "    # fontsize of grpahs elements\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 16\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "            \n",
    "    if stats == 'Yearly sum':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].sum().rename(columns = {title_column_modeled:'Yearly '+climate_var+' '+unit})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].sum()\n",
    "    if stats == 'Yearly average':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].mean().rename(columns = {title_column_modeled:'Average yearly '+climate_var+' '+unit})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].mean()\n",
    "    if stats == 'Yearly median':\n",
    "        for model in list_models_NEX_GDDP_CMIP6:\n",
    "            yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby('Year')[[title_column_modeled]].median().rename(columns = {title_column_modeled:'Median yearly '+climate_var+' '+unit})\n",
    "            plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "        climate_var_yearly_obs=data_obs.groupby('Year')[[title_column_obs]].median()\n",
    "        if climate_var == 'precipitation':\n",
    "            plt.ylim(0,1.5)\n",
    "        \n",
    "    if 'Seasonal' in stats:\n",
    "        \n",
    "        if stats == 'Seasonal sum':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].sum().rename(columns = {title_column_modeled:stats+' '+climate_var+' mm/season each year'})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year')\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].sum()\n",
    "        if stats == 'Seasonal average':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].mean().rename(columns = {title_column_modeled:stats+' '+climate_var+unit})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year') # set the colomun with both information as the new column\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].mean()\n",
    "            \n",
    "        if stats == 'Seasonal median':\n",
    "            for model in list_models_NEX_GDDP_CMIP6:\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = data_model[data_model['Model']==model].groupby(['Year','Season'])[[title_column_modeled]].median().rename(columns = {title_column_modeled:stats+' '+climate_var+unit})\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.reset_index() # put Year and Season as columns\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.set_index('Year') # set the colomun with both information as the new column\n",
    "                yearly_climate_var_NEX_GDDP_CMIP6 = yearly_climate_var_NEX_GDDP_CMIP6.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "                plt.plot(yearly_climate_var_NEX_GDDP_CMIP6.index,yearly_climate_var_NEX_GDDP_CMIP6,label=model)\n",
    "                \n",
    "            climate_var_yearly_obs=data_obs.groupby(['Year','Season'])[[title_column_obs]].median()\n",
    "        # managed the observation data for seasonal stats\n",
    "        climate_var_yearly_obs = climate_var_yearly_obs.reset_index() # put Year and Season as columns\n",
    "        climate_var_yearly_obs = climate_var_yearly_obs.set_index('Year') # set the colomun with both information as the new column\n",
    "        climate_var_yearly_obs = climate_var_yearly_obs.drop(['Season'],axis=1) # drop the columns Year and season\n",
    "        plt.xticks(np.arange(start_year, stop_year, step=5))  # Set label locations.\n",
    "    plt.plot(climate_var_yearly_obs.index,climate_var_yearly_obs,'k',label='observation')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel(stats+' '+climate_var+unit)\n",
    "    plt.title(stats+' '+climate_var+' '+unit+' accross models from '+source_modeled+', with observation\\nfrom '+source_obs+', at station '+name_station+', between '+str(start_year)+' and '+str(stop_year))\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    plt.tight_layout() # Adjust the padding between and around subplots.\n",
    "    title_png = climate_var+'_'+stats.replace(' ','')+'_'+'graph'+'_'+source_obs+'_'+source_modeled+'_'+name_station+'.png'\n",
    "    #if not os.path.isfile(path_to_figure): # the file does not exists\n",
    "    if not os.path.isdir(os.path.join(path_figure,'figures3','Graphs',climate_var,name_station)):\n",
    "        print('File is created')\n",
    "        os.makedirs(os.path.join(path_figure,'figures3','Graphs',climate_var,name_station)) # ensure creation of the path\n",
    "    path_to_figure = os.path.join(path_figure,'figures3','Graphs',climate_var,name_station,title_png)\n",
    "    path_to_figure=path_length(path_to_figure)\n",
    "    plt.savefig(path_to_figure,format ='png') # savefig or save text must be before plt.show. for savefig, format should be explicity written\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fed2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions test if the path is too long\n",
    "# if the path is more than 250 char, the path wll be modified in order for windows to accept is as a path\n",
    "\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f2771",
   "metadata": {},
   "source": [
    "# Project information\n",
    "Those project were chosen based on the interest of the company (decided with SIPA and RAPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074319a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_projects_data = np.array(['WTP_Mutua_EIB', 'Gorongosa_EIB', 'Chimoio_WTP_EIB', 'Pemba_EIB'])\n",
    "name_projects = pd.Series(name_projects_data)\n",
    "\n",
    "lon_projects_data = np.array([34.5927839939706, 34.07824286310398 , 33.47333313659342, 40.52545156033736])\n",
    "lon_projects = pd.Series(lon_projects_data)\n",
    "\n",
    "lat_projects_data = np.array([-19.495079648575242, -18.68063728746643, -19.125095255188334,-12.973942656747809])\n",
    "lat_projects = pd.Series(lat_projects_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b5031",
   "metadata": {},
   "source": [
    "# Comparaison between observational data and modeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4639cc",
   "metadata": {},
   "source": [
    "## Observation data coming from the place\n",
    "\n",
    "Excel 'Dados_e_grafico_P_812.xls', was given by SIPA, who has received it from André Görgens (Cosnultant, Water resources Management, Zutari) in an email, on the 20th of June 2023.\n",
    "\n",
    "Those data can be use as precipitation observation data for the town of Gorongosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942ebe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pr_gorongosa_SIPA = import_treat_observed_Gorongosa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8412840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-01</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>138.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>80.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14976 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pr\n",
       "time             \n",
       "1980-01-01    NaN\n",
       "1980-01-02    NaN\n",
       "1980-01-03    NaN\n",
       "1980-01-04    NaN\n",
       "1980-01-05    NaN\n",
       "...           ...\n",
       "2020-12-27    2.7\n",
       "2020-12-28      0\n",
       "2020-12-29      0\n",
       "2020-12-30  138.4\n",
       "2020-12-31   80.4\n",
       "\n",
       "[14976 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_pr_gorongosa_SIPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2e7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare observational data coming from gorongosa to the values of NEX-GDDP-CMIP6 at a point in Gorongosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12043c4f",
   "metadata": {},
   "source": [
    "## Observational data coming from NOAA\n",
    "[Global Historical Climatology Network daily (GHCNd) | National Centers for Environmental Information (NCEI) (noaa.gov)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily), climate data online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "282c21d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'PRCP',\n",
       "       'PRCP_ATTRIBUTES', 'TAVG', 'TAVG_ATTRIBUTES', 'TMAX', 'TMAX_ATTRIBUTES',\n",
       "       'TMIN', 'TMIN_ATTRIBUTES', 'Year', 'Month', 'Season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obs_NOAA=import_treat_obs_NOAA()\n",
    "data_obs_NOAA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc30caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRCP_ATTRIBUTES</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TAVG_ATTRIBUTES</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMAX_ATTRIBUTES</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_ATTRIBUTES</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MZM00067223</td>\n",
       "      <td>MONTEPUEZ, MZ</td>\n",
       "      <td>-13.133</td>\n",
       "      <td>39.033</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1974-04-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>23.8</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>29.0</td>\n",
       "      <td>,D,S</td>\n",
       "      <td>20.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>1974</td>\n",
       "      <td>4</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MZM00067223</td>\n",
       "      <td>MONTEPUEZ, MZ</td>\n",
       "      <td>-13.133</td>\n",
       "      <td>39.033</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1974-06-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>18.2</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>11.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MZM00067223</td>\n",
       "      <td>MONTEPUEZ, MZ</td>\n",
       "      <td>-13.133</td>\n",
       "      <td>39.033</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1974-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1974</td>\n",
       "      <td>6</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MZM00067223</td>\n",
       "      <td>MONTEPUEZ, MZ</td>\n",
       "      <td>-13.133</td>\n",
       "      <td>39.033</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1974-07-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>21.5</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>1974</td>\n",
       "      <td>7</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MZM00067223</td>\n",
       "      <td>MONTEPUEZ, MZ</td>\n",
       "      <td>-13.133</td>\n",
       "      <td>39.033</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1974-07-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>20.5</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>1974</td>\n",
       "      <td>7</td>\n",
       "      <td>Dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161770</th>\n",
       "      <td>MZ000067297</td>\n",
       "      <td>BEIRA, MZ</td>\n",
       "      <td>-19.800</td>\n",
       "      <td>34.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.8</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>32.3</td>\n",
       "      <td>,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Humid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161771</th>\n",
       "      <td>MZ000067297</td>\n",
       "      <td>BEIRA, MZ</td>\n",
       "      <td>-19.800</td>\n",
       "      <td>34.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.4</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Humid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161772</th>\n",
       "      <td>MZ000067297</td>\n",
       "      <td>BEIRA, MZ</td>\n",
       "      <td>-19.800</td>\n",
       "      <td>34.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.6</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Humid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161773</th>\n",
       "      <td>MZ000067297</td>\n",
       "      <td>BEIRA, MZ</td>\n",
       "      <td>-19.800</td>\n",
       "      <td>34.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>24.9</td>\n",
       "      <td>,,S</td>\n",
       "      <td>28.3</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>31.2</td>\n",
       "      <td>,,S</td>\n",
       "      <td>25.7</td>\n",
       "      <td>,,S</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Humid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161774</th>\n",
       "      <td>MZ000067297</td>\n",
       "      <td>BEIRA, MZ</td>\n",
       "      <td>-19.800</td>\n",
       "      <td>34.900</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>,,S</td>\n",
       "      <td>28.1</td>\n",
       "      <td>H,,S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>,,S</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>Humid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161775 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION           NAME  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0       MZM00067223  MONTEPUEZ, MZ   -13.133     39.033      535.0   \n",
       "1       MZM00067223  MONTEPUEZ, MZ   -13.133     39.033      535.0   \n",
       "2       MZM00067223  MONTEPUEZ, MZ   -13.133     39.033      535.0   \n",
       "3       MZM00067223  MONTEPUEZ, MZ   -13.133     39.033      535.0   \n",
       "4       MZM00067223  MONTEPUEZ, MZ   -13.133     39.033      535.0   \n",
       "...             ...            ...       ...        ...        ...   \n",
       "161770  MZ000067297      BEIRA, MZ   -19.800     34.900       16.0   \n",
       "161771  MZ000067297      BEIRA, MZ   -19.800     34.900       16.0   \n",
       "161772  MZ000067297      BEIRA, MZ   -19.800     34.900       16.0   \n",
       "161773  MZ000067297      BEIRA, MZ   -19.800     34.900       16.0   \n",
       "161774  MZ000067297      BEIRA, MZ   -19.800     34.900       16.0   \n",
       "\n",
       "              DATE  PRCP PRCP_ATTRIBUTES  TAVG TAVG_ATTRIBUTES  TMAX  \\\n",
       "0       1974-04-05   2.0             ,,S  23.8            H,,S  29.0   \n",
       "1       1974-06-17   0.0             ,,S  18.2            H,,S  27.0   \n",
       "2       1974-06-23   NaN             NaN  21.0            H,,S   NaN   \n",
       "3       1974-07-02   0.0             ,,S  21.5            H,,S   NaN   \n",
       "4       1974-07-03   0.0             ,,S  20.5            H,,S   NaN   \n",
       "...            ...   ...             ...   ...             ...   ...   \n",
       "161770  2020-12-27   NaN             NaN  28.8            H,,S  32.3   \n",
       "161771  2020-12-28   NaN             NaN  29.4            H,,S   NaN   \n",
       "161772  2020-12-29   NaN             NaN  29.6            H,,S   NaN   \n",
       "161773  2020-12-30  24.9             ,,S  28.3            H,,S  31.2   \n",
       "161774  2020-12-31   5.1             ,,S  28.1            H,,S   NaN   \n",
       "\n",
       "       TMAX_ATTRIBUTES  TMIN TMIN_ATTRIBUTES  Year Month Season  \n",
       "0                 ,D,S  20.0             ,,S  1974     4    Dry  \n",
       "1                  ,,S  11.0             ,,S  1974     6    Dry  \n",
       "2                  NaN   NaN             NaN  1974     6    Dry  \n",
       "3                  NaN  16.0             ,,S  1974     7    Dry  \n",
       "4                  NaN  16.0             ,,S  1974     7    Dry  \n",
       "...                ...   ...             ...   ...   ...    ...  \n",
       "161770             ,,S   NaN             NaN  2020    12  Humid  \n",
       "161771             NaN  25.0             ,,S  2020    12  Humid  \n",
       "161772             NaN  26.0             ,,S  2020    12  Humid  \n",
       "161773             ,,S  25.7             ,,S  2020    12  Humid  \n",
       "161774             NaN  25.0             ,,S  2020    12  Humid  \n",
       "\n",
       "[161775 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obs_NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa6c7d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest meteorological station to the project WTP_Mutua_EIB is the one located in BEIRA, MZ\n",
      "The closest meteorological station to the project Gorongosa_EIB is the one located in CHIMOIO, MZ\n",
      "The closest meteorological station to the project Chimoio_WTP_EIB is the one located in CHIMOIO, MZ\n",
      "The closest meteorological station to the project Pemba_EIB is the one located in PEMBA, MZ\n",
      "\n",
      "\n",
      "The coordinates for the meteorological stations which are the closest to the project of interest are :\n",
      "\n",
      "\n",
      "Name CHIMOIO, MZ\n",
      "Longitude 33.467\n",
      "Latitude -19.117\n",
      "\n",
      "\n",
      "Name BEIRA, MZ\n",
      "Longitude 34.9\n",
      "Latitude -19.8\n",
      "\n",
      "\n",
      "Name PEMBA, MZ\n",
      "Longitude 40.533\n",
      "Latitude -12.983\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_closest_meteo_station_to_projects(data_obs_NOAA,name_projects,lat_projects,lon_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc580d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PEMBA, MZ',\n",
       " 'MAPULANGUENE MAPUTO, MZ',\n",
       " 'MOCIMBOA DA PRAIA, MZ',\n",
       " 'CHANGALANE, MZ',\n",
       " 'MAPUTO, MZ',\n",
       " 'NAMPULA, MZ',\n",
       " 'CHIMOIO, MZ',\n",
       " 'MONTEPUEZ, MZ',\n",
       " 'PAFURI, SF',\n",
       " 'PANDA INHAMBANE, MZ',\n",
       " 'VILANKULO, MZ',\n",
       " 'TETE, MZ',\n",
       " 'LUMBO, MZ',\n",
       " 'CUAMBA, MZ',\n",
       " 'ANGOCHE, MZ',\n",
       " 'BEIRA, MZ',\n",
       " 'XAI XAI, MZ',\n",
       " 'LICHINGA, MZ',\n",
       " 'INHAMBANE, MZ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(data_obs_NOAA['NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c8e9683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>PRCP_ATTRIBUTES</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TAVG_ATTRIBUTES</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMAX_ATTRIBUTES</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>TMIN_ATTRIBUTES</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [STATION, NAME, LATITUDE, LONGITUDE, ELEVATION, DATE, PRCP, PRCP_ATTRIBUTES, TAVG, TAVG_ATTRIBUTES, TMAX, TMAX_ATTRIBUTES, TMIN, TMIN_ATTRIBUTES, Year, Month, Season]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obs_NOAA[data_obs_NOAA['NAME']=='GORONGOSA, MZ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3814e",
   "metadata": {},
   "source": [
    "## Data at the same emplacement coming from NEX GDDP CMIP6\n",
    " \n",
    "[NEX-GDDP-CMIP6](https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6) data are CMIP6 data, bias corrected by NASA, with [Global Meteorological Forcing Dataset (GMFD) for Land Surface Modeling](https://aquaknow.jrc.ec.europa.eu/en/content/global-meteorological-forcing-dataset-land-surface-modeling-pgfprinceton) (which are [reanalysis data](https://www.researchgate.net/publication/200472354_Development_of_a_50-Year_High-Resolution_Global_Dataset_of_Meteorological_Forcings_for_Land_Surface_Modeling)). More information about NEX-GDDP-CMIP6 data in the [technical note](https://www.nccs.nasa.gov/sites/default/files/NEX-GDDP-CMIP6-Tech_Note.pdf).\n",
    " \n",
    " \n",
    " With information found with precedent file, the values produced by NEX-GDDP-CMIP6 at the emplacement of the meteorological stations, that are the closest to the projects of interest, are compiled in a file named EmplacementStationNOAA_pr_1970-2014_projectsMoz.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4da654a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\NEX-GDDP-CMIP6-AllMoz\\\\csv_file\\\\pr\\\\pr_mm_per_day_day_1970-2014\\\\NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_pr_1970-2014_projectsMoz.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m climate_var_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m=\u001b[39m\u001b[43mimport_treat_modeled_NEX_GDDP_CMIP6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_var\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mimport_treat_modeled_NEX_GDDP_CMIP6\u001b[1;34m(climate_var)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# temperature\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     path_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOWI.net\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA245000\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA248363\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCRVA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNEX-GDDP-CMIP6-AllMoz\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcsv_file\u001b[39m\u001b[38;5;124m'\u001b[39m,climate_var,climate_var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Celsius_day_1970-2014\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mclimate_var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1970-2014_projectsMoz.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_NEX_GDDP_CMIP6_EmplacementStation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation \u001b[38;5;241m=\u001b[39m data_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# add Year, month and season columns for graphs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\NEX-GDDP-CMIP6-AllMoz\\\\csv_file\\\\pr\\\\pr_mm_per_day_day_1970-2014\\\\NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_pr_1970-2014_projectsMoz.csv'"
     ]
    }
   ],
   "source": [
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation=import_treat_modeled_NEX_GDDP_CMIP6(climate_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9695b52",
   "metadata": {},
   "source": [
    "## Compare precipitation data for different stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select climate variable and meteorological station; select data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'PEMBA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'BEIRA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0b1217",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\NEX-GDDP-CMIP6-AllMoz\\\\csv_file\\\\pr\\\\pr_mm_per_day_day_1970-2014\\\\NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_pr_1970-2014_projectsMoz.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompare_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_obs_NOAA\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCHIMOIO, MZ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mcompare_\u001b[1;34m(climate_var, data_obs_NOAA, name_station)\u001b[0m\n\u001b[0;32m     38\u001b[0m climate_var_obs_NOAA_station\u001b[38;5;241m=\u001b[39mdata_obs_NOAA[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m,title_column_obs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeason\u001b[39m\u001b[38;5;124m'\u001b[39m]][data_obs_NOAA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mname_station]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# data from NEX GDDP CMIP6 at the emplacement of the station\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m=\u001b[39m\u001b[43mimport_treat_modeled_NEX_GDDP_CMIP6\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclimate_var_abreviation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation_station\u001b[38;5;241m=\u001b[39mdata_NEX_GDDP_CMIP6_EmplacementStation[data_NEX_GDDP_CMIP6_EmplacementStation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName station\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mname_station]\n\u001b[0;32m     42\u001b[0m list_models_NEX_GDDP_CMIP6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(data_NEX_GDDP_CMIP6_EmplacementStation_station[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mimport_treat_modeled_NEX_GDDP_CMIP6\u001b[1;34m(climate_var)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# temperature\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     path_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOWI.net\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA245000\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA248363\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCRVA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNEX-GDDP-CMIP6-AllMoz\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcsv_file\u001b[39m\u001b[38;5;124m'\u001b[39m,climate_var,climate_var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Celsius_day_1970-2014\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mclimate_var\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_1970-2014_projectsMoz.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_NEX_GDDP_CMIP6_EmplacementStation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m data_NEX_GDDP_CMIP6_EmplacementStation \u001b[38;5;241m=\u001b[39m data_NEX_GDDP_CMIP6_EmplacementStation\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# add Year, month and season columns for graphs\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\NEX-GDDP-CMIP6-AllMoz\\\\csv_file\\\\pr\\\\pr_mm_per_day_day_1970-2014\\\\NEXGDDPCMIP6_at_same_emplacement_as_NOAA_stationPembaChimoioBeira_pr_1970-2014_projectsMoz.csv'"
     ]
    }
   ],
   "source": [
    "compare_(climate_var,data_obs_NOAA,'CHIMOIO, MZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ef05e",
   "metadata": {},
   "source": [
    "## Compare temperature data for different stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23acf6d4",
   "metadata": {},
   "source": [
    "### Average temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81582ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_('tas',data_obs_NOAA,'PEMBA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_('tas',data_obs_NOAA,'BEIRA, MZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_('tas',data_obs_NOAA,'CHIMOIO, MZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631d5606",
   "metadata": {},
   "source": [
    "### Minimum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2052414",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_('tasmin',data_obs_NOAA,'PEMBA, MZ')\n",
    "compare_('tasmin',data_obs_NOAA,'BEIRA, MZ')\n",
    "compare_('tasmin',data_obs_NOAA,'CHIMOIO, MZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b1ef6",
   "metadata": {},
   "source": [
    "### Maximum temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_('tasmax',data_obs_NOAA,'PEMBA, MZ')\n",
    "compare_('tasmax',data_obs_NOAA,'BEIRA, MZ')\n",
    "compare_('tasmax',data_obs_NOAA,'CHIMOIO, MZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a1727",
   "metadata": {},
   "source": [
    "# Note concerning distribution of precipitation data\n",
    "Observational data over this period much bigger than modeled data. However, mediane of all set of data close to 0 --> much more smaller values than big values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfbe6b",
   "metadata": {},
   "source": [
    "# BIAS CORRECTION - POINT WISE METHOD\n",
    "\n",
    "[Scikit-downscale](https://github.com/pangeo-data/scikit-downscale/tree/main)\n",
    "[Detailed process here](https://github.com/pangeo-data/scikit-downscale/blob/main/examples/2020ECAHM-scikit-downscale.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from utils import get_sample_data\n",
    "\n",
    "sns.set(style='darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare set of data for Bias correction\n",
    "# load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out rows for which date is not in both set of data\n",
    "(data_obs_NOAA, climate_var_NEX_GDDP_CMIP6_EmplacementStation,start_year,stop_year) = take_out_years_not_overlaping(data_obs_NOAA, climate_var_NEX_GDDP_CMIP6_EmplacementStation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_NOAA2=data_obs_NOAA.set_index('DATE')[['PRCP']]\n",
    "type(data_obs_NOAA2.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe91caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obs_NOAA2#[['PRCP']]['1974': '2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c8309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC=climate_var_NEX_GDDP_CMIP6_EmplacementStation[climate_var_NEX_GDDP_CMIP6_EmplacementStation['Name station']==name_station].drop(['Name station','Year','Month','Season'],axis =1)\n",
    "climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC_model = climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC[climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC['Model'] =='ACCESS-CM2'].drop(['Model'],axis=1)\n",
    "training = climate_var_NEX_GDDP_CMIP6_EmplacementStation_BC_model.rename(columns = {'Date':'time','Mean of the daily precipitation rate mm/day':'pcp'}).reset_index()\n",
    "\n",
    "# changing format of Date for training\n",
    "Date1 = training['time'].values\n",
    "for i in np.arange(0,len(training)):\n",
    "    training['time'][i] = Date1[i][6:10]+'-'+Date1[i][3:5]+'-'+Date1[i][0:2]#datetime.strptime(, '%Y-%M-%d').date()\n",
    "    print(training['time'][i])\n",
    "# .date() to avoid having the hours in the datetime\n",
    "training=training.set_index('time').drop(['index'],axis=1)\n",
    "\n",
    "\n",
    "# targets\n",
    "targets = data_obs_NOAA[['NAME','DATE','PRCP']] # select only 3 columns of interest\n",
    "targets = targets[targets['NAME']==name_station].rename(columns = {'DATE':'time','PRCP':'pcp'}).set_index('time').drop(['NAME'],axis=1) # the targets data is meant to represent our \"observations\"\n",
    "\n",
    "\n",
    "# to have the same size of vectors\n",
    "targets = targets.dropna() # drop rows with NaN\n",
    "training = training[training.index.isin(list(targets.index))] # drop rows of training where date is equal to date where there is no value for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d24a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[['pcp']]['1980': '2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(targets.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date1 = pr_obs_NOAA_to_compare_pemba['DATE'].values\n",
    "pr_obs_NOAA_to_compare2_pemba = pr_obs_NOAA_to_compare_pemba.copy(deep=True)\n",
    "for i in np.arange(0,len(pr_obs_NOAA_to_compare_pemba)):\n",
    "    pr_obs_NOAA_to_compare2_pemba['DATE'][i] = datetime.strptime(Date1[i], '%Y-%M-%d').date() #Date1[0][8:10] +'-'+Date1[i][5:7]+'-'+Date1[i][0:4]\n",
    "pr_obs_NOAA_to_compare2_pemba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date1 = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba['Date'].values\n",
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba = data_NEX_GDDP_CMIP6_EmplacementStation_to_compare_pemba.copy(deep=True).reset_index()\n",
    "for i in np.arange(0,len(data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba)):\n",
    "    data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Date'][i] = datetime.strptime(Date1[i][6:10]+'-'+Date1[i][3:5]+'-'+Date1[i][0:2], '%Y-%M-%d').date()\n",
    "    #print(data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba['Date'][i])\n",
    "# .date() to avoid having the hours in the datetime\n",
    "data_NEX_GDDP_CMIP6_EmplacementStation_to_compare2_pemba # 2h54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of the training/targets data\n",
    "display(pd.concat({'training': training, 'targets': targets}, axis=1))\n",
    "#display(pd.DataFrame.merge(training,targets,on='time'))\n",
    "\n",
    "# make a plot of the temperature and precipitation data\n",
    "fig, axes = plt.subplots(ncols=1, nrows=2, figsize=(8, 6), sharex=True)\n",
    "time_slice = slice('1990-01-01', '1990-12-31')\n",
    "\n",
    "# plot-temperature\n",
    "training[time_slice]['pcp'].plot(ax=axes[0], label='training')\n",
    "targets[time_slice]['pcp'].plot(ax=axes[0], label='targets')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylabel('Precipitation [mm/day]')\n",
    "\n",
    "# plot-precipitation\n",
    "training[time_slice]['pcp'].plot(ax=axes[1])\n",
    "targets[time_slice]['pcp'].plot(ax=axes[1])\n",
    "_ = axes[1].set_ylabel('Precipitation [mm/day]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat({'training': training, 'targets': targets}, axis=1)\n",
    "\n",
    "df=df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.droplevel(1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ca513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31df339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploratory data analysis for arrm model\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "\n",
    "def ARRM(n_bins=7):\n",
    "    return Pipeline([\n",
    "        ('')\n",
    "    ])\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "c = {'train': 'black', 'predict': 'blue', 'test': 'grey'}\n",
    "\n",
    "qqwargs = {'n_quantiles': int(1e6), 'copy': True, 'subsample': int(1e6)} # add int for n_quantiles and subsample to avoid\n",
    "# foloowing problem:  InvalidParameterError: The 'n_quantiles' parameter of QuantileTransformer must be an int in the range [1, inf). Got 1000000.0 instead.\n",
    "n_bins = 7\n",
    "\n",
    "\n",
    "\n",
    "X = df1[['training']].values#['1980': '2014']#training[['pcp']]['1980': '2014'].values\n",
    "y = df1[['targets']].values# targets[['pcp']]['1980': '2014'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xqt = QuantileTransformer(**qqwargs).fit(X_train)\n",
    "\n",
    "Xq_train = xqt.transform(X_train)\n",
    "Xq_test = xqt.transform(X_test)\n",
    "\n",
    "yqt = QuantileTransformer(**qqwargs).fit(y_train)\n",
    "yq_train = xqt.transform(y_train)[:, 0]\n",
    "yq_test = xqt.transform(y_test)[:, 0]\n",
    "\n",
    "\n",
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='quantile'))\n",
    "# model.fit(Xq_train, yq_train)\n",
    "# predq = model.predict(Xq_test)\n",
    "# pred = qt.inverse_transform(predq.reshape(-1, 1))\n",
    "\n",
    "y_train = y_train[:, 0]\n",
    "for strat in ['kmeans', 'uniform', 'quantile']:\n",
    "    model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy=strat))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(strat, model.score(X_test, y_test))\n",
    "    \n",
    "model = PiecewiseRegressor(binner=KBinsDiscretizer(n_bins=n_bins, strategy='kmeans'))\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(X_train, y_train, c=c['train'], s=5, label='train')\n",
    "plt.scatter(X_test, y_test, c=c['test'], s=5, label='test')\n",
    "ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "plt.scatter(np.sort(X_train, axis=0), np.sort(y_train, axis=0), c=c['train'], s=5, label='train')\n",
    "plt.scatter(np.sort(X_test, axis=0), np.sort(y_test, axis=0), c=c['test'], s=5, label='test')\n",
    "plt.plot(np.sort(X_test, axis=0), np.sort(pred, axis=0), c=c['predict'], lw=2, label='predictions')\n",
    "ax.legend()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "# ax.plot(Xq_test[:, 0], yq_test, \".\", label='data', c=c['test'])\n",
    "# ax.plot(Xq_test[:, 0], predq, \".\", label=\"predictions\", c=c['predict'])\n",
    "# ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "# ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(X_test[:, 0], y_test, \".\", label='data', c=c['test'])\n",
    "ax.plot(X_test[:, 0], pred, \".\", label=\"predictions\", c=c['predict'])\n",
    "ax.set_title(f\"Piecewise Linear Regression\\n{n_bins} buckets\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2222b8",
   "metadata": {},
   "source": [
    "Scikit-downscale, the ability to test and compare arbitrary combinations of models under a common interface. This allows us to try many combinations of models and parameters, choosing only the best combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b12533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skdownscale\n",
    "from skdownscale.pointwise_models import bcsd # name of the model to write \n",
    "\n",
    "# all modeled listed here\n",
    "# C:\\Users\\CLMRX\\AppData\\Local\\miniconda3\\envs\\geodata\\Lib\\site-packages\\skdownscale\\pointwise_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bca057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = {'detrend':True}\n",
    "\n",
    "# parameters for QuantileMapper in bcsd\n",
    "r'''\n",
    "    Parameters\n",
    "    ----------\n",
    "    detrend : boolean, optional\n",
    "        If True, detrend the data before quantile mapping and add the trend\n",
    "        back after transforming. Default is False.\n",
    "    lt_kwargs : dict, optional\n",
    "        Dictionary of keyword arguments to pass to the LinearTrendTransformer\n",
    "    qm_kwargs : dict, optional\n",
    "        Dictionary of keyword arguments to pass to the QuantileMapper'''\n",
    "\n",
    "model = bcsd.BcsdPrecipitation()#**parameters\n",
    "X = df1[['training']]#['1980': '2014']#training[['pcp']]['1980': '2014'].values\n",
    "y = df1[['targets']]# targets[['pcp']]['1980': '2014'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model.fit(X_train, y_train) # problem, both vector do not have the same length. Problem comes from train_test_split(X, y), defined in _split.py,\n",
    "# in C:\\Users\\CLMRX\\AppData\\Local\\miniconda3\\envs\\geodata\\Lib\\site-packages\\sklearn\\model_selection \n",
    "# try to find _safe_indexing function, that generates return values. Say it is in utils but not found\n",
    "predictions = model.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ff26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)-len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from skdownscale.pointwise_models import PureAnalog, AnalogRegression\n",
    "from skdownscale.pointwise_models import BcsdTemperature, BcsdPrecipitation\n",
    "\n",
    "\n",
    "models = {\n",
    "    'GARD: PureAnalog-best-1': PureAnalog(kind='best_analog', n_analogs=1),\n",
    "    'GARD: PureAnalog-sample-10': PureAnalog(kind='sample_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-10': PureAnalog(kind='weight_analogs', n_analogs=10),\n",
    "    'GARD: PureAnalog-weight-100': PureAnalog(kind='weight_analogs', n_analogs=100),\n",
    "    'GARD: PureAnalog-mean-10': PureAnalog(kind='mean_analogs', n_analogs=10),\n",
    "    'GARD: AnalogRegression-100': AnalogRegression(n_analogs=100),\n",
    "    'GARD: LinearRegression': LinearRegression(),\n",
    "    'BCSD: BcsdTemperature': BcsdTemperature(return_anoms=False),\n",
    "    'Sklearn: RandomForestRegressor': RandomForestRegressor(random_state=0)\n",
    "}\n",
    "\n",
    "#train_slice = slice('1980-01-01', '1989-12-31')\n",
    "#predict_slice = slice('1990-01-01', '1999-12-31')\n",
    "train_slice = slice(datetime.date(1980, 1, 1), datetime.date(1989, 12, 31))\n",
    "predict_slice = slice(datetime.date(1990, 1, 1), datetime.date(1999, 12, 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training / prediction data\n",
    "X_train = training[['pcp']][train_slice]\n",
    "y_train = targets[['pcp']][train_slice]\n",
    "X_predict = training[['pcp']][predict_slice]\n",
    "\n",
    "# Fit all models\n",
    "for key, model in models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be859d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb86f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
