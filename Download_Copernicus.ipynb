{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93dcc14",
   "metadata": {},
   "source": [
    "This notebook is meant to download data from copernicus CMIP6.\n",
    "\n",
    "Data source : https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c8b78",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a4269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_of_interest = 'past' # 'future' (2015-2100) or 'past' (1950-2014)\n",
    "global_variable = 'temperature'\n",
    "name_variable = 'daily_maximum_near_surface_air_temperature' \n",
    "\n",
    "# 'tas' 'near_surface_air_temperature'\n",
    "# 'tasmax' 'daily_maximum_near_surface_air_temperature'\n",
    "# 'tasmin' 'daily_minimum_near_surface_air_temperature'\n",
    "# 'hurs' 'near_surface_specific_humidity'\n",
    "# 'Wind' 'near_surface_wind_speed'\n",
    "\n",
    "temporal_resolution = 'daily'\n",
    "\n",
    "# wind register at 10 m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fe416",
   "metadata": {},
   "source": [
    "# Functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9510fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4 as nc#not directly used but needs to be imported for some nc4 files manipulations, use for nc files\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import datetime # to have actual date\n",
    "import os\n",
    "import os.path\n",
    "import cdsapi # for copernicus function\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3262e08",
   "metadata": {},
   "source": [
    "# Out path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ead08c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path=r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53516663",
   "metadata": {},
   "source": [
    "# Area information\n",
    "\n",
    "This code download data one area at the time. The user must indicate which part of the word he/she wnats to download.\n",
    "\n",
    "Reminder: \n",
    "\n",
    "latitude is vertical, it specifies North-South positions.\n",
    "\n",
    "longitude is horizontal, it specifies West-East positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2fba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default coordinates are the ones of Mozambique\n",
    "\n",
    "name_area = 'all-Mozambique'\n",
    "\n",
    "North = -10\n",
    "South = -27\n",
    "West = 30\n",
    "East = 41\n",
    "\n",
    "area = [North, West, South, East] # list format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3f294",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e29fa6",
   "metadata": {},
   "source": [
    "### Calendar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d6a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to define parameter of time that remain constant durinf the whole script\n",
    "class calendar:\n",
    "    default_month = [ \n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                ]\n",
    "    default_day = [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                '13', '14', '15',\n",
    "                '16', '17', '18',\n",
    "                '19', '20', '21',\n",
    "                '22', '23', '24',\n",
    "                '25', '26', '27',\n",
    "                '28', '29', '30',\n",
    "                '31',\n",
    "                ]\n",
    "    #actual_date = datetime.date.today()\n",
    "    #actual_year = actual_date.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c5e67",
   "metadata": {},
   "source": [
    "### Copernicus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f79fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of tuples that will be useful to search which data are available or not\n",
    "# make it tuples to make unchangeable\n",
    "class copernicus_elements:\n",
    "    # there is 58 models\n",
    "    models =('access_cm2','awi_cm_1_1_mr','bcc_csm2_mr','cams_csm1_0','canesm5_canoe','cesm2_fv2','cesm2_waccm_fv2','cmcc_cm2_hr4','cmcc_esm2','cnrm_cm6_1_hr','e3sm_1_0','e3sm_1_1_eca','ec_earth3_aerchem','ec_earth3_veg','fgoals_f3_l','fio_esm_2_0','giss_e2_1_g','hadgem3_gc31_ll','iitm_esm','inm_cm5_0','ipsl_cm6a_lr','kiost_esm','miroc6','miroc_es2l','mpi_esm1_2_hr','mri_esm2_0','norcpm1','noresm2_mm','taiesm1','access_esm1_5','awi_esm_1_1_lr','bcc_esm1','canesm5','cesm2','cesm2_waccm','ciesm','cmcc_cm2_sr5','cnrm_cm6_1','cnrm_esm2_1','e3sm_1_1','ec_earth3','ec_earth3_cc','ec_earth3_veg_lr','fgoals_g3','gfdl_esm4','giss_e2_1_h','hadgem3_gc31_mm','inm_cm4_8','ipsl_cm5a2_inca','kace_1_0_g','mcm_ua_1_0','miroc_es2h','mpi_esm_1_2_ham','mpi_esm1_2_lr','nesm3','noresm2_lm','sam0_unicon','ukesm1_0_ll')\n",
    "    experiments = ('ssp1_1_9','ssp1_2_6','ssp4_3_4','ssp5_3_4os','ssp2_4_5','ssp4_6_0','ssp3_7_0','ssp5_8_5')\n",
    "    experiments_historical=('historical',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a04313",
   "metadata": {},
   "outputs": [],
   "source": [
    "if period_of_interest == 'past':\n",
    "    y_start = 1950\n",
    "    y_end = 2014\n",
    "    scenarios = copernicus_elements.experiments_historical\n",
    "if period_of_interest == 'future':\n",
    "    y_start = 2015\n",
    "    y_end = 2100\n",
    "    scenarios = copernicus_elements.experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c51b12",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503373bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Period for copernicus function ################################################\n",
    "# Aim of the function: by giving it a first and last year of the period that must analyzed, this function produce several \n",
    "# vectors,containing time informations, useful to download and treat data from CMIP6 projections (https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=overview )\n",
    "# Those time vectors are used in the copernicus_data and the dataframe_copernicus and csv_copernicus functions\n",
    "\n",
    "# function year_copernicus produce \n",
    "# year: a vector containing all the year in the period of interest\n",
    "# year_str: an array containing all the year in the period of interest in the string format\n",
    "# index: an array containing the index of the year and year_str\n",
    "#### Parameters of the function\n",
    "# first_year: number in int format, of the first year of the period of interest\n",
    "# last_year: number in int format, of the last year of the period of interest\n",
    "def year_copernicus(first_year,last_year):\n",
    "    year = np.arange(first_year,(last_year+1),1) # create vector of years\n",
    "    year_str = [0]*len(year) # create initiale empty vector to convert years in int\n",
    "    index = np.arange(0,len(year)) # create vector of index for year\n",
    "    i = 0 # initialize index\n",
    "    for i in index: # convert all the date in string format\n",
    "        year_str[i]=str(year[i])\n",
    "    return (year, year_str, index)\n",
    "\n",
    "# function date_copernicus produce \n",
    "# dates: the format depend on the temporal reolution, but always contain the dates of the period of interest.\n",
    "#        with temporal_resolution=daily, dates is a DatetimeIndex\n",
    "#        with temporal_resolution=monthly, dates is a list\n",
    "# index_dates: an array containing the index of the dates\n",
    "#### Parameters of the function\n",
    "# temporal_resolution: daily or monthly\n",
    "# year_str: ???? produce by function year_copernicus, containing the year of the period of interest in string format\n",
    "def date_copernicus(temporal_resolution,year_str):\n",
    "    start_date = \"01-01-\"+year_str[0] # string start date based on start year\n",
    "    stop_date = \"31-12-\"+year_str[len(year_str)-1] # string stop date based on stop year\n",
    "    if temporal_resolution =='daily':\n",
    "        # vector of dates between start date and stop date\n",
    "        dates = pd.date_range(start_date,stop_date)# dates is a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "        # By default, freq = 'D', which means calendar day frequency (source : https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "        #index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    if temporal_resolution =='monthly':\n",
    "        dates = pd.date_range(start_date,stop_date,freq='MS') # vector of dates between start date and stop date\n",
    "        dates=list(dates.strftime('%m-%Y')) # dates is an pandas.core.indexes.base.Index, not a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "    #if temporal_resolution =='fixed': trouver donnees pour gerer cela\n",
    "    index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    return (dates, index_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bec7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Download data from Copernicus Website ############################################\n",
    "# Aim of the function: this function aims to downloaded with the function copernicus_data the files of interest from the website\n",
    "# Copernicus CMIP6\n",
    "# Actions of this function\n",
    "#     1) Create the string indicating the period of interest\n",
    "#     2) Download data, with its corresponding experiments and models\n",
    "#        2 a) Creates path for file\n",
    "#        2 b) Thanks to function 'copernicus_data', download the data inthe path just created\n",
    "\n",
    "# Parameters of the function\n",
    "# temporal_resolution: 'daily', 'monthly', or 'fixed'. String type \n",
    "# year_str: list containing all the years under the string type and in the period of interest\n",
    "# experiments: copernicus_elements.experiments\n",
    "# models: copernicus_elements.models\n",
    "# out_path: path were the outputs are registered. Defined by the user at the beginning of the code \n",
    "# global_variable: global name of the climate variable of interest (example: Wind)\n",
    "# name_variable: name of the elements downloaded from copernicus (example: 'near_surface_wind_speed')\n",
    "# area: list containing latitudes and longitudes of area of interest\n",
    "# name_area: Name of the area of interest\n",
    "# source: name of the source of the data, by default it is 'Copernicus-CMIP6'\n",
    "\n",
    "def download_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable,area, name_area,source='Copernicus-CMIP6'):    \n",
    "    # create string for name of folder depending on type of period\n",
    "    if temporal_resolution == 'fixed':\n",
    "        period = 'fixed'\n",
    "    else:\n",
    "        period=year_str[0]+'-'+year_str[len(year_str)-1]\n",
    "        \n",
    "    for SSP in experiments:\n",
    "        experiment = (SSP,) # create tuple for iteration of dataframe\n",
    "        for model_simulation in models:\n",
    "            model =(model_simulation,) # create tuple for iteration of dataframe\n",
    "            print('Test with scenario '+SSP+' and model '+model_simulation)\n",
    "            # path were the futur downloaded file is registered\n",
    "            path_for_file= os.path.join(out_path,global_variable,name_variable,source,'raw_data',period,SSP,model_simulation)\n",
    "            #path_for_file = path_length(path_for_file)\n",
    "            # existence of path_for_file tested in copernicus function\n",
    "            copernicus_data(temporal_resolution,SSP,name_variable,model_simulation,year_str,area,path_for_file,out_path,name_area,source)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350b5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Copernicus data function ###################################################\n",
    "# Aim of the function : Determine if the data were already downloadeed or not. If the data were not downloaded, call\n",
    "# function 'try_download_copernicus' to download them. If the data were already downloaded but not extracted, call function\n",
    "# 'download_extract'\n",
    "# Actions of this function\n",
    "#     1) create the string of the path where the data will be registered \n",
    "#        \n",
    "#     2) Check if the path where the data will be registered already exists or not\n",
    "#        2 a) The path where the data will be registered does not exist\n",
    "#             The path where are the compressed data exists ?\n",
    "#                   ---> no : call the 'try_download_copernicus' to download and extract the data of interest\n",
    "#                   ---> yes : is the path empty ?\n",
    "#                              > yes : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                              > no : call function 'download_extract' to extract the files in this path to path_for_file\n",
    "#        2 b) The path where the data will be registered does exist\n",
    "#             Is the path empty ?\n",
    "#                   ---> yes : the path where the compressed data are exists ?\n",
    "#                             > no : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                             > yes : is the folder empty ?\n",
    "#                                     * yes : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                                     * no : call function 'download_extract' to extract the files in this path to path_for_file\n",
    "#                   ---> no : the data were downloaded and extracted for the elements of interest \n",
    "\n",
    "#### Parameters of the function\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : scenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# year: year(s) of study to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# out_path: path were all the outputs are registered, defined by the user in the begining of the main code\n",
    "# name_area :  Name of the area of interest\n",
    "# source: name of the source of the data (here 'Copernicus-CMIP6')\n",
    "\n",
    "def copernicus_data(temporal_resolution,SSP,name_variable,model,year,area,path_for_file,out_path,name_area,source): \n",
    "    # create path for the downloaded file\n",
    "    start_path = os.path.join(out_path,'Data_download_zip')\n",
    "    file_download=create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source)\n",
    "    \n",
    "    if not os.path.isdir(path_for_file):\n",
    "        # the path for the file does not exist\n",
    "        print('path_for_file does not exist: the data may not have been downloaded') \n",
    "        if not os.path.isdir(file_download):\n",
    "            print('file_download does not exist: the data were not downloaded')\n",
    "            # function try to download from copernicus\n",
    "            try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "            return\n",
    "            \n",
    "        else: # if the path already exist, the data in zip format should also exists\n",
    "            if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                print('The path for the download file exists, but is empty')\n",
    "                # function try to download from copernicus\n",
    "                try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)                \n",
    "                return\n",
    "            else:\n",
    "                print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                download_extract(path_for_file,file_download,name_area)\n",
    "                return\n",
    "                \n",
    "    else: \n",
    "        # the path for the file exists\n",
    "        if not os.listdir(path_for_file): # if the path is empty\n",
    "            if not os.path.isdir(file_download):\n",
    "                print('file_download does not exist: the data were not downloaded')\n",
    "                # function try to download from copernicus\n",
    "                try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "                return\n",
    "\n",
    "            else: # if the path already exist, the data in zip format should also exists\n",
    "                if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                    print('The path for the download file exists, but is empty')\n",
    "                    # function try to download from copernicus\n",
    "                    try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "                    return\n",
    "                else:\n",
    "                    print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                    download_extract(path_for_file,file_download,name_area)\n",
    "                    return\n",
    "        \n",
    "        else: # if the path is not empty\n",
    "            print(f'The data has already been downloaded and extracted at {path_for_file}')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c6d6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### try_download_copernicus function ###################################################\n",
    "# Aim of the function : download compressed files from the Copernicus CMIP6 website (indicated at the beginning of the website)\n",
    "\n",
    "##### Actions of the functions :\n",
    "#     1) import function cdsapi.Client(). Will be use in step 3, with c.retrieve\n",
    "#     2) Create the variables dictionnary, depending on the parameters of 'try_download_copernicus'. this dictionnary will then\n",
    "#        be used in the c.retrieve function\n",
    "#     3) Try to downloaded compressed file from Copernicus CMIP6 website. If parameters are not matching, will fall in except \n",
    "#        and continue\n",
    "#     4) Use function 'download_extract' to extract compressed files in path_for_file\n",
    "\n",
    "##### Parameters :\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : scenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# year: year(s) of study to choose\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# file_download : path where the compressed files under a zip format are registered\n",
    "# name_area : Name of the area of interest\n",
    "\n",
    "def try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area):\n",
    "    c = cdsapi.Client()# function to use the c.retrieve\n",
    "    # basic needed dictionnary to give to the c.retrieve function the parameters asked by the user\n",
    "    variables = {\n",
    "                'format': 'zip', # this function is only designed to download and unzip zip files\n",
    "                'temporal_resolution': temporal_resolution,\n",
    "                'experiment': SSP,\n",
    "                'variable': name_variable,\n",
    "                'model': model,\n",
    "    }\n",
    "\n",
    "    if area != []: # the user is interested by a sub region and not the whole region \n",
    "        variables.update({'area':area}) \n",
    "\n",
    "    if (name_variable=='air_temperature') or (name_variable=='relative_humidity') or (name_variable=='specific_humidity') or (name_variable=='eastward_wind') or (name_variable=='northward_wind') or (name_variable=='geopotential_height'): # test if variable is temperature\n",
    "        variables['level'] = '1000' # [hPa], value of the standard pressure at sea level is 1013.25 [hPa], so 1000 [hPa] is the neareste value. Other pressure value are available but there is no interest for the aim of this project\n",
    "\n",
    "    if temporal_resolution != 'fixed':# if 'fixed', no year, month, date to choose\n",
    "        variables['year']=year # period chosen by the user\n",
    "        variables['month']= calendar.default_month  # be default, all the months are given; defined in class calendar\n",
    "        if temporal_resolution == 'daily':\n",
    "            variables['day']= calendar.default_day # be default, all the days are given; defined in class calendar\n",
    "    # c.retrieve download the data from the website\n",
    "    try:\n",
    "        c.retrieve(\n",
    "            'projections-cmip6',\n",
    "            variables,\n",
    "            'download.zip') # the file in a zip format is registered in the current directory\n",
    "    except:\n",
    "        print('Some parameters are not matching')\n",
    "        return # stop the function, because some data the user entered are not matching\n",
    "    print('The file has been download')\n",
    "    # function to extract the downloaded zip\n",
    "    download_extract(path_for_file,file_download,name_area)\n",
    "    print('The file has been extracted')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4958584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'download_extract' function aims to extract in path_for_file, the downloaded file in zip format which is registered \n",
    "# in file_download\n",
    "\n",
    "#### Actions of the function :\n",
    "#     1) Check if the path_for_file, where the decompressed file should be registered, exists\n",
    "#        > no : ensure the creation of the path with os.makedirs\n",
    "#     2) Check if the compressed file is in the working directory\n",
    "#        > no : move the compressed fil to the working directory\n",
    "#     3) Extract the compressed file, in a folder named 'name_area'\n",
    "#     4) Check if the file_download, where the compressed file should be registered, exists\n",
    "#        > no : ensure the creation of the path with os.makedirs\n",
    "#     5) move the files to the appropriate places\n",
    "\n",
    "def download_extract(path_for_file,file_download,name_area):\n",
    "    # step 1\n",
    "    path_for_file = os.path.join(path_for_file,name_area)\n",
    "    if not os.path.isdir(path_for_file): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(path_for_file) # to ensure the creation of the path\n",
    "        print(path_for_file)\n",
    "        print('Path for the file is created, did not existed before')\n",
    "    \n",
    "    # step 2\n",
    "    if 'download.zip' not in os.listdir(): # check if download is in the working directory\n",
    "        print('The download zip is moved to the working directory')\n",
    "        path_downloaded_zip=os.path.join(file_download,'download.zip')\n",
    "        shutil.move(path_downloaded_zip,r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool') # move download file to working directory\n",
    "    \n",
    "    # step 3\n",
    "    from zipfile import ZipFile\n",
    "    zf = ZipFile('download.zip', 'r')\n",
    "    zf.extractall(name_area) # if no precision of directory, extract in current directory\n",
    "    zf.close()\n",
    "\n",
    "    # step 4\n",
    "    if not os.path.isdir(file_download): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(file_download) # to ensure the creation of the path\n",
    "    \n",
    "    # step 5\n",
    "    # moving download to appropriate place\n",
    "    shutil.move('download.zip',file_download) # no need to delete 'download.zip' from inital place\n",
    "    for file in os.listdir(name_area):\n",
    "        try:\n",
    "            shutil.move(os.path.join(r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool',name_area,file),os.path.join(path_for_file,file)) # move extracted data to the path created for them\n",
    "            print('the file named '+file+ ' was moved')\n",
    "        except:\n",
    "            #os.remove(file) # does not work\n",
    "            pass\n",
    "    #if name_area in os.listdir():\n",
    "    #    print(name_area + ' is here')\n",
    "    #    shutil.rmtree(name_area)\n",
    "    #    print(name_area + ' has been deleted')\n",
    "    print('\\n The downloaded file is extracted')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1770731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'create_file_download_path' function to create path for the downloaded compressed folder\n",
    "\n",
    "def create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source):\n",
    "    # adapt the name of the folder for the period, depending on the type of period\n",
    "    if len(year)==1:\n",
    "        file_download = os.path.join(start_path,name_variable,source,year,SSP,model,name_area)\n",
    "    elif len(year)>1:\n",
    "        period=year[0]+'-'+year[len(year)-1]\n",
    "        file_download = os.path.join(start_path,name_variable,source,period,SSP,model,name_area)\n",
    "    elif temporal_resolution == 'fixed':\n",
    "        file_download = os.path.join(start_path,name_variable,source,'fixed_period',SSP,model,name_area)\n",
    "    #file_download = path_length(file_download)\n",
    "    return file_download # returns string of the path where the downloaded compressed folder must be registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01fd0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seach_for_nc is a function looking in path_for_file for a document in .nc format\n",
    "\n",
    "def search_for_nc(path_for_file):\n",
    "    print('path_for_file does exist Function copernicus search for nc')\n",
    "    for file in os.listdir(path_for_file):\n",
    "        if file.endswith(\".nc\"):\n",
    "            final_path=os.path.join(path_for_file, file)\n",
    "            \n",
    "            print('The file is in the path Function copernicus search for nc\\n')\n",
    "            print('Before path_length, The final path for the nc file is: '+final_path)\n",
    "            answer = str(os.path.isfile(final_path))\n",
    "            print('\\n The final path for nc file exists ? '+answer+'\\n')\n",
    "            final_path=path_length(final_path) # check if length of path is too long\n",
    "            print('After path_length, The final path for the nc file is: '+final_path)\n",
    "            answer = str(os.path.isfile(final_path))\n",
    "            print('\\n The final path for nc file exists ? '+answer+'\\n')\n",
    "            return final_path # the function returns the path of the nc file of interest\n",
    "            break # stop the function if a nc file was found \n",
    "        else:\n",
    "            pass\n",
    "    # the all folder has been search and there is no nc file in it\n",
    "    print('Problem : No nc file was found Function copernicus Function copernicus search for nc')# this line is out of the for loop, \n",
    "    #because it should only appear once all the folder has been examinated and if the break of the if was not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073da551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions test if the path is too long\n",
    "# if the path is more than 250 char, the path wll be modified in order for windows to accept is as a path\n",
    "\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccff81",
   "metadata": {},
   "source": [
    "# Register copernicus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3f80c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(year, year_str, index)=year_copernicus(y_start,y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with scenario historical and model access_cm2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does exist, the data have been downloaded, but not extracted\n",
      "\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\temperature\\daily_maximum_near_surface_air_temperature\\Copernicus-CMIP6\\raw_data\\1950-2014\\historical\\access_cm2\\all-Mozambique\n",
      "Path for the file is created, did not existed before\n",
      "The download zip is moved to the working directory\n",
      "the file named tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_19500101-20141231_v20191108.nc was moved\n",
      "\n",
      " The downloaded file is extracted\n",
      "Test with scenario historical and model awi_cm_1_1_mr\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does exist, the data have been downloaded, but not extracted\n",
      "\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\temperature\\daily_maximum_near_surface_air_temperature\\Copernicus-CMIP6\\raw_data\\1950-2014\\historical\\awi_cm_1_1_mr\\all-Mozambique\n",
      "Path for the file is created, did not existed before\n",
      "The download zip is moved to the working directory\n",
      "the file named tasmax_day_AWI-CM-1-1-MR_historical_r1i1p1f1_gn_19500101-20141231_v20181218.nc was moved\n",
      "\n",
      " The downloaded file is extracted\n",
      "Test with scenario historical and model bcc_csm2_mr\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:42,667 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:42,668 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:42,754 INFO Request is queued\n",
      "2023-07-14 18:48:43,801 INFO Request is failed\n",
      "2023-07-14 18:48:43,802 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:43,802 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'BCC-CSM2-MR', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:43,803 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:43,803 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:43,804 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:43,804 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:43,805 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:43,806 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:43,806 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:43,808 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:43,809 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:43,809 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:43,810 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:43,811 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:43,812 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:43,813 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'BCC-CSM2-MR', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:43,848 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:43,849 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:43,934 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model cams_csm1_0\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:44,969 INFO Request is failed\n",
      "2023-07-14 18:48:44,969 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:44,970 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CAMS-CSM1-0', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:44,970 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:44,972 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:44,972 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:44,973 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:44,974 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:44,974 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:44,975 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:44,976 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:44,976 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:44,976 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:44,977 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:44,977 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:44,978 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:44,978 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CAMS-CSM1-0', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:45,017 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:45,018 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:45,113 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model canesm5_canoe\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:46,153 INFO Request is failed\n",
      "2023-07-14 18:48:46,155 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:46,155 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CanESM5-CanOE', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:46,155 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:46,155 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:46,157 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:46,158 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:46,158 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:46,158 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:46,159 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:46,159 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:46,159 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:46,161 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:46,162 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:46,163 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:46,164 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:46,165 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CanESM5-CanOE', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:46,214 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:46,215 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:46,285 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model cesm2_fv2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:47,335 INFO Request is failed\n",
      "2023-07-14 18:48:47,336 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:47,336 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CESM2-FV2', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:47,336 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:47,338 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:47,338 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:47,339 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:47,339 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:47,340 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:47,341 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:47,342 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:47,342 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:47,343 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:47,344 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:47,345 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:47,346 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:47,346 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CESM2-FV2', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:47,390 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:47,391 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:47,454 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model cesm2_waccm_fv2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:48,498 INFO Request is failed\n",
      "2023-07-14 18:48:48,499 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:48,499 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CESM2-WACCM-FV2', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:48,500 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:48,500 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:48,501 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:48,501 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:48,502 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:48,503 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:48,504 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:48,505 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:48,505 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:48,506 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:48,507 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:48,508 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:48,508 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:48,509 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CESM2-WACCM-FV2', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:48,547 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:48,548 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:48,667 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model cmcc_cm2_hr4\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:51,241 INFO Request is running\n",
      "2023-07-14 18:48:53,522 INFO Request is failed\n",
      "2023-07-14 18:48:53,524 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:48:53,524 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'CMCC-CM2-HR4', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:48:53,525 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:48:53,526 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:48:53,527 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:48:53,528 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:48:53,528 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:48:53,529 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:48:53,530 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:48:53,530 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:48:53,531 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:48:53,532 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:48:53,534 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:48:53,535 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:48:53,535 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:48:53,536 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'CMCC-CM2-HR4', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model cmcc_esm2\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does exist, the data have been downloaded, but not extracted\n",
      "\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\temperature\\daily_maximum_near_surface_air_temperature\\Copernicus-CMIP6\\raw_data\\1950-2014\\historical\\cmcc_esm2\\all-Mozambique\n",
      "Path for the file is created, did not existed before\n",
      "The download zip is moved to the working directory\n",
      "the file named tasmax_day_CMCC-ESM2_historical_r1i1p1f1_gn_19500101-20141231_v20210114.nc was moved\n",
      "\n",
      " The downloaded file is extracted\n",
      "Test with scenario historical and model cnrm_cm6_1_hr\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does exist, the data have been downloaded, but not extracted\n",
      "\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\temperature\\daily_maximum_near_surface_air_temperature\\Copernicus-CMIP6\\raw_data\\1950-2014\\historical\\cnrm_cm6_1_hr\\all-Mozambique\n",
      "Path for the file is created, did not existed before\n",
      "The download zip is moved to the working directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:48:59,208 INFO Welcome to the CDS\n",
      "2023-07-14 18:48:59,209 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:48:59,304 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the file named tasmax_day_CNRM-CM6-1-HR_historical_r1i1p1f2_gr_19500101-20141231_v20191021.nc was moved\n",
      "\n",
      " The downloaded file is extracted\n",
      "Test with scenario historical and model e3sm_1_0\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:49:00,343 INFO Request is failed\n",
      "2023-07-14 18:49:00,344 ERROR Message: an internal error occurred processing your request\n",
      "2023-07-14 18:49:00,345 ERROR Reason:  No matching data for request {'experiment': 'historical', 'model': 'E3SM-1-0', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:49:00,346 ERROR   Traceback (most recent call last):\n",
      "2023-07-14 18:49:00,346 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/cdshandlers/services/handler.py\", line 59, in handle_request\n",
      "2023-07-14 18:49:00,347 ERROR       result = cached(context.method, proc, context, context.args, context.kwargs)\n",
      "2023-07-14 18:49:00,348 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/caching.py\", line 108, in cached\n",
      "2023-07-14 18:49:00,348 ERROR       result = proc(context, *context.args, **context.kwargs)\n",
      "2023-07-14 18:49:00,349 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 124, in __call__\n",
      "2023-07-14 18:49:00,349 ERROR       return p(*args, **kwargs)\n",
      "2023-07-14 18:49:00,350 ERROR     File \"/opt/cdstoolbox/cdscompute/cdscompute/services.py\", line 60, in __call__\n",
      "2023-07-14 18:49:00,350 ERROR       return self.proc(context, *args, **kwargs)\n",
      "2023-07-14 18:49:00,350 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/__init__.py\", line 30, in execute\n",
      "2023-07-14 18:49:00,352 ERROR       request_facets, request = facets.search(context, request)\n",
      "2023-07-14 18:49:00,354 ERROR     File \"/home/cds/cdsservices/services/esgf_wps/facets.py\", line 61, in search\n",
      "2023-07-14 18:49:00,354 ERROR       raise ValueError(f'No matching data for request {tmp_request}')\n",
      "2023-07-14 18:49:00,354 ERROR   ValueError: No matching data for request {'experiment': 'historical', 'model': 'E3SM-1-0', 'temporal_resolution': 'day', 'variable': 'tasmax'}\n",
      "2023-07-14 18:49:00,394 INFO Welcome to the CDS\n",
      "2023-07-14 18:49:00,396 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/projections-cmip6\n",
      "2023-07-14 18:49:00,436 INFO Request is queued\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some parameters are not matching\n",
      "Test with scenario historical and model e3sm_1_1_eca\n",
      "path_for_file does not exist: the data may not have been downloaded\n",
      "file_download does not exist: the data were not downloaded\n"
     ]
    }
   ],
   "source": [
    "download_copernicus(temporal_resolution,year_str,scenarios,copernicus_elements.models,out_path, global_variable, name_variable,area,name_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aea961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a31c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
