{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93dcc14",
   "metadata": {},
   "source": [
    "This notebook is meant to download data from copernicus CMIP6.\n",
    "\n",
    "Data source : https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c8b78",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_of_interest = 'past' # 'future' (2015-2100) or 'past' (1950-2014)\n",
    "global_variable = 'temperature'\n",
    "name_variable = 'near_surface_air_temperature' \n",
    "\n",
    "# 'tas' 'near_surface_air_temperature'\n",
    "# 'tasmax' 'daily_maximum_near_surface_air_temperature'\n",
    "# 'tasmin' 'daily_minimum_near_surface_air_temperature'\n",
    "# 'hurs' 'near_surface_specific_humidity'\n",
    "# 'Wind' 'near_surface_wind_speed'\n",
    "\n",
    "temporal_resolution = 'daily'\n",
    "\n",
    "# wind register at 10 m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fe416",
   "metadata": {},
   "source": [
    "# Functions and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9510fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4 as nc#not directly used but needs to be imported for some nc4 files manipulations, use for nc files\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import datetime # to have actual date\n",
    "import os\n",
    "import os.path\n",
    "import cdsapi # for copernicus function\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3262e08",
   "metadata": {},
   "source": [
    "# Out path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead08c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path=r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53516663",
   "metadata": {},
   "source": [
    "# Area information\n",
    "\n",
    "This code download data one area at the time. The user must indicate which part of the word he/she wnats to download.\n",
    "\n",
    "Reminder: \n",
    "\n",
    "latitude is vertical, it specifies North-South positions.\n",
    "\n",
    "longitude is horizontal, it specifies West-East positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default coordinates are the ones of Mozambique\n",
    "\n",
    "name_area = 'all-Mozambique'\n",
    "\n",
    "North = -10\n",
    "South = -27\n",
    "West = 30\n",
    "East = 41\n",
    "\n",
    "area = [North, West, South, East] # list format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3f294",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e29fa6",
   "metadata": {},
   "source": [
    "### Calendar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to define parameter of time that remain constant durinf the whole script\n",
    "class calendar:\n",
    "    default_month = [ \n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                ]\n",
    "    default_day = [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                '13', '14', '15',\n",
    "                '16', '17', '18',\n",
    "                '19', '20', '21',\n",
    "                '22', '23', '24',\n",
    "                '25', '26', '27',\n",
    "                '28', '29', '30',\n",
    "                '31',\n",
    "                ]\n",
    "    #actual_date = datetime.date.today()\n",
    "    #actual_year = actual_date.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c5e67",
   "metadata": {},
   "source": [
    "### Copernicus class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f79fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of tuples that will be useful to search which data are available or not\n",
    "# make it tuples to make unchangeable\n",
    "class copernicus_elements:\n",
    "    # there is 58 models\n",
    "    models =('access_cm2','awi_cm_1_1_mr','bcc_csm2_mr','cams_csm1_0','canesm5_canoe','cesm2_fv2','cesm2_waccm_fv2','cmcc_cm2_hr4','cmcc_esm2','cnrm_cm6_1_hr','e3sm_1_0','e3sm_1_1_eca','ec_earth3_aerchem','ec_earth3_veg','fgoals_f3_l','fio_esm_2_0','giss_e2_1_g','hadgem3_gc31_ll','iitm_esm','inm_cm5_0','ipsl_cm6a_lr','kiost_esm','miroc6','miroc_es2l','mpi_esm1_2_hr','mri_esm2_0','norcpm1','noresm2_mm','taiesm1','access_esm1_5','awi_esm_1_1_lr','bcc_esm1','canesm5','cesm2','cesm2_waccm','ciesm','cmcc_cm2_sr5','cnrm_cm6_1','cnrm_esm2_1','e3sm_1_1','ec_earth3','ec_earth3_cc','ec_earth3_veg_lr','fgoals_g3','gfdl_esm4','giss_e2_1_h','hadgem3_gc31_mm','inm_cm4_8','ipsl_cm5a2_inca','kace_1_0_g','mcm_ua_1_0','miroc_es2h','mpi_esm_1_2_ham','mpi_esm1_2_lr','nesm3','noresm2_lm','sam0_unicon','ukesm1_0_ll')\n",
    "    experiments = ('ssp1_1_9','ssp1_2_6','ssp4_3_4','ssp5_3_4os','ssp2_4_5','ssp4_6_0','ssp3_7_0','ssp5_8_5')\n",
    "    experiments_historical=('historical',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a04313",
   "metadata": {},
   "outputs": [],
   "source": [
    "if period_of_interest == 'past':\n",
    "    y_start = 1950\n",
    "    y_end = 2014\n",
    "    scenarios = copernicus_elements.experiments_historical\n",
    "if period_of_interest == 'future':\n",
    "    y_start = 2015\n",
    "    y_end = 2100\n",
    "    scenarios = copernicus_elements.experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c51b12",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503373bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ Period for copernicus function ################################################\n",
    "# Aim of the function: by giving it a first and last year of the period that must analyzed, this function produce several \n",
    "# vectors,containing time informations, useful to download and treat data from CMIP6 projections (https://cds.climate.copernicus.eu/cdsapp#!/dataset/projections-cmip6?tab=overview )\n",
    "# Those time vectors are used in the copernicus_data and the dataframe_copernicus and csv_copernicus functions\n",
    "\n",
    "# function year_copernicus produce \n",
    "# year: a vector containing all the year in the period of interest\n",
    "# year_str: an array containing all the year in the period of interest in the string format\n",
    "# index: an array containing the index of the year and year_str\n",
    "#### Parameters of the function\n",
    "# first_year: number in int format, of the first year of the period of interest\n",
    "# last_year: number in int format, of the last year of the period of interest\n",
    "def year_copernicus(first_year,last_year):\n",
    "    year = np.arange(first_year,(last_year+1),1) # create vector of years\n",
    "    year_str = [0]*len(year) # create initiale empty vector to convert years in int\n",
    "    index = np.arange(0,len(year)) # create vector of index for year\n",
    "    i = 0 # initialize index\n",
    "    for i in index: # convert all the date in string format\n",
    "        year_str[i]=str(year[i])\n",
    "    return (year, year_str, index)\n",
    "\n",
    "# function date_copernicus produce \n",
    "# dates: the format depend on the temporal reolution, but always contain the dates of the period of interest.\n",
    "#        with temporal_resolution=daily, dates is a DatetimeIndex\n",
    "#        with temporal_resolution=monthly, dates is a list\n",
    "# index_dates: an array containing the index of the dates\n",
    "#### Parameters of the function\n",
    "# temporal_resolution: daily or monthly\n",
    "# year_str: ???? produce by function year_copernicus, containing the year of the period of interest in string format\n",
    "def date_copernicus(temporal_resolution,year_str):\n",
    "    start_date = \"01-01-\"+year_str[0] # string start date based on start year\n",
    "    stop_date = \"31-12-\"+year_str[len(year_str)-1] # string stop date based on stop year\n",
    "    if temporal_resolution =='daily':\n",
    "        # vector of dates between start date and stop date\n",
    "        dates = pd.date_range(start_date,stop_date)# dates is a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "        # By default, freq = 'D', which means calendar day frequency (source : https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases)\n",
    "        #index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    if temporal_resolution =='monthly':\n",
    "        dates = pd.date_range(start_date,stop_date,freq='MS') # vector of dates between start date and stop date\n",
    "        dates=list(dates.strftime('%m-%Y')) # dates is an pandas.core.indexes.base.Index, not a pandas.core.indexes.datetimes.DatetimeIndex\n",
    "    #if temporal_resolution =='fixed': trouver donnees pour gerer cela\n",
    "    index_dates = np.arange(0,len(dates)) # vector containning index o dates vector\n",
    "    return (dates, index_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Download data from Copernicus Website ############################################\n",
    "# Aim of the function: this function aims to downloaded with the function copernicus_data the files of interest from the website\n",
    "# Copernicus CMIP6\n",
    "# Actions of this function\n",
    "#     1) Create the string indicating the period of interest\n",
    "#     2) Download data, with its corresponding experiments and models\n",
    "#        2 a) Creates path for file\n",
    "#        2 b) Thanks to function 'copernicus_data', download the data inthe path just created\n",
    "\n",
    "# Parameters of the function\n",
    "# temporal_resolution: 'daily', 'monthly', or 'fixed'. String type \n",
    "# year_str: list containing all the years under the string type and in the period of interest\n",
    "# experiments: copernicus_elements.experiments\n",
    "# models: copernicus_elements.models\n",
    "# out_path: path were the outputs are registered. Defined by the user at the beginning of the code \n",
    "# global_variable: global name of the climate variable of interest (example: Wind)\n",
    "# name_variable: name of the elements downloaded from copernicus (example: 'near_surface_wind_speed')\n",
    "# area: list containing latitudes and longitudes of area of interest\n",
    "# name_area: Name of the area of interest\n",
    "# source: name of the source of the data, by default it is 'Copernicus-CMIP6'\n",
    "\n",
    "def download_copernicus(temporal_resolution,year_str,experiments,models,out_path, global_variable, name_variable,area, name_area,source='Copernicus-CMIP6'):    \n",
    "    # create string for name of folder depending on type of period\n",
    "    if temporal_resolution == 'fixed':\n",
    "        period = 'fixed'\n",
    "    else:\n",
    "        period=year_str[0]+'-'+year_str[len(year_str)-1]\n",
    "        \n",
    "    for SSP in experiments:\n",
    "        experiment = (SSP,) # create tuple for iteration of dataframe\n",
    "        for model_simulation in models:\n",
    "            model =(model_simulation,) # create tuple for iteration of dataframe\n",
    "            print('Test with scenario '+SSP+' and model '+model_simulation)\n",
    "            # path were the futur downloaded file is registered\n",
    "            path_for_file= os.path.join(out_path,global_variable,name_variable,source,'raw_data',period,SSP,model_simulation)\n",
    "            #path_for_file = path_length(path_for_file)\n",
    "            # existence of path_for_file tested in copernicus function\n",
    "            copernicus_data(temporal_resolution,SSP,name_variable,model_simulation,year_str,area,path_for_file,out_path,name_area,source)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Copernicus data function ###################################################\n",
    "# Aim of the function : Determine if the data were already downloadeed or not. If the data were not downloaded, call\n",
    "# function 'try_download_copernicus' to download them. If the data were already downloaded but not extracted, call function\n",
    "# 'download_extract'\n",
    "# Actions of this function\n",
    "#     1) create the string of the path where the data will be registered \n",
    "#        \n",
    "#     2) Check if the path where the data will be registered already exists or not\n",
    "#        2 a) The path where the data will be registered does not exist\n",
    "#             The path where are the compressed data exists ?\n",
    "#                   ---> no : call the 'try_download_copernicus' to download and extract the data of interest\n",
    "#                   ---> yes : is the path empty ?\n",
    "#                              > yes : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                              > no : call function 'download_extract' to extract the files in this path to path_for_file\n",
    "#        2 b) The path where the data will be registered does exist\n",
    "#             Is the path empty ?\n",
    "#                   ---> yes : the path where the compressed data are exists ?\n",
    "#                             > no : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                             > yes : is the folder empty ?\n",
    "#                                     * yes : use 'try_download_copernicus' to download and extract the data of interest\n",
    "#                                     * no : call function 'download_extract' to extract the files in this path to path_for_file\n",
    "#                   ---> no : the data were downloaded and extracted for the elements of interest \n",
    "\n",
    "#### Parameters of the function\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : scenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# year: year(s) of study to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# out_path: path were all the outputs are registered, defined by the user in the begining of the main code\n",
    "# name_area :  Name of the area of interest\n",
    "# source: name of the source of the data (here 'Copernicus-CMIP6')\n",
    "\n",
    "def copernicus_data(temporal_resolution,SSP,name_variable,model,year,area,path_for_file,out_path,name_area,source): \n",
    "    # create path for the downloaded file\n",
    "    start_path = os.path.join(out_path,'Data_download_zip')\n",
    "    file_download=create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source)\n",
    "    \n",
    "    if not os.path.isdir(path_for_file):\n",
    "        # the path for the file does not exist\n",
    "        print('path_for_file does not exist: the data may not have been downloaded') \n",
    "        if not os.path.isdir(file_download):\n",
    "            print('file_download does not exist: the data were not downloaded')\n",
    "            # function try to download from copernicus\n",
    "            try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "            return\n",
    "            \n",
    "        else: # if the path already exist, the data in zip format should also exists\n",
    "            if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                print('The path for the download file exists, but is empty')\n",
    "                # function try to download from copernicus\n",
    "                try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)                \n",
    "                return\n",
    "            else:\n",
    "                print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                download_extract(path_for_file,file_download,name_area)\n",
    "                return\n",
    "                \n",
    "    else: \n",
    "        # the path for the file exists\n",
    "        if not os.listdir(path_for_file): # if the path is empty\n",
    "            if not os.path.isdir(file_download):\n",
    "                print('file_download does not exist: the data were not downloaded')\n",
    "                # function try to download from copernicus\n",
    "                try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "                return\n",
    "\n",
    "            else: # if the path already exist, the data in zip format should also exists\n",
    "                if not os.path.isfile(os.path.join(file_download,'download.zip')):\n",
    "                    print('The path for the download file exists, but is empty')\n",
    "                    # function try to download from copernicus\n",
    "                    try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area)\n",
    "                    return\n",
    "                else:\n",
    "                    print('file_download does exist, the data have been downloaded, but not extracted')\n",
    "                    download_extract(path_for_file,file_download,name_area)\n",
    "                    return\n",
    "        \n",
    "        else: # if the path is not empty\n",
    "            print(f'The data has already been downloaded and extracted at {path_for_file}')\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### try_download_copernicus function ###################################################\n",
    "# Aim of the function : download compressed files from the Copernicus CMIP6 website (indicated at the beginning of the website)\n",
    "\n",
    "##### Actions of the functions :\n",
    "#     1) import function cdsapi.Client(). Will be use in step 3, with c.retrieve\n",
    "#     2) Create the variables dictionnary, depending on the parameters of 'try_download_copernicus'. this dictionnary will then\n",
    "#        be used in the c.retrieve function\n",
    "#     3) Try to downloaded compressed file from Copernicus CMIP6 website. If parameters are not matching, will fall in except \n",
    "#        and continue\n",
    "#     4) Use function 'download_extract' to extract compressed files in path_for_file\n",
    "\n",
    "##### Parameters :\n",
    "# temporal_resolution : daily or monthly or fixed\n",
    "# SSP : scenario that is studied \"Historical\", \"SSP1-1.9\", \"SSP1-2.6\" ...\n",
    "# name_variable : variable to be studied\n",
    "# model: model of projection to choose\n",
    "# area: area of study, if not specific, area should be an empty array area=[]\n",
    "# year: year(s) of study to choose\n",
    "# path_for_file: path where the file must be unzipped\n",
    "# file_download : path where the compressed files under a zip format are registered\n",
    "# name_area : Name of the area of interest\n",
    "\n",
    "def try_download_copernicus(temporal_resolution,SSP,name_variable,model,area,year,path_for_file,file_download,name_area):\n",
    "    c = cdsapi.Client()# function to use the c.retrieve\n",
    "    # basic needed dictionnary to give to the c.retrieve function the parameters asked by the user\n",
    "    variables = {\n",
    "                'format': 'zip', # this function is only designed to download and unzip zip files\n",
    "                'temporal_resolution': temporal_resolution,\n",
    "                'experiment': SSP,\n",
    "                'variable': name_variable,\n",
    "                'model': model,\n",
    "    }\n",
    "\n",
    "    if area != []: # the user is interested by a sub region and not the whole region \n",
    "        variables.update({'area':area}) \n",
    "\n",
    "    if (name_variable=='air_temperature') or (name_variable=='relative_humidity') or (name_variable=='specific_humidity') or (name_variable=='eastward_wind') or (name_variable=='northward_wind') or (name_variable=='geopotential_height'): # test if variable is temperature\n",
    "        variables['level'] = '1000' # [hPa], value of the standard pressure at sea level is 1013.25 [hPa], so 1000 [hPa] is the neareste value. Other pressure value are available but there is no interest for the aim of this project\n",
    "\n",
    "    if temporal_resolution != 'fixed':# if 'fixed', no year, month, date to choose\n",
    "        variables['year']=year # period chosen by the user\n",
    "        variables['month']= calendar.default_month  # be default, all the months are given; defined in class calendar\n",
    "        if temporal_resolution == 'daily':\n",
    "            variables['day']= calendar.default_day # be default, all the days are given; defined in class calendar\n",
    "    # c.retrieve download the data from the website\n",
    "    try:\n",
    "        c.retrieve(\n",
    "            'projections-cmip6',\n",
    "            variables,\n",
    "            'download.zip') # the file in a zip format is registered in the current directory\n",
    "    except:\n",
    "        print('Some parameters are not matching')\n",
    "        return # stop the function, because some data the user entered are not matching\n",
    "    print('The file has been download')\n",
    "    # function to extract the downloaded zip\n",
    "    download_extract(path_for_file,file_download,name_area)\n",
    "    print('The file has been extracted')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4958584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'download_extract' function aims to extract in path_for_file, the downloaded file in zip format which is registered \n",
    "# in file_download\n",
    "\n",
    "#### Actions of the function :\n",
    "#     1) Check if the path_for_file, where the decompressed file should be registered, exists\n",
    "#        > no : ensure the creation of the path with os.makedirs\n",
    "#     2) Check if the compressed file is in the working directory\n",
    "#        > no : move the compressed fil to the working directory\n",
    "#     3) Extract the compressed file, in a folder named 'name_area'\n",
    "#     4) Check if the file_download, where the compressed file should be registered, exists\n",
    "#        > no : ensure the creation of the path with os.makedirs\n",
    "#     5) move the files to the appropriate places\n",
    "\n",
    "def download_extract(path_for_file,file_download,name_area):\n",
    "    # step 1\n",
    "    path_for_file = os.path.join(path_for_file,name_area)\n",
    "    if not os.path.isdir(path_for_file): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(path_for_file) # to ensure the creation of the path\n",
    "        print(path_for_file)\n",
    "        print('Path for the file is created, did not existed before')\n",
    "    \n",
    "    # step 2\n",
    "    if 'download.zip' not in os.listdir(): # check if download is in the working directory\n",
    "        print('The download zip is moved to the working directory')\n",
    "        path_downloaded_zip=os.path.join(file_download,'download.zip')\n",
    "        shutil.move(path_downloaded_zip,r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool') # move download file to working directory\n",
    "    \n",
    "    # step 3\n",
    "    from zipfile import ZipFile\n",
    "    zf = ZipFile('download.zip', 'r')\n",
    "    zf.extractall(name_area) # if no precision of directory, extract in current directory\n",
    "    zf.close()\n",
    "\n",
    "    # step 4\n",
    "    if not os.path.isdir(file_download): # path_for_file does not exists, need to ensure that is is created\n",
    "        os.makedirs(file_download) # to ensure the creation of the path\n",
    "    \n",
    "    # step 5\n",
    "    # moving download to appropriate place\n",
    "    shutil.move('download.zip',file_download) # no need to delete 'download.zip' from inital place\n",
    "    for file in os.listdir(name_area):\n",
    "        shutil.move(os.path.join(r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool',name_area,file),os.path.join(path_for_file,file)) # move extracted data to the path created for them\n",
    "    #if name_area in os.listdir():\n",
    "    #    print(name_area + ' is here')\n",
    "    #    shutil.rmtree(name_area)\n",
    "    #    print(name_area + ' has been deleted')\n",
    "    print('\\n The downloaded file is extracted')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1770731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'create_file_download_path' function to create path for the downloaded compressed folder\n",
    "\n",
    "def create_file_download_path(start_path,name_variable,name_area,SSP,model,year,temporal_resolution,source):\n",
    "    # adapt the name of the folder for the period, depending on the type of period\n",
    "    if len(year)==1:\n",
    "        file_download = os.path.join(start_path,name_variable,source,year,SSP,model,name_area)\n",
    "    elif len(year)>1:\n",
    "        period=year[0]+'-'+year[len(year)-1]\n",
    "        file_download = os.path.join(start_path,name_variable,source,period,SSP,model,name_area)\n",
    "    elif temporal_resolution == 'fixed':\n",
    "        file_download = os.path.join(start_path,name_variable,source,'fixed_period',SSP,model,name_area)\n",
    "    #file_download = path_length(file_download)\n",
    "    return file_download # returns string of the path where the downloaded compressed folder must be registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073da551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions test if the path is too long\n",
    "# if the path is more than 250 char, the path wll be modified in order for windows to accept is as a path\n",
    "\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccff81",
   "metadata": {},
   "source": [
    "# Register copernicus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f80c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(year, year_str, index)=year_copernicus(y_start,y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_copernicus(temporal_resolution,year_str,scenarios,copernicus_elements.models,out_path, global_variable, name_variable,area,name_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace72068",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\temperature\\near_surface_air_temperature\\Copernicus-CMIP6\\raw_data\\1950-2014\\historical\\inm_cm5_0\\all-Mozambique'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d25b485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json',\n",
       " 'adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.png',\n",
       " 'tas_day_KIOST-ESM_historical_r1i1p1f1_gr1_19500101-20141231_v20191202.nc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('all-Mozambique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\all-Mozambique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ea84d2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path 'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCLMRX\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - COWI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCRVA_tool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mall-Mozambique\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124madaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m path_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOWI.net\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mA245000\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mA248363\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCRVA\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnear_surface_air_temperature\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCopernicus-CMIP6\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraw_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m1950-2014\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mkiost_esm\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mall-Mozambique\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_1\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCLMRX\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive - COWI\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGitHub\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCRVA_tool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\shutil.py:813\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    810\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> 813\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path 'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json' already exists"
     ]
    }
   ],
   "source": [
    "path_1 = r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\all-Mozambique\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json'\n",
    "path_2 = '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\temperature\\\\near_surface_air_temperature\\\\Copernicus-CMIP6\\\\raw_data\\\\1950-2014\\\\historical\\\\kiost_esm\\\\all-Mozambique'\n",
    "\n",
    "shutil.move(path_1,r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c94704c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\temperature\\\\near_surface_air_temperature\\\\Copernicus-CMIP6\\\\raw_data\\\\1950-2014\\\\historical\\\\kiost_esm\\\\all-Mozambique\\\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\shutil.py:815\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 815\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\CLMRX\\\\OneDrive - COWI\\\\Documents\\\\GitHub\\\\CRVA_tool\\\\all-Mozambique\\\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json' -> '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\temperature\\\\near_surface_air_temperature\\\\Copernicus-CMIP6\\\\raw_data\\\\1950-2014\\\\historical\\\\kiost_esm\\\\all-Mozambique\\\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m path_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCLMRX\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - COWI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCRVA_tool\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mall-Mozambique\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124madaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m path_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCOWI.net\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mA245000\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mA248363\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCRVA\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnear_surface_air_temperature\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCopernicus-CMIP6\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraw_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m1950-2014\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mkiost_esm\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mall-Mozambique\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\shutil.py:835\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    833\u001b[0m         rmtree(src)\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 835\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\shutil.py:434\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    433\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 434\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\geodata\\lib\\shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    257\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    258\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    259\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\temperature\\\\near_surface_air_temperature\\\\Copernicus-CMIP6\\\\raw_data\\\\1950-2014\\\\historical\\\\kiost_esm\\\\all-Mozambique\\\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json'"
     ]
    }
   ],
   "source": [
    "path_1 = r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\all-Mozambique\\adaptor.esgf_wps.retrieve-1689169153.15843-1234-17-68bb0f07-aa61-47ed-8da9-cf09919ba771_provenance.json'\n",
    "path_2 = '\\\\\\\\COWI.net\\\\projects\\\\A245000\\\\A248363\\\\CRVA\\\\Datasets\\\\temperature\\\\near_surface_air_temperature\\\\Copernicus-CMIP6\\\\raw_data\\\\1950-2014\\\\historical\\\\kiost_esm\\\\all-Mozambique'\n",
    "\n",
    "shutil.move(path_1,path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48401c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d28fd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7da769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CLMRX\\\\OneDrive - COWI\\\\Documents\\\\GitHub\\\\CRVA_tool'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37a0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
