{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcbb322",
   "metadata": {},
   "source": [
    "# User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41760de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_of_interest = 'tas' # need hurs, rsds, sfcWind\n",
    "temporal_resolution = 'day'\n",
    "\n",
    "start_year = 1960 \n",
    "stop_year = 2060\n",
    "\n",
    "# zone of interest in Mozambique\n",
    "# negative latitude is southern hemisphere, latitude is horizontal, longitude is vertical\n",
    "# decimal degrees\n",
    "#min_lat_zone_interest = -30\n",
    "#max_lat_zone_interest = -10\n",
    "#min_lon_zone_interest = 30\n",
    "#max_lon_zone_interest = 45\n",
    "\n",
    "# to have the more precise locations, based on this link https://ds.nccs.nasa.gov/thredds/ncss/grid/AMES/NEX/GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/pr/pr_day_ACCESS-CM2_historical_r1i1p1f1_gn_2014.nc/dataset.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c261e09",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f277db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import multiprocessing as mp# to download several file in parrallel\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8847fc",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bea1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the name of the file from its url\n",
    "# the imput is an url\n",
    "def extract_name_file(url):\n",
    "    index_before_name=url.rfind('/') # returns the highest index where the last character '/' was found, which is just before the name of the file    \n",
    "    #index_end_name=url.rfind('?') # returns the lowest index where the character '?' was found, which is just after the name of the file    \n",
    "    name = url[index_before_name+1:len(url)] # return the name of the file as a string, with the suffix '.nc'\n",
    "    return name\n",
    "\n",
    "# function 'produce_name_list' produce a list of files' name, with the suffix '.nc'\n",
    "# 'produce_name_list' use the function 'extract_name_file' to have the name of a file from its url\n",
    "# the input is a list of url, from which we want to extract the corresponding names of files\n",
    "def produce_name_list(url_list):\n",
    "    name_list=[] # create empty list\n",
    "    for file in url_list:\n",
    "        f_name = extract_name_file(file) # return the name of the file as a string, with the suffix '.nc'\n",
    "        name_list.append(f_name) # add extracted name in the list\n",
    "    return name_list # return the list of names in the url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81fbadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function download_file download the file in the url given as input\n",
    "# the input is an url of a file\n",
    "def download_file(file):\n",
    "    out_path=r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6' \n",
    "    # find the name of the file\n",
    "    f_name = extract_name_file(file) # return the name of the file as a string, with the suffix '.nc' at the end of the name\n",
    "    print('\\nName of the file: '+f_name)\n",
    "    if os.path.join(out_path,f_name):\n",
    "        print('The file '+f_name+' exists')\n",
    "        if test_open_file(os.path.join(out_path,f_name))==[]:\n",
    "        # the file exists and is not corrupted\n",
    "            return print('The file '+f_name+' is not corrupted')# will return None when used in \n",
    "    print('The file '+f_name+' must be requested')\n",
    "    \n",
    "    # this will get the url and retry 20 times in case of requests.exceptions.ConnectionError\n",
    "    # backoff_factor will help to apply delays between attempts to avoid failing again in case of periodic request quota\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=10, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    with session.get(file) as r:\n",
    "        # download data in the servor for datasets\n",
    "        with open(f'//COWI.net/projects/A245000/A248363/CRVA/Datasets/NEX-GDDP-CMIP6/{f_name}', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    \n",
    "    while test_open_file(os.path.join(out_path,f_name))!=[]: # test if download file is corrupted\n",
    "        print('\\nFile '+f_name+' did not open')\n",
    "        \n",
    "        #connect_timeout = 1 # time in seconds, the timeout for establishing a connection to the server. This timeout value can be set by passing the \"timeout\" parameter to the requests.request() function and setting the \"connect\" key to the desired timeout value:\n",
    "        #read_timeout = 1000 # time in seconds, the timeout for waiting for a response from the server after the connection has been established. This timeout value can be set by passing the \"timeout\" parameter to the requests.request() function and setting the \"read\" key to the desired timeout value:\n",
    "\n",
    "        with session.get(file) as r:# return the url were data need to be downloaded\n",
    "        # download data in the servor for datasets\n",
    "            with open(f'//COWI.net/projects/A245000/A248363/CRVA/Datasets/NEX-GDDP-CMIP6/{f_name}', 'wb') as f:\n",
    "                f.write(r.content)\n",
    "    \n",
    "    print('\\nFile '+f_name+' did open')\n",
    "    \n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3faafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 'list_name_corrupted_file' aims to return a list of names, corresponding to the names of the corrupted files\n",
    "# in the name_list given as input\n",
    "def list_name_corrupted_file(name_list,out_path):\n",
    "    ## Hypothesis: some files are corrupted\n",
    "    # check if files are corrupted and count the corrupted ones\n",
    "    invalid_files = [] # create an empty list to register the names of the corrupted files\n",
    "    for name in name_list:\n",
    "        if not name.endswith('.nc'):\n",
    "            name = name + '.nc'\n",
    "        if test_open_file(os.path.join(out_path,name))!=[]:\n",
    "            invalid_files.append(name) # register name of the corrupted files\n",
    "    return invalid_files # return a list of names, with suffix '.nc', of corrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e87291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_open_file(path):\n",
    "    try:\n",
    "        im = Dataset(path)\n",
    "        name = []\n",
    "        im.close()\n",
    "    except (IOError, OSError):\n",
    "        # the files is corrupted\n",
    "        name = extract_name_file(path) # return the name of the file as a string, with the suffix '.nc'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ad974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list urls that should be downloaded again\n",
    "def url_to_download_again(url_list,invalid_files):\n",
    "    url_corrupted_file = []\n",
    "    for url in url_list:\n",
    "        f_name = extract_name_file(url) # return the name of the file as a string\n",
    "        if f_name in invalid_files:\n",
    "            url_corrupted_file.append(url)\n",
    "\n",
    "    dict ={' fileUrl':url_corrupted_file}\n",
    "    df = pd.DataFrame(dict)\n",
    "    path = os.path.join(out_path,'file_to_download_again.csv')\n",
    "    df.to_csv(path)\n",
    "    return url_corrupted_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e598389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## those three function are used to have the information concerning a file\n",
    "## information are in the name of the file, so the name of the file is used to find its related information\n",
    "## information mean variable, time_aggregation, model, scenario, year of the file\n",
    "\n",
    "### this function permit to extract the word before the first character '_' in the input 'name'\n",
    "### the input name is in format str\n",
    "### returning the new_name, without the word found, will permit to re-use the function to find all \n",
    "#     the information concerning the studied file\n",
    "def name_next_boundary(name):\n",
    "    index_before_name=name.find('_') # returns the lowest index where the character '_' was found\n",
    "    word = name[0:index_before_name] # first word in the string 'name', before the first character '_'\n",
    "    new_name = name.replace(word+'_','') # delete the word found from the string 'name'\n",
    "    return word, new_name # return, in string format, the word found (which is an information of the studied file), \n",
    "                    # and the string 'new_name', which is 'name' without the word found\n",
    "\n",
    "# this function permit to extract the year of the studied file\n",
    "# the year is always writen at the end of the name's file\n",
    "# the input name is in format str\n",
    "def find_year(name):\n",
    "    index_before_name=name.rfind('_') # returns the highest index where the character '_' was found\n",
    "    # the last character '_' is just before the year in the string 'name'\n",
    "    # determine if the string 'name' ends with '.nc'\n",
    "    if name.endswith('.nc'):\n",
    "        # 'name' ends with '.nc'\n",
    "        name_end = 3 # the three last character of the string name will be removed to find the year of the studied file\n",
    "    else:\n",
    "        # 'name' does not end with '.nc'\n",
    "        name_end = 0 # no character will be removed at the end of 'name' to find the year of the studied file\n",
    "    year = name[index_before_name+1:len(name)-name_end] # the year is extracted from the name of the file studied\n",
    "    # based on the index_before_name (highest index where the character '_' was found) and the suffix of 'name'\n",
    "    return year # the year in string format is returned\n",
    "\n",
    "# This function use the functions 'name_next_boundary' and 'find_year' to extract the information of the file studied\n",
    "# the input name is in format str, the name of the file from which we want information\n",
    "def data_information(name):\n",
    "    #### use of the function 'name_next_boundary': each time it is used, \n",
    "    # returns an information, and the name of the studied file without this information\n",
    "    (variable, shorten_name) = name_next_boundary(name)\n",
    "    (time_aggregation, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (model, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (scenario, shorten_name) = name_next_boundary(shorten_name)\n",
    "    #### use the function 'find_year' to extract the information 'year' from the string 'shorten_name'\n",
    "    year = find_year(shorten_name)\n",
    "    # the function returns all the information of the studied file\n",
    "    return variable, time_aggregation, model, scenario, year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e80bd",
   "metadata": {},
   "source": [
    "# Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcdb42ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path=r'\\\\COWI.net\\projects\\A245000\\A248363\\CRVA\\Datasets\\NEX-GDDP-CMIP6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa548ce",
   "metadata": {},
   "source": [
    "# Infos for Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c31a5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of CPU/cores\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9829133",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBCORES=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb488f",
   "metadata": {},
   "source": [
    "# Complete list of url with files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09add4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register information from csv file\n",
    "#all_urls = pd.read_csv(r'C:\\Users\\CLMRX\\OneDrive - COWI\\Documents\\GitHub\\CRVA_tool\\outputs\\NEX-GDDP-CMIP6\\gddp-cmip6-thredds-fileserver.csv')\n",
    "csv_path = os.path.join(out_path,'gddp-cmip6-thredds-fileserver.csv')\n",
    "all_urls = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e4f2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make all elements of the csv into a readable list\n",
    "\n",
    "temp_list = all_urls[[' fileUrl']].T# transpose csv\n",
    "temp_list=temp_list.values.tolist()\n",
    "temp_list=temp_list[0]\n",
    "url_list=[s.replace(' ', '') for s in temp_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb674bf",
   "metadata": {},
   "source": [
    "# Interest in temperature files\n",
    "Define list of url and files' names corresponding to temperature files between start day and stop day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9128938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_climate_variable = [url for url in url_list if (variable_of_interest+'_') in url and int(url[len(url)-7:len(url)-3])>=start_year and int(url[len(url)-7:len(url)-3])<=stop_year and 'r1i1p1f1_gn' in url and temporal_resolution in url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d058ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3539"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url_list_climate_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "686f87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create url that will only that zone of interest\n",
    "#url_list_climate_variable_zone_of_interest = [url.replace('thredds2/fileServer','thredds/ncss') + '?var='+variable_of_interest+'&north='+str(max_lat_zone_interest)+'&west='+str(min_lon_zone_interest)+'&east='+str(max_lon_zone_interest)+'&south='+str(min_lat_zone_interest)+'&disableProjSubset=on&horizStride=1&time_start='+url[len(url)-7:len(url)-3]+'-01-01T12%3A00%3A00Z&time_end='+url[len(url)-7:len(url)-3]+'-12-31T12%3A00%3A00Z&timeStride=1&addLatLon=true' for url in url_list_climate_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73aeae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url_list_climate_variable_zone_of_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb433f",
   "metadata": {},
   "source": [
    "# Download file of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165784a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1960.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1960.nc exists\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1961.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1961.nc exists\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1962.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1962.nc exists\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1963.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1963.nc exists\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1964.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1964.nc exists\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1960.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1965.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1965.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1963.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1966.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1966.nc exists\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1962.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1967.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1967.nc exists\n",
      "None\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1961.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1968.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1968.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1964.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1969.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1969.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1965.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1970.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1970.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1969.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1971.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1971.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1967.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1972.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1972.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1968.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1973.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1973.nc exists\n",
      "None\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1966.nc is not corrupted\n",
      "\n",
      "Name of the file: tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1974.nc\n",
      "The file tas_day_ACCESS-CM2_historical_r1i1p1f1_gn_1974.nc exists\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # download files with Threads\n",
    "    results = ThreadPool(NBCORES).imap_unordered(download_file, url_list_climate_variable) \n",
    "    # first input is the function, second input must be an iterable\n",
    "    for r in results: #I don't understand why, without this step, it does not work\n",
    "         print(r)\n",
    "except:\n",
    "    print('Error occured')\n",
    "    \n",
    "name_list_climate_variable = produce_name_list(url_list_climate_variable)\n",
    "name_list_climate_variable_corrupted = list_name_corrupted_file(name_list_climate_variable,out_path)\n",
    "url_corrupted_file=url_to_download_again(url_list_climate_variable,name_list_climate_variable_corrupted)\n",
    "len(name_list_climate_variable_corrupted)\n",
    "\n",
    "while name_list_climate_variable_corrupted!=[]:\n",
    "    # download files with Threads\n",
    "    try:\n",
    "        results = ThreadPool(NBCORES).imap_unordered(download_file, url_corrupted_file) \n",
    "        # first input is the function, second input must be an iterable\n",
    "        for r in results: #I don't understand why, without this step, it does not work\n",
    "             print(r)\n",
    "    except:\n",
    "        continue\n",
    "    name_list_climate_variable_corrupted = list_name_corrupted_file(name_list_climate_variable,out_path)\n",
    "    url_corrupted_file=url_to_download_again(url_list_climate_variable,name_list_climate_variable_corrupted)\n",
    "    len(name_list_climate_variable_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a576a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list_climate_variable = produce_name_list(url_list_climate_variable)\n",
    "name_list_climate_variable_corrupted = list_name_corrupted_file(name_list_climate_variable,out_path)\n",
    "url_corrupted_file=url_to_download_again(url_list_climate_variable,name_list_climate_variable_corrupted)\n",
    "len(name_list_climate_variable_corrupted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fb71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08248d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
