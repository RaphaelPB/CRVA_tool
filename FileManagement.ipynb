{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64945eb",
   "metadata": {},
   "source": [
    "This file aims to regroup all function involved in file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import time # to measure elasped time\n",
    "from netCDF4 import Dataset\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f985b0",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7bc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gros bug sur cette function\n",
    "\n",
    "def download_extract(path_file,path_for_file):\n",
    "    #if not os.path.isdir(path_for_file): # path_for_file does not exists, need to ensure that is is created\n",
    "    #    os.makedirs(path_for_file) # to ensure the creation of the path\n",
    "    # unzip the downloaded file\n",
    "    from zipfile import ZipFile\n",
    "  \n",
    "    # loading the temp.zip and creating a zip object\n",
    "    os.chdir(path_file)\n",
    "    with ZipFile(path_for_file, 'r') as zObject:\n",
    "      \n",
    "    # Extracting all the members of the zip \n",
    "    # into a specific location.\n",
    "        print(zObject)\n",
    "        zObject.extractall()\n",
    "    \n",
    "    print('\\n ----------------------------- The downloaded file is extracted in the indicated file -----------------------------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c51bfe",
   "metadata": {},
   "source": [
    "# Manage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7bda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions aims to check if the path is too long, and if yes to deal with it\n",
    "# this function was created because a bug exist when using python on windows. When the path is too long (more than 250 characters), \n",
    "# '\\\\\\\\?\\\\' should be added before the path in order for Windows to understand it \n",
    "# (source: https://stackoverflow.com/questions/29557760/long-paths-in-python-on-windows)\n",
    "\n",
    "# the input is a path in a string format\n",
    "# the output is the path in a string format\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        # the path has more than 250 characters\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        # the path has less than 250 characters, the path is not too long\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53536952",
   "metadata": {},
   "source": [
    "# Manage with url of files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4198c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the name of the file from its url\n",
    "# the input is an url\n",
    "def extract_name_file(url):\n",
    "    index_before_name=url.rfind('/') # returns the highest index where the last character '/' was found, which is just before the name of the file    \n",
    "    name = url[index_before_name+1:len(url)] # return the name of the file as a string, with the suffix '.nc'\n",
    "    return name\n",
    "\n",
    "# function 'produce_name_list' produce a list of files' name, with the suffix '.nc'\n",
    "# 'produce_name_list' use the function 'extract_name_file' to have the name of a file from its url\n",
    "# the input is a list of url, from which we want to extract the corresponding names of files\n",
    "def produce_name_list(url_list):\n",
    "    name_list=[] # create empty list\n",
    "    for file in url_list:\n",
    "        f_name = extract_name_file(file) # return the name of the file as a string, with the suffix '.nc'\n",
    "        name_list.append(f_name) # add extracted name in the list\n",
    "    return name_list # return the list of names in the url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8535728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## those three function are used to have the information concerning a file\n",
    "## information are in the name of the file, so the name of the file is used to find its related information\n",
    "## information mean variable, time_aggregation, model, scenario, year of the file\n",
    "\n",
    "### this function permit to extract the word before the first character '_' in the input 'name'\n",
    "### the input name is in format str\n",
    "### returning the new_name, without the word found, will permit to re-use the function to find all \n",
    "#     the information concerning the studied file\n",
    "def name_next_boundary(name):\n",
    "    index_before_name=name.find('_') # returns the lowest index where the character '_' was found\n",
    "    word = name[0:index_before_name] # first word in the string 'name', before the first character '_'\n",
    "    new_name = name.replace(word+'_','') # delete the word found from the string 'name'\n",
    "    return word, new_name # return, in string format, the word found (which is an information of the studied file), \n",
    "                    # and the string 'new_name', which is 'name' without the word found\n",
    "\n",
    "# this function permit to extract the year of the studied file\n",
    "# the year is always writen at the end of the name's file\n",
    "# the input name is in format str\n",
    "def find_year(name):\n",
    "    index_before_name=name.rfind('_') # returns the highest index where the character '_' was found\n",
    "    # the last character '_' is just before the year in the string 'name'\n",
    "    # determine if the string 'name' ends with '.nc'\n",
    "    if name.endswith('.nc'):\n",
    "        # 'name' ends with '.nc'\n",
    "        name_end = 3 # the three last character of the string name will be removed to find the year of the studied file\n",
    "    else:\n",
    "        # 'name' does not end with '.nc'\n",
    "        name_end = 0 # no character will be removed at the end of 'name' to find the year of the studied file\n",
    "    year = name[index_before_name+1:len(name)-name_end] # the year is extracted from the name of the file studied\n",
    "    # based on the index_before_name (highest index where the character '_' was found) and the suffix of 'name'\n",
    "    return year # the year in string format is returned\n",
    "\n",
    "# This function use the functions 'name_next_boundary' and 'find_year' to extract the information of the file studied\n",
    "# the input name is in format str, the name of the file from which we want information\n",
    "def data_information(name):\n",
    "    #### use of the function 'name_next_boundary': each time it is used, \n",
    "    # returns an information, and the name of the studied file without this information\n",
    "    (variable, shorten_name) = name_next_boundary(name)\n",
    "    (time_aggregation, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (model, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (scenario, shorten_name) = name_next_boundary(shorten_name)\n",
    "    #### use the function 'find_year' to extract the information 'year' from the string 'shorten_name'\n",
    "    year = find_year(shorten_name)\n",
    "    # the function returns all the information of the studied file\n",
    "    return variable, time_aggregation, model, scenario, year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1843186",
   "metadata": {},
   "source": [
    "# Reading of nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b3ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to read from a netCDF file the information of interest\n",
    "# the input is a ....\n",
    "# the ouputs are vector arrays;\n",
    "#     first one with the latitudes of the nc file\n",
    "#     second one with the longitudes of the nc file\n",
    "#     third one with the time of the nc file\n",
    "#     fourth one with the variable of interest (for example precipitation) of the nc file\n",
    "\n",
    "def read_nc_file(Open_path):\n",
    "    start = timer()\n",
    "    # use the function find_column_name to find the name of the variable of interest\n",
    "    start2 = timer()\n",
    "    name_variable = find_column_name(Open_path) # name_variable is the name of the variable of interest in a string format\n",
    "    end2 = timer()\n",
    "    if (end2 - start2) > 1.0 :\n",
    "        print('Time to execute the function find_column_name: ' + str(end2 - start2)+' seconds')\n",
    "        print('\\n')\n",
    "    # use the function 'get_data_nc' to have the data from the nc file\n",
    "    # the function 'get_data_nc' return an array containing the values of interest of the variable indicated as second input\n",
    "    lat=get_data_nc(Open_path,'lat')\n",
    "    lon=get_data_nc(Open_path,'lon')\n",
    "    time=get_data_nc(Open_path,'time')\n",
    "    #variable=return_NaN(path,name_variable) # this function does not work for the moment\n",
    "    variable=get_data_nc(Open_path,name_variable)\n",
    "    end = timer()\n",
    "    if (end - start) > 1.0 :\n",
    "        print('Time to execute the function read_nc_file: ' + str(end - start)+' seconds')\n",
    "        print('\\n')\n",
    "    return lat, lon, time, variable # return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e6537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function 'get_data_nc' aims to acces the masked data of the nc files\n",
    "def get_data_nc(Open_path,name_variable):\n",
    "    start = timer()\n",
    "    variable = np.ma.getdata(Open_path.variables[name_variable]).data\n",
    "    end = timer()\n",
    "    if (end - start) > 1.0 :\n",
    "        print('\\n')\n",
    "        print('Time to execute the function get_data_nc for the variable '+ name_variable +': ' + str(end - start)+' seconds')\n",
    "        print('\\n')\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38dd9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return column name in the netCDF file\n",
    "# all netCDF file form copernicus have this format for their variables names\n",
    "# ['time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds', Name of climate variable of interest]\n",
    "# take of 'time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds'\n",
    "def find_column_name(Open_path):\n",
    "    # make a list with every variables of the netCDF file of interest\n",
    "    climate_variable_variables=list(Open_path.variables)\n",
    "    # variables that are not the column name of interest \n",
    "    elements_not_climate_var =['time', 'time_bnds', 'bnds','lat', 'lat_bnds', 'lon', 'lon_bnds','time_bounds','bounds','lat_bounds','lon_bounds','height']\n",
    "    for str in elements_not_climate_var:\n",
    "        if str in climate_variable_variables:\n",
    "            climate_variable_variables.remove(str)\n",
    "    return climate_variable_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b31939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction ne fonctionne pas\n",
    "\n",
    "def return_NaN(Open_path,name_variable):\n",
    "    variable = get_data_nc(Open_path,name_variable)\n",
    "    value_NaN = Open_path.variables[name_variable]._FillValue\n",
    "    import math\n",
    "    #variable[variable==value_NaN] = math.nan#float('NaN')\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd42d46",
   "metadata": {},
   "source": [
    "## Reading of nc file: convert vector time from unix to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1caa2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to convert the vector of the time vector from Unix time to the format '%Y-%m-%d'\n",
    "# the function us the 2 following functions 'extract_start_date' and 'time_conversion'\n",
    "def time_vector_conversion(Open_path,resolution):\n",
    "    from datetime import date # package to work with date and time\n",
    "    (year,month,day) = extract_start_date(Open_path) # next function, returning the year, month and day of the start date\n",
    "    start = date(year,month,day) # the function date, with some number in the format int as input\n",
    "    # the function date return the date in format 'YYYY-MM-DD'\n",
    "    time=get_data_nc(Open_path,'time') # get data from the nc file\n",
    "    time_converted = [] # create an empty list, to register the converted time vector\n",
    "    # for loop to convert the date from Unix to the format '%Y-%m-%d'\n",
    "    for day in time:\n",
    "        # add each converted time in the list 'time_converted'\n",
    "        time_converted.append(time_conversion(day,start,resolution)) # convert time with the function 'time_conversion'\n",
    "        # the function the function 'time_conversion'\n",
    "    return time_converted # return the list with time converted in format '%Y-%m-%d'\n",
    "\n",
    "# this function aims to extract the year, month and day of the start date\n",
    "# the input is the path leading to the file of interest\n",
    "def extract_start_date(Open_path):\n",
    "    # start date is after the str 'days since ' in units in the path indicated as input of the function\n",
    "    start_date=Open_path.variables['time'].units.replace('days since ','') # the start_date in string format\n",
    "    # next step is to extract and convert in int format the information in te str start_date\n",
    "    # the year is always the 4 first elements of the str start_date\n",
    "    year = int(start_date[0:4])\n",
    "    # the month is always between the first '-' and the second '-' the str start_date\n",
    "    month = int(start_date[start_date.find('-')+1:start_date.rfind('-')])\n",
    "    # the day is always after the second '-' and before the end the str start_date\n",
    "    day = int(start_date[start_date.rfind('-')+1:start_date.rfind('-')+3])\n",
    "    return year,month,day # return year, mont and day in int format\n",
    "\n",
    "# this function convert time from unix in str format\n",
    "# input : \n",
    "##### days is the number representing a time in Unix\n",
    "##### start is the date in format 'YYYY-MM-DD'\n",
    "##### resolution : in str form. can be 'monthly' or 'daily'\n",
    "def time_conversion(days,start,resolution):\n",
    "    from datetime import timedelta # import the function timedelta\n",
    "    if not days.dtype == int:\n",
    "        # the days is not in int format\n",
    "        days = int(days)\n",
    "    # use the function timedelta, with an int as imput\n",
    "    delta = timedelta(days) # Create a time delta object from the number of days\n",
    "    offset = start + delta # add the delta to the start date\n",
    "    # depending on the resolution, converted the offset in str format with strftime function\n",
    "    if resolution == 'monthly':\n",
    "        offset = offset.strftime('%Y-%m')\n",
    "    if resolution == 'daily':\n",
    "        offset = offset.strftime('%Y-%m-%d')\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4d66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xr_array(data,coordonates):\n",
    "    data_structure = xr.DataArray(data, coords=[times, locs], dims=[\"time\", \"space\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8477bc0",
   "metadata": {},
   "source": [
    "# Register information from nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7425d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the register_data_in_dataframe function aims to test if data with the specific parameters exist in the folder of concern\n",
    "# As inputs :\n",
    "#      the list of urls of the files of interest. The name of the file will be extracted from them\n",
    "#      temporal_resolution: the temporal resolution of the climate variable in question in string format\n",
    "#      year_str: a vector containing the year of the period of interest in a string format\n",
    "#      scenarios: a list of the scenorios of interest in string format\n",
    "#      models: a list of the models of interest in string format\n",
    "#      out_path: the out_path in a string format\n",
    "#      name_variable: the name of the variable of interest (example: 'pr' for precipitation)\n",
    "#      name_project: the list of names of the project of interest\n",
    "#      index_closest_lat: array containing an index for each project, \n",
    "#                           corresponding to the index of the value in latitude vector which is the closest to \n",
    "#                           the project latitude\n",
    "#      index_closest_lat: array containing an index for each project, \n",
    "#                           corresponding to the index of the value in longitude vector which is the closest to \n",
    "#                           the project longitude\n",
    "#      closest_value_lat: array containing a value for each project, corresponding to the value in the \n",
    "#                           latitude vector which is the closest to the project's latitude\n",
    "#      closest_value_lon: array containing a value for each project, corresponding to the value in the \n",
    "#                           longitude vector which is the closest to the project's longitude\n",
    "#      df : empty dataframe to fill\n",
    "\n",
    "# Outputs are:\n",
    "#      df: the filled dataframe with the values of interest\n",
    "#      path_file_not_found: the list of files that were not found with the parameters asked\n",
    "#      ds_did_not_open: the list of files that could not be read\n",
    "\n",
    "def register_data_in_dataframe(name_list,temporal_resolution,year_str,scenarios,models,out_path, name_variable, name_project,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon,df):    \n",
    "    path_file_not_found = [] # create empty list to register names of files that were not found with the corresponding parameters\n",
    "    ds_did_not_open = [] # create empty list to register names of files that couldn't be opened\n",
    "    for year in year_str:\n",
    "        for SSP in scenarios:\n",
    "            for model_simulation in models:\n",
    "                # for each year, each scenarios and each models, test if there is a corresponding file existing\n",
    "                # with function 'find_path_file'\n",
    "                climate_variable_path = find_path_file(out_path,name_list,name_variable,temporal_resolution,model_simulation,SSP,year,'r1i1p1f1_gn')\n",
    "                if climate_variable_path!= []:\n",
    "                    # a file with the corresponding parameters were found\n",
    "                    ds =  xr.open_dataset(climate_variable_path) # open the file corresponding to the parameters\n",
    "                    time = ds.indexes['time'].strftime('%d-%m-%Y').values # register the time in the file\n",
    "                    for i in np.arange(0,len(name_project)):\n",
    "                        print('For the year '+year+' and project '+name_project[i]+', test with scenario '+SSP+', with model '+model_simulation)\n",
    "                        try: # to register information from the dataset ds in the dataframe df\n",
    "                            # for each year, scenarios, models and each project, the values of the opened dataset ds\n",
    "                            # are registered in the empty dataframe df, to a specific place corresponding to the parameters of the loop\n",
    "                            df.loc[(name_project[i],SSP,model_simulation,time,closest_value_lat[i]),('Longitude',closest_value_lon[i])] = ds.pr.isel(lat=index_closest_lat[i],lon=index_closest_lon[i]).values\n",
    "                        except: # the dataset ds can not be read\n",
    "                            # add information of the dataset that can't be read in the empty list ds_did_not_open\n",
    "                            ds_did_not_open.append(climate_variable_path+'_'+'project_'+name_project[i])\n",
    "                            continue # try with next project\n",
    "                    ds.close() # the opened dataset is closed to spare memory\n",
    "                else:\n",
    "                    # NO file with the corresponding parameters were found\n",
    "                    # add information of the missing file in the empty list path_file_not_found\n",
    "                    path_file_not_found.append(name_variable+'_'+temporal_resolution+'_'+model_simulation+'_'+SSP+'_'+year+'_'+'r1i1p1f1_gn')\n",
    "                    continue # try another file\n",
    "    return df,path_file_not_found,ds_did_not_open\n",
    "\n",
    "# the function df_to_csv aims to return the filled dataframe in a csv format\n",
    "# Inputs are:\n",
    "#       df: the dataframe that should be register in a csv file\n",
    "#      path_for_csv: this is the path where the csv file should be registered, in a string format\n",
    "#      title_file: this is the name of the csv file to be created in a string format\n",
    "#                  CAREFUL --> title_file MUST have the extension of the file in the string (.csv for example)\n",
    "# Output is:\n",
    "#      in the case where the dataframe is not empty, the ouput is the full path to the created csv file\n",
    "#      in the case where the dataframe is empty, the output is an empty list\n",
    "def df_to_csv(df,path_for_csv,title_file):\n",
    "    # test if dataframe is empty, if values exist for this period\n",
    "    if not df.empty: \n",
    "        # if dataframe is not empty, value were registered, the first part is run : \n",
    "        # a path to register the csv file is created, .....\n",
    "        if not os.path.isdir(path_for_csv):\n",
    "            # the path to the file does not exist\n",
    "            os.makedirs(path_for_csv) # to ensure creation of the folder\n",
    "            # creation of the path for the csv file, in a string format\n",
    "        full_name = os.path.join(path_for_csv,title_file)\n",
    "        # ..... and the dataframe is registered in a csv file\n",
    "        df.to_csv(full_name) # register dataframe in csv file\n",
    "        print('Path for csv file is: ' + full_name)\n",
    "        return full_name # return the full path that leads to the created csv file\n",
    "    else: # if the dataframe is empty, no value were found, there is no value to register or to return\n",
    "        print('The dataframe is empty')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abad33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function is used in register_data. The function aims to select in a vector, elements between the values min_vector \n",
    "# and max_vector\n",
    "# in the register_data function, the function 'find_index_project' is used to find the index of the latitudes and longitude \n",
    "# vectors elements which are between min_vector and max_vector values. this allows to select the latitudes and longitudes around\n",
    "# the projects\n",
    "# the input of the function are:\n",
    "# a vector; in register_data, it is the latitude or the longitude vector of the file studied\n",
    "# the minimal value of the interval of interest\n",
    "# the maximal value of the interval of interest\n",
    "# the output is;\n",
    "# the indexes of the vector elements, which values are between min_vector and max_vector\n",
    "def find_index_project(vector,min_vector,max_vector):\n",
    "    # values of vector between min_vector and max_vector\n",
    "    vector_project =[element for element in vector if element > min_vector and element < max_vector]\n",
    "    index_item =[] # prepare empty list to register the indexes of the values of vector whice are between min_vector\n",
    "    # and max_vector\n",
    "    # for loop, to register the indexes of the values of vector whice are between min_vector and max_vector\n",
    "    for item in vector_project:\n",
    "        # values in vector are compared to vector_project values \n",
    "        index_item.append(np.where(vector == item)[0][0])\n",
    "        # the function np.where return the indexes of vector, where the values of vector are equal to item\n",
    "    return index_item # a vector containing the indexes of the vectors elements, which are between min_vector and max_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a3fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used in 'create_dataframe'. The function aims to return the path of the file of interest\n",
    "# The function looks into a list of name which name in the list has every input \n",
    "# The inputs are:\n",
    "#    out_path: a general file path where the files are registered, \n",
    "#    name_file_list: a list of files' names\n",
    "#    variable: the name of the variable of interest\n",
    "#    model: the model of interest (example: ACCESS-CM2)\n",
    "#    scenario: the scenario of interest (example:ssp245)\n",
    "#    year: the year of interest\n",
    "#    ensemble: the ensemble of interest (example: r1i1p1f1_gn)\n",
    "# the output is:\n",
    "#    the path of the file corresponding to all the parameters indicated in input\n",
    "\n",
    "def find_path_file(out_path,name_file_list,variable,temporal_resolution,model,scenario,year,ensemble):\n",
    "    # look into the list of names if find a name with every parameter indicated in inputs\n",
    "    name_found = [name for name in name_file_list if scenario in name and model in name and year in name and ensemble in name and temporal_resolution in name]\n",
    "    print('The name of the file is ' + name_found[0])\n",
    "    if name_found == []:\n",
    "        # no name with all the parameters indicated as inputs was found\n",
    "        return name_found # return an empty element instead of a path, the function does not run the following lines\n",
    "    # the name was found, so prepare the path of the file of interest\n",
    "    path = os.path.join(out_path,name_found[0])\n",
    "    return path # return the path of the file of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc495cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to select the closest point to the geographical point of the project\n",
    "# the function takes as input \n",
    "#     location_project, which is a numpy.float64\n",
    "#     vector, which is a numpy.ndarray\n",
    "# the function returns\n",
    "#     closest_value[0], a numpy.float64\n",
    "\n",
    "def closest_lat_lon_to_proj(location_project,vector):\n",
    "    # the function any() returns a boolean value. Here, the function test if there are elements in the array \n",
    "    # containing the difference between the vector and the location_project, equal to the minimum of the absolute \n",
    "    # value of the difference between the vector and the location_project\n",
    "    if any(np.where((vector - location_project) == min(abs(vector - location_project)))[0]):\n",
    "        # the function any() returned True\n",
    "        # there is an element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    else:\n",
    "        # the function any() returned False\n",
    "        # there is NO element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == -min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == -min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    return index_closest, closest_value \n",
    "    # the function returns\n",
    "    #     first, the value of the index of the element of vector, that is the closest to location_project    \n",
    "    #     second, the array containing the element of vector, that is the closest to location_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1e8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to create the empty dataframe that will be filled\n",
    "\n",
    "def create_empty_dataframe(name_project,scenarios,models,time,closest_value_lat,closest_value_lon):\n",
    "    df = pd.DataFrame()\n",
    "    for i in np.arange(0,len(name_project)):\n",
    "        midx = pd.MultiIndex.from_product([(name_project[i],),scenarios, models, time, (closest_value_lat[i],)],names=['Name project','Experiment', 'Model', 'Date', 'Latitude'])\n",
    "        cols = pd.MultiIndex.from_product([('Longitude',),(closest_value_lon[i],)])\n",
    "        Variable_dataframe = pd.DataFrame(data = [], \n",
    "                                    index = midx,\n",
    "                                    columns = cols)\n",
    "        df = pd.concat([df,Variable_dataframe])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b48736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions aims to regroup all the scenarios, models, time_aggregation and variables in vectors\n",
    "# the function use the function 'data_information'\n",
    "\n",
    "def information_files_in_vectors(name_list):\n",
    "    variables= []\n",
    "    time_aggregations= []\n",
    "    models= []\n",
    "    scenarios= []\n",
    "    for file_name in name_list:\n",
    "        (variable, time_aggregation, model, scenario, year) = data_information(file_name) \n",
    "        # use function data_information to find information concerning the file_name\n",
    "        if variable not in variables:\n",
    "            variables.append(variable)\n",
    "        if time_aggregation not in time_aggregations:\n",
    "            time_aggregations.append(time_aggregation)\n",
    "        if model not in models:\n",
    "            models.append(model)\n",
    "        if scenario not in scenarios:\n",
    "            scenarios.append(scenario)\n",
    "    return variables, time_aggregations,models,scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20875032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions aims to return the closest latitudes and longitudes to the projects, and the respectives index \n",
    "#  in the lat and lon vectors of the file\n",
    "def _lat_lon(path,lat_projects,lon_projects):\n",
    "    ds =  xr.open_dataset(path) \n",
    "    # ds.indexes['time'] gives back CFTimeIndex format, with hours. The strftime('%d-%m-%Y') permits to have time \n",
    "    # as an index, with format '%d-%m-%Y'. The .values permits to have an array\n",
    "    lat  = ds.lat.values\n",
    "    lon  = ds.lon.values\n",
    "    ds.close() # to spare memory\n",
    "    # preallocate space for the future vectors\n",
    "    index_closest_lat = []\n",
    "    index_closest_lon = []\n",
    "    closest_value_lat = []\n",
    "    closest_value_lon = []\n",
    "    for j in np.arange(0,len(lat_projects)):\n",
    "        (A,B)=closest_lat_lon_to_proj(lat_projects[j],lat)\n",
    "        index_closest_lat.append(A[0])\n",
    "        closest_value_lat.append(B[0])\n",
    "        (C,D)=closest_lat_lon_to_proj(lon_projects[j],lon)\n",
    "        index_closest_lon.append(C[0])\n",
    "        closest_value_lon.append(D[0])\n",
    "    return index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38265c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0e1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053442fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc62b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823bc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ef0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350dda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49be44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f8cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69214d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81226166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
