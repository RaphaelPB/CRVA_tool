{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64945eb",
   "metadata": {},
   "source": [
    "This file aims to regroup all function involved in file management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27ad997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import time # to measure elasped time\n",
    "from netCDF4 import Dataset\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f985b0",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gros bug sur cette function\n",
    "\n",
    "def download_extract(path_file,path_for_file):\n",
    "    #if not os.path.isdir(path_for_file): # path_for_file does not exists, need to ensure that is is created\n",
    "    #    os.makedirs(path_for_file) # to ensure the creation of the path\n",
    "    # unzip the downloaded file\n",
    "    from zipfile import ZipFile\n",
    "  \n",
    "    # loading the temp.zip and creating a zip object\n",
    "    os.chdir(path_file)\n",
    "    with ZipFile(path_for_file, 'r') as zObject:\n",
    "      \n",
    "    # Extracting all the members of the zip \n",
    "    # into a specific location.\n",
    "        print(zObject)\n",
    "        zObject.extractall()\n",
    "    \n",
    "    print('\\n ----------------------------- The downloaded file is extracted in the indicated file -----------------------------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c51bfe",
   "metadata": {},
   "source": [
    "# Manage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c7bda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions aims to check if the path is too long, and if yes to deal with it\n",
    "# this function was created because a bug exist when using python on windows. When the path is too long (more than 250 characters), \n",
    "# '\\\\\\\\?\\\\' should be added before the path in order for Windows to understand it \n",
    "# (source: https://stackoverflow.com/questions/29557760/long-paths-in-python-on-windows)\n",
    "\n",
    "# the input is a path in a string format\n",
    "# the output is the path in a string format\n",
    "def path_length(str1):\n",
    "    if len(str1)>250:\n",
    "        # the path has more than 250 characters\n",
    "        path = os.path.abspath(str1) # normalize path\n",
    "        if path.startswith(u\"\\\\\\\\\"):\n",
    "            path=u\"\\\\\\\\?\\\\UNC\\\\\"+path[2:]\n",
    "        else:\n",
    "            path=u\"\\\\\\\\?\\\\\"+path\n",
    "        return path\n",
    "    else:\n",
    "        # the path has less than 250 characters, the path is not too long\n",
    "        return str1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53536952",
   "metadata": {},
   "source": [
    "# Manage with url of files to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4198c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the name of the file from its url\n",
    "# the input is an url\n",
    "def extract_name_file(url):\n",
    "    index_before_name=url.rfind('/') # returns the highest index where the last character '/' was found, which is just before the name of the file    \n",
    "    name = url[index_before_name+1:len(url)] # return the name of the file as a string, with the suffix '.nc'\n",
    "    return name\n",
    "\n",
    "# function 'produce_name_list' produce a list of files' name, with the suffix '.nc'\n",
    "# 'produce_name_list' use the function 'extract_name_file' to have the name of a file from its url\n",
    "# the input is a list of url, from which we want to extract the corresponding names of files\n",
    "def produce_name_list(url_list):\n",
    "    name_list=[] # create empty list\n",
    "    for file in url_list:\n",
    "        f_name = extract_name_file(file) # return the name of the file as a string, with the suffix '.nc'\n",
    "        name_list.append(f_name) # add extracted name in the list\n",
    "    return name_list # return the list of names in the url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8535728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## those three function are used to have the information concerning a file\n",
    "## information are in the name of the file, so the name of the file is used to find its related information\n",
    "## information mean variable, time_aggregation, model, scenario, year of the file\n",
    "\n",
    "### this function permit to extract the word before the first character '_' in the input 'name'\n",
    "### the input name is in format str\n",
    "### returning the new_name, without the word found, will permit to re-use the function to find all \n",
    "#     the information concerning the studied file\n",
    "def name_next_boundary(name):\n",
    "    index_before_name=name.find('_') # returns the lowest index where the character '_' was found\n",
    "    word = name[0:index_before_name] # first word in the string 'name', before the first character '_'\n",
    "    new_name = name.replace(word+'_','') # delete the word found from the string 'name'\n",
    "    return word, new_name # return, in string format, the word found (which is an information of the studied file), \n",
    "                    # and the string 'new_name', which is 'name' without the word found\n",
    "\n",
    "# this function permit to extract the year of the studied file\n",
    "# the year is always writen at the end of the name's file\n",
    "# the input name is in format str\n",
    "def find_year(name):\n",
    "    index_before_name=name.rfind('_') # returns the highest index where the character '_' was found\n",
    "    # the last character '_' is just before the year in the string 'name'\n",
    "    # determine if the string 'name' ends with '.nc'\n",
    "    if name.endswith('.nc'):\n",
    "        # 'name' ends with '.nc'\n",
    "        name_end = 3 # the three last character of the string name will be removed to find the year of the studied file\n",
    "    else:\n",
    "        # 'name' does not end with '.nc'\n",
    "        name_end = 0 # no character will be removed at the end of 'name' to find the year of the studied file\n",
    "    year = name[index_before_name+1:len(name)-name_end] # the year is extracted from the name of the file studied\n",
    "    # based on the index_before_name (highest index where the character '_' was found) and the suffix of 'name'\n",
    "    return year # the year in string format is returned\n",
    "\n",
    "# This function use the functions 'name_next_boundary' and 'find_year' to extract the information of the file studied\n",
    "# the input name is in format str, the name of the file from which we want information\n",
    "def data_information(name):\n",
    "    #### use of the function 'name_next_boundary': each time it is used, \n",
    "    # returns an information, and the name of the studied file without this information\n",
    "    (variable, shorten_name) = name_next_boundary(name)\n",
    "    (time_aggregation, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (model, shorten_name) = name_next_boundary(shorten_name)\n",
    "    (scenario, shorten_name) = name_next_boundary(shorten_name)\n",
    "    #### use the function 'find_year' to extract the information 'year' from the string 'shorten_name'\n",
    "    year = find_year(shorten_name)\n",
    "    # the function returns all the information of the studied file\n",
    "    return variable, time_aggregation, model, scenario, year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1843186",
   "metadata": {},
   "source": [
    "# Reading of nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b3ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to read from a netCDF file the information of interest\n",
    "# the input is a ....\n",
    "# the ouputs are vector arrays;\n",
    "#     first one with the latitudes of the nc file\n",
    "#     second one with the longitudes of the nc file\n",
    "#     third one with the time of the nc file\n",
    "#     fourth one with the variable of interest (for example precipitation) of the nc file\n",
    "\n",
    "def read_nc_file(Open_path):\n",
    "    start = timer()\n",
    "    # use the function find_column_name to find the name of the variable of interest\n",
    "    start2 = timer()\n",
    "    name_variable = find_column_name(Open_path) # name_variable is the name of the variable of interest in a string format\n",
    "    end2 = timer()\n",
    "    if (end2 - start2) > 1.0 :\n",
    "        print('Time to execute the function find_column_name: ' + str(end2 - start2)+' seconds')\n",
    "        print('\\n')\n",
    "    # use the function 'get_data_nc' to have the data from the nc file\n",
    "    # the function 'get_data_nc' return an array containing the values of interest of the variable indicated as second input\n",
    "    lat=get_data_nc(Open_path,'lat')\n",
    "    lon=get_data_nc(Open_path,'lon')\n",
    "    time=get_data_nc(Open_path,'time')\n",
    "    #variable=return_NaN(path,name_variable) # this function does not work for the moment\n",
    "    variable=get_data_nc(Open_path,name_variable)\n",
    "    end = timer()\n",
    "    if (end - start) > 1.0 :\n",
    "        print('Time to execute the function read_nc_file: ' + str(end - start)+' seconds')\n",
    "        print('\\n')\n",
    "    return lat, lon, time, variable # return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e6537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function 'get_data_nc' aims to acces the masked data of the nc files\n",
    "def get_data_nc(Open_path,name_variable):\n",
    "    start = timer()\n",
    "    variable = np.ma.getdata(Open_path.variables[name_variable]).data\n",
    "    end = timer()\n",
    "    if (end - start) > 1.0 :\n",
    "        print('\\n')\n",
    "        print('Time to execute the function get_data_nc for the variable '+ name_variable +': ' + str(end - start)+' seconds')\n",
    "        print('\\n')\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38dd9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return column name in the netCDF file\n",
    "# all netCDF file form copernicus have this format for their variables names\n",
    "# ['time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds', Name of climate variable of interest]\n",
    "# take of 'time', 'time_bnds', 'lat', 'lat_bnds', 'lon', 'lon_bnds'\n",
    "def find_column_name(Open_path):\n",
    "    # make a list with every variables of the netCDF file of interest\n",
    "    climate_variable_variables=list(Open_path.variables)\n",
    "    # variables that are not the column name of interest \n",
    "    elements_not_climate_var =['time', 'time_bnds', 'bnds','lat', 'lat_bnds', 'lon', 'lon_bnds','time_bounds','bounds','lat_bounds','lon_bounds','height']\n",
    "    for str in elements_not_climate_var:\n",
    "        if str in climate_variable_variables:\n",
    "            climate_variable_variables.remove(str)\n",
    "    return climate_variable_variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b31939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction ne fonctionne pas\n",
    "\n",
    "def return_NaN(Open_path,name_variable):\n",
    "    variable = get_data_nc(Open_path,name_variable)\n",
    "    value_NaN = Open_path.variables[name_variable]._FillValue\n",
    "    import math\n",
    "    #variable[variable==value_NaN] = math.nan#float('NaN')\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd42d46",
   "metadata": {},
   "source": [
    "## Reading of nc file: convert vector time from unix to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1caa2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to convert the vector of the time vector from Unix time to the format '%Y-%m-%d'\n",
    "# the function us the 2 following functions 'extract_start_date' and 'time_conversion'\n",
    "def time_vector_conversion(Open_path,resolution):\n",
    "    from datetime import date # package to work with date and time\n",
    "    (year,month,day) = extract_start_date(Open_path) # next function, returning the year, month and day of the start date\n",
    "    start = date(year,month,day) # the function date, with some number in the format int as input\n",
    "    # the function date return the date in format 'YYYY-MM-DD'\n",
    "    time=get_data_nc(Open_path,'time') # get data from the nc file\n",
    "    time_converted = [] # create an empty list, to register the converted time vector\n",
    "    # for loop to convert the date from Unix to the format '%Y-%m-%d'\n",
    "    for day in time:\n",
    "        # add each converted time in the list 'time_converted'\n",
    "        time_converted.append(time_conversion(day,start,resolution)) # convert time with the function 'time_conversion'\n",
    "        # the function the function 'time_conversion'\n",
    "    return time_converted # return the list with time converted in format '%Y-%m-%d'\n",
    "\n",
    "# this function aims to extract the year, month and day of the start date\n",
    "# the input is the path leading to the file of interest\n",
    "def extract_start_date(Open_path):\n",
    "    # start date is after the str 'days since ' in units in the path indicated as input of the function\n",
    "    start_date=Open_path.variables['time'].units.replace('days since ','') # the start_date in string format\n",
    "    # next step is to extract and convert in int format the information in te str start_date\n",
    "    # the year is always the 4 first elements of the str start_date\n",
    "    year = int(start_date[0:4])\n",
    "    # the month is always between the first '-' and the second '-' the str start_date\n",
    "    month = int(start_date[start_date.find('-')+1:start_date.rfind('-')])\n",
    "    # the day is always after the second '-' and before the end the str start_date\n",
    "    day = int(start_date[start_date.rfind('-')+1:start_date.rfind('-')+3])\n",
    "    return year,month,day # return year, mont and day in int format\n",
    "\n",
    "# this function convert time from unix in str format\n",
    "# input : \n",
    "##### days is the number representing a time in Unix\n",
    "##### start is the date in format 'YYYY-MM-DD'\n",
    "##### resolution : in str form. can be 'monthly' or 'daily'\n",
    "def time_conversion(days,start,resolution):\n",
    "    from datetime import timedelta # import the function timedelta\n",
    "    if not days.dtype == int:\n",
    "        # the days is not in int format\n",
    "        days = int(days)\n",
    "    # use the function timedelta, with an int as imput\n",
    "    delta = timedelta(days) # Create a time delta object from the number of days\n",
    "    offset = start + delta # add the delta to the start date\n",
    "    # depending on the resolution, converted the offset in str format with strftime function\n",
    "    if resolution == 'monthly':\n",
    "        offset = offset.strftime('%Y-%m')\n",
    "    if resolution == 'daily':\n",
    "        offset = offset.strftime('%Y-%m-%d')\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4d66a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xr_array(data,coordonates):\n",
    "    data_structure = xr.DataArray(data, coords=[times, locs], dims=[\"time\", \"space\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8477bc0",
   "metadata": {},
   "source": [
    "# Register information from nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7425d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataframe_copernicus functions aims to test if the data with the specific parameters exists (with copernicus_data)\n",
    "# and then produce a csv file if the data exists\n",
    "\n",
    "def register_data_in_dataframe(url_list,temporal_resolution,year_str,time,experiments,models,out_path, name_variable, name_project,lon_project,lat_project,index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon,df):    \n",
    "\n",
    "    for i in np.arange(0,len(name_project)):\n",
    "        for year in year_str:\n",
    "            #print('Year '+year)\n",
    "            for SSP in experiments:\n",
    "                #experiment = (SSP,) # create tuple for iteration of dataframe\n",
    "                #print('Test with scenario '+SSP)\n",
    "                for model_simulation in models:\n",
    "                    #model =(model_simulation,) # create tuple for iteration of dataframe\n",
    "                    print('For the year '+year+' and project '+name_project[i]+', test with scenario '+SSP+', with model '+model_simulation)\n",
    "                    # path were the futur downloaded file is registered\n",
    "                    #path_for_file= os.path.join(out_path,'Datasets','NEX-GDDP-CMIP6',name_variable,name_project,SSP,model_simulation,period)\n",
    "                    # existence of path_for_file tested in copernicus function\n",
    "                    # climate_variable_path=copernicus_data(temporal_resolution,SSP,name_variable,model_simulation,year_str,area,path_for_file,out_path,name_project,source)\n",
    "                    climate_variable_path = find_path_file(out_path,url_list,name_variable,temporal_resolution,model_simulation,SSP,year,'r1i1p1f1_gn')\n",
    "                    #df=register_data(climate_variable_path,temporal_resolution,name_project,area_projects,SSP,model_simulation,df)\n",
    "                    # area is determined in the \"Load shapefiles and plot\" part\n",
    "                    #df=register_data_in_dataframe(climate_variable_path,temporal_resolution,name_project[i],closest_value_lat[i],closest_value_lon[i],index_closest_lat[i],index_closest_lon[i],SSP,model_simulation,df)\n",
    "                    Open_path = Dataset(climate_variable_path) # open netcdf file\n",
    "                    ds =  xr.open_dataset(climate_variable_path)\n",
    "                    df.loc[(name_project[i],SSP,model_simulation,time,closest_value_lat[i]),('Longitude',closest_value_lon[i])] = ds.pr.isel(lat=index_closest_lat[i],lon=index_closest_lon[i]).values\n",
    "                    Open_path.close # to spare memory\n",
    "    return df\n",
    "\n",
    "def df_to_csv(df,out_path,title_file,name_variable,period):\n",
    "    path_for_csv = os.path.join(out_path,'csv_file',name_variable+period)\n",
    "    # test if dataframe is empty, if values exist for this period\n",
    "    if not df.empty: # if dataframe is not empty, value were registered, the first part is run : a path to register the csv file is created, and the dataframe is registered in a csv file\n",
    "        if not os.path.isdir(path_for_csv):\n",
    "            os.makedirs(path_for_csv) # to ensure creation of file\n",
    "        full_name = os.path.join(path_for_csv,title_file)\n",
    "        print(full_name)\n",
    "        df.to_csv(full_name) # register dataframe in csv file\n",
    "    #else: # if the dataframe is empty, no value were found, there is no value to register or to return\n",
    "        #os.remove(path_for_file)# remove path\n",
    "        #return #df,period# there is no dataframe to return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6abad33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function is used in register_data. The function aims to select in a vector, elements between the values min_vector \n",
    "# and max_vector\n",
    "# in the register_data function, the function 'find_index_project' is used to find the index of the latitudes and longitude \n",
    "# vectors elements which are between min_vector and max_vector values. this allows to select the latitudes and longitudes around\n",
    "# the projects\n",
    "# the input of the function are:\n",
    "# a vector; in register_data, it is the latitude or the longitude vector of the file studied\n",
    "# the minimal value of the interval of interest\n",
    "# the maximal value of the interval of interest\n",
    "# the output is;\n",
    "# the indexes of the vector elements, which values are between min_vector and max_vector\n",
    "def find_index_project(vector,min_vector,max_vector):\n",
    "    # values of vector between min_vector and max_vector\n",
    "    vector_project =[element for element in vector if element > min_vector and element < max_vector]\n",
    "    index_item =[] # prepare empty list to register the indexes of the values of vector whice are between min_vector\n",
    "    # and max_vector\n",
    "    # for loop, to register the indexes of the values of vector whice are between min_vector and max_vector\n",
    "    for item in vector_project:\n",
    "        # values in vector are compared to vector_project values \n",
    "        index_item.append(np.where(vector == item)[0][0])\n",
    "        # the function np.where return the indexes of vector, where the values of vector are equal to item\n",
    "    return index_item # a vector containing the indexes of the vectors elements, which are between min_vector and max_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a3fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used in 'create_dataframe'. The function aims to return the path of the file of interest\n",
    "# The function looks into a list of name which name in the list has every input \n",
    "# The inputs are:\n",
    "#    out_path: a general file path where the files are registered, \n",
    "#    name_file_list: a list of files' names\n",
    "#    variable: the name of the variable of interest\n",
    "#    model: the model of interest (example: ACCESS-CM2)\n",
    "#    scenario: the scenario of interest (example:ssp245)\n",
    "#    year: the year of interest\n",
    "#    ensemble: the ensemble of interest (example: r1i1p1f1_gn)\n",
    "# the output is:\n",
    "#    the path of the file corresponding to all the parameters indicated in input\n",
    "\n",
    "def find_path_file(out_path,name_file_list,variable,temporal_resolution,model,scenario,year,ensemble):\n",
    "    # look into the list of names if find a name with every parameter indicated in inputs\n",
    "    name_found = [name for name in name_file_list if scenario in name and model in name and year in name and ensemble in name and temporal_resolution in name]\n",
    "    print(name_found)\n",
    "    if name_found == []:\n",
    "        # no name with all the parameters indicated as inputs was found\n",
    "        return name_found # return an empty element instead of a path, the function does not run the following lines\n",
    "    # the name was found, so prepare the path of the file of interest\n",
    "    path = os.path.join(out_path,name_found[0])\n",
    "    return path # return the path of the file of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc495cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to select the closest point to the geographical point of the project\n",
    "# the function takes as input \n",
    "#     location_project, which is a numpy.float64\n",
    "#     vector, which is a numpy.ndarray\n",
    "# the function returns\n",
    "#     closest_value[0], a numpy.float64\n",
    "\n",
    "def closest_lat_lon_to_proj(location_project,vector):\n",
    "    # the function any() returns a boolean value. Here, the function test if there are elements in the array \n",
    "    # containing the difference between the vector and the location_project, equal to the minimum of the absolute \n",
    "    # value of the difference between the vector and the location_project\n",
    "    if any(np.where((vector - location_project) == min(abs(vector - location_project)))[0]):\n",
    "        # the function any() returned True\n",
    "        # there is an element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    else:\n",
    "        # the function any() returned False\n",
    "        # there is NO element in the vector that is equal to the minimum of the absolute value of the difference \n",
    "        # between the vector and the location_project\n",
    "        \n",
    "        # the function np.where() returns the index for which (vector - location_project) == -min(abs(vector - location_project))\n",
    "        index_closest = np.where((vector - location_project) == -min(abs(vector - location_project)))[0]\n",
    "        closest_value = vector[index_closest]\n",
    "    return index_closest, closest_value \n",
    "    # the function returns\n",
    "    #     first, the value of the index of the element of vector, that is the closest to location_project    \n",
    "    #     second, the array containing the element of vector, that is the closest to location_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1e8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function aims to create the empty dataframe that will be filled\n",
    "\n",
    "def create_empty_dataframe(name_project,scenarios,models,time,closest_value_lat,closest_value_lon):\n",
    "    df = pd.DataFrame()\n",
    "    for i in np.arange(0,len(name_project)):\n",
    "        midx = pd.MultiIndex.from_product([(name_project[i],),scenarios, models, time, (closest_value_lat[i],)],names=['Name project','Experiment', 'Model', 'Date', 'Latitude'])\n",
    "        cols = pd.MultiIndex.from_product([('Longitude',),(closest_value_lon[i],)])\n",
    "        Variable_dataframe = pd.DataFrame(data = [], \n",
    "                                    index = midx,\n",
    "                                    columns = cols)\n",
    "        df = pd.concat([df,Variable_dataframe])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f851c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions aims to regroup all the scenarios, models, time_aggregation and variables in vectors\n",
    "# the function use the function 'data_information'\n",
    "\n",
    "def information_files_in_vectors(name_list):\n",
    "    variables= []\n",
    "    time_aggregations= []\n",
    "    models= []\n",
    "    scenarios= []\n",
    "    for file_name in name_list:\n",
    "        (variable, time_aggregation, model, scenario, year) = data_information(file_name) \n",
    "        # use function data_information to find information concerning the file_name\n",
    "        if variable not in variables:\n",
    "            variables.append(variable)\n",
    "        if time_aggregation not in time_aggregations:\n",
    "            time_aggregations.append(time_aggregation)\n",
    "        if model not in models:\n",
    "            models.append(model)\n",
    "        if scenario not in scenarios:\n",
    "            scenarios.append(scenario)\n",
    "    return variables, time_aggregations,models,scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d0ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions aims to return the time, latitudes and longitudes of the files of concern\n",
    "def time_lat_lon(path,lat_projects,lon_projects):\n",
    "    ds =  xr.open_dataset(path)\n",
    "    time = ds.indexes['time'].strftime('%d-%m-%Y').values \n",
    "    # ds.indexes['time'] gives back CFTimeIndex format, with hours. The strftime('%d-%m-%Y') permits to have time \n",
    "    # as an index, with format '%d-%m-%Y'. The .values permits to have an array\n",
    "    lat  = ds.lat.values\n",
    "    lon  = ds.lon.values\n",
    "    # preallocate space for the future vectors\n",
    "    index_closest_lat = []\n",
    "    index_closest_lon = []\n",
    "    closest_value_lat = []\n",
    "    closest_value_lon = []\n",
    "    for j in np.arange(0,len(lat_projects)):\n",
    "        (A,B)=closest_lat_lon_to_proj(lat_projects[j],lat)\n",
    "        index_closest_lat.append(A[0])\n",
    "        closest_value_lat.append(B[0])\n",
    "        (C,D)=closest_lat_lon_to_proj(lon_projects[j],lon)\n",
    "        index_closest_lon.append(C[0])\n",
    "        closest_value_lon.append(D[0])\n",
    "    return time, index_closest_lat,index_closest_lon,closest_value_lat,closest_value_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba716215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968340b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e2b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
